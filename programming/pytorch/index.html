<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Pytorch 踩坑 - Rui&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Rui&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Rui&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="使用 Pytorch 时学到的一些知识"><meta property="og:type" content="blog"><meta property="og:title" content="Pytorch 踩坑"><meta property="og:url" content="https://blog.superui.cc/programming/pytorch/"><meta property="og:site_name" content="Rui&#039;s Blog"><meta property="og:description" content="使用 Pytorch 时学到的一些知识"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://blog.superui.cc/gallery/covers/pytorch.png"><meta property="article:published_time" content="2020-12-09T06:55:50.000Z"><meta property="article:modified_time" content="2022-04-11T02:45:00.000Z"><meta property="article:author" content="Superui"><meta property="article:tag" content="Python"><meta property="article:tag" content="Pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/covers/pytorch.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.superui.cc/programming/pytorch/"},"headline":"Rui's Blog","image":["https://blog.superui.cc/gallery/covers/pytorch.png"],"datePublished":"2020-12-09T06:55:50.000Z","dateModified":"2022-04-11T02:45:00.000Z","author":{"@type":"Person","name":"Superui"},"description":"使用 Pytorch 时学到的一些知识"}</script><link rel="canonical" href="https://blog.superui.cc/programming/pytorch/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Rui's Blog" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo_superui1.svg" alt="Rui&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/blog-general-info/message-board">Board</a><a class="navbar-item" href="/blog-general-info/friends">Friends</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/gallery/covers/pytorch.png" alt="Pytorch 踩坑"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-09T06:55:50.000Z" title="2020-12-09T06:55:50.000Z">2020-12-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-11T02:45:00.000Z" title="2022-04-11T02:45:00.000Z">2022-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/programming/">Programming</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Pytorch 踩坑</h1><div class="content"><p>使用 Pytorch 时学到的一些知识</p>
<span id="more"></span>
<ul>
<li><a href="#1-用法">1. 用法</a><ul>
<li><a href="#11-随机种子">1.1. 随机种子</a></li>
<li><a href="#12-zero_grad-optimizer-or-net">1.2. zero_grad optimizer or net？</a></li>
<li><a href="#13-初始化网络">1.3. 初始化网络</a></li>
<li><a href="#14-nnmodule-中-__call__-vs-forward">1.4. nn.module 中 <code>__call__</code> vs <code>forward</code></a></li>
<li><a href="#15-nllloss--crossentropyloss">1.5. NLLLoss &amp; CrossEntropyLoss</a></li>
<li><a href="#16-tensor-非-contiguous-导致无法使用-view">1.6. tensor 非 contiguous 导致无法使用 view()</a></li>
<li><a href="#17-pytorch-中-hook-的使用">1.7. pytorch 中 hook 的使用</a></li>
<li><a href="#18-查看某一层梯度">1.8. 查看某一层梯度</a></li>
<li><a href="#19-计算某一层梯度">1.9. 计算某一层梯度</a></li>
<li><a href="#110-计算梯度的时间">1.10. 计算梯度的时间</a></li>
<li><a href="#111-增加与删减维度">1.11. 增加与删减维度</a></li>
<li><a href="#112-允许-batch-中的样本不等长">1.12. 允许 batch 中的样本不等长</a></li>
<li><a href="#112-对-batchnorm-的参数进行固定">1.12. 对 BatchNorm 的参数进行固定</a></li>
<li><a href="#113-对使用线程数进行固定">1.13. 对使用线程数进行固定</a></li>
</ul>
</li>
<li><a href="#2-设置">2. 设置</a><ul>
<li><a href="#21-dataloader-中的-num_workers-造成训练循环缓慢">2.1. Dataloader 中的 num_workers 造成训练循环缓慢</a></li>
</ul>
</li>
<li><a href="#3-报错">3. 报错</a><ul>
<li><a href="#31-runtimeerror-cuda-error-device-side-assert-triggered">3.1. RuntimeError: CUDA error: device-side assert triggered</a></li>
<li><a href="#32-runtimeerror-cuda-out-of-memory">3.2. RuntimeError: CUDA out of memory</a></li>
<li><a href="#33-runtimeerror-function-mulbackward0-returned-nan-values-in-its-0th-output">3.3. RuntimeError: Function ‘MulBackward0’ returned nan values in its 0th output.</a></li>
</ul>
</li>
</ul>
<h1 id="1-用法"><a href="#1-用法" class="headerlink" title="1. 用法"></a>1. 用法</h1><h2 id="1-1-随机种子"><a href="#1-1-随机种子" class="headerlink" title="1.1. 随机种子"></a>1.1. 随机种子</h2><blockquote>
<p>在导入文件之前，先导入与随机种子相关的包，这样导入的文件随机数也被确定。</p>
</blockquote>
<p>在文件的开头添加以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seed_torch</span>(<span class="params">seed=<span class="number">1029</span></span>):</span><br><span class="line">	random.seed(seed)</span><br><span class="line">	os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed) <span class="comment"># 为了禁止hash随机化，使得实验可复现</span></span><br><span class="line">	np.random.seed(seed)</span><br><span class="line">	torch.manual_seed(seed)</span><br><span class="line">	torch.cuda.manual_seed(seed)</span><br><span class="line">	torch.cuda.manual_seed_all(seed) <span class="comment"># if you are using multi-GPU.</span></span><br><span class="line">	torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">	torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">seed_torch()</span><br></pre></td></tr></table></figure>
<h2 id="1-2-zero-grad-optimizer-or-net？"><a href="#1-2-zero-grad-optimizer-or-net？" class="headerlink" title="1.2. zero_grad optimizer or net？"></a>1.2. zero_grad optimizer or net？</h2><blockquote>
<p><code>model.zero_grad()</code> and <code>optimizer.zero_grad()</code> are the same IF all your model parameters are in that optimizer. 
It is safer to call <code>model.zero_grad()</code> to make sure all grads are zero. 
e.g. if you have two or more optimizers for one model.</p>
</blockquote>
<h2 id="1-3-初始化网络"><a href="#1-3-初始化网络" class="headerlink" title="1.3. 初始化网络"></a>1.3. 初始化网络</h2><p>网络参数初始化会对模型表现产生影响，一般通过一些随机的方式初始化参数。具体的影响可以见<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25110150">这篇博文</a>。
具体如何实现网络权重初始化，可以通过对模型每一层遍历赋值实现，参见如下代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line">torch.nn.init.xavier_uniform(layer) <span class="keyword">for</span> layer <span class="keyword">in</span> params</span><br></pre></td></tr></table></figure>
<h2 id="1-4-nn-module-中-call-vs-forward"><a href="#1-4-nn-module-中-call-vs-forward" class="headerlink" title="1.4. nn.module 中 __call__ vs forward"></a>1.4. nn.module 中 <code>__call__</code> vs <code>forward</code></h2><blockquote>
<p>call 方法中调用了 forward 函数，区别主要在于如果使用 forward 函数来进行前向传播，则无法使用 pytorch 提供的 hook 功能。</p>
</blockquote>
<h2 id="1-5-NLLLoss-amp-CrossEntropyLoss"><a href="#1-5-NLLLoss-amp-CrossEntropyLoss" class="headerlink" title="1.5. NLLLoss &amp; CrossEntropyLoss"></a>1.5. NLLLoss &amp; CrossEntropyLoss</h2><p>从文档中：</p>
<blockquote>
<p>This CrossEntropyLoss criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.</p>
</blockquote>
<p>可以简单理解为：</p>
<blockquote>
<p>CrossEntropyLoss == LogSoftmax + NLLLoss</p>
</blockquote>
<p>那我们为什么要用 LogSoftmax 呢？</p>
<blockquote>
<p>因为在实现上，算log值更加便捷，如果直接计算指数值，可能会出现极大或者极其接近0的情况。
所以使用 LogSoftmax 的话数值稳定性可能会更好。
参考<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/358069078/answer/912691444">此链接</a>。</p>
</blockquote>
<h2 id="1-6-tensor-非-contiguous-导致无法使用-view"><a href="#1-6-tensor-非-contiguous-导致无法使用-view" class="headerlink" title="1.6. tensor 非 contiguous 导致无法使用 view()"></a>1.6. tensor 非 contiguous 导致无法使用 view()</h2><p>当使用 tensor 操作时，新建了一份 tensor 元信息，并重新制定 stride，导致其不连续，无法使用 view()。</p>
<p>最简单的解决方法是使用<code>tensor.contiguous()</code>, 此时会重新开辟一块内存储存底层数据。</p>
<p>若不介意底层数据是否使用了新的内存，用<code>reshape()</code>则更方便。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64551412">这篇文章</a>提供了一个非常完善的解释。</p>
<h2 id="1-7-pytorch-中-hook-的使用"><a href="#1-7-pytorch-中-hook-的使用" class="headerlink" title="1.7. pytorch 中 hook 的使用"></a>1.7. pytorch 中 hook 的使用</h2><p>Pytorch 中的 hook 为我们提供了一个较为方便的方式来访问网络某一层的输入与输出（前向的话返回 feature，反向的话返回梯度。）</p>
<p>具体的使用方法，首先要在相应的层上打开前向或者反向的 hook：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># forward</span></span><br><span class="line"><span class="comment"># 定义 forward hook function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hook_fn_forward</span>(<span class="params">module, <span class="built_in">input</span>, output</span>):</span><br><span class="line">    <span class="built_in">print</span>(module) <span class="comment"># 用于区分模块</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;input&#x27;</span>, <span class="built_in">input</span>) <span class="comment"># 首先打印出来</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;output&#x27;</span>, output)</span><br><span class="line">    total_feat_out.append(output) <span class="comment"># 然后分别存入全局 list 中</span></span><br><span class="line">    total_feat_in.append(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add hook on the layer you want</span></span><br><span class="line">modules = model.named_children() <span class="comment"># </span></span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> modules:</span><br><span class="line">    module.register_forward_hook(hook_fn_forward)</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################</span></span><br><span class="line"><span class="comment"># backward</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hook_fn_backward</span>(<span class="params">module, grad_input, grad_output</span>):</span><br><span class="line">    <span class="built_in">print</span>(module) <span class="comment"># 为了区分模块</span></span><br><span class="line">    <span class="comment"># 为了符合反向传播的顺序，我们先打印 grad_output</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;grad_output&#x27;</span>, grad_output) </span><br><span class="line">    <span class="comment"># 再打印 grad_input</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;grad_input&#x27;</span>, grad_input)</span><br><span class="line">    <span class="comment"># 保存到全局变量</span></span><br><span class="line">    total_grad_in.append(grad_input)</span><br><span class="line">    total_grad_out.append(grad_output)</span><br><span class="line"></span><br><span class="line">modules = model.named_children()</span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> modules:</span><br><span class="line">    module.register_backward_hook(hook_fn_backward)</span><br></pre></td></tr></table></figure>
<p>注意 register 函数接受的是一个函数，会为传入的函数传递三个参数 module， grad_input， grad_output。
这里的 input 和 output 都是以前向网络的方向来进行标记的。</p>
<p>反向传播中对于线性模块：o=W*x+b ，它的输入端包括了W、x 和 b 三部分，因此 grad_input 就是一个包含三个元素的 tuple。
而在 forward hook 中，input 是 x，而不包括 W 和 b。</p>
<p>详见这篇非常好的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75054200">讲解</a>。</p>
<h2 id="1-8-查看某一层梯度"><a href="#1-8-查看某一层梯度" class="headerlink" title="1.8. 查看某一层梯度"></a>1.8. 查看某一层梯度</h2><p>hook 是一种提取梯度的方法，同样的，还有其他方法可以提取梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个全链接层举例</span></span><br><span class="line"><span class="built_in">list</span>(model.modules())[<span class="number">5</span>].weight.grad</span><br></pre></td></tr></table></figure>
<h2 id="1-9-计算某一层梯度"><a href="#1-9-计算某一层梯度" class="headerlink" title="1.9. 计算某一层梯度"></a>1.9. 计算某一层梯度</h2><p>其实如果使用 <code>loss.backward()</code> 然后再利用 hook来提取梯度会有一些耗费时间，因为反向传播是要从尾到头的，如果你只需要倒数几层的梯度的话，其实可以直接计算。
<code>torch.autograd.grad</code> 方法提供了一个计算梯度的方式，可以看以下例子，此方法返回的对象是一个仅有一个元素的元组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算梯度</span></span><br><span class="line"><span class="comment"># 如果需要多次计算的话记得保留计算图</span></span><br><span class="line">grad= torch.autograd.grad(outputs=loss, inputs=W, retain_graph=<span class="literal">True</span>, only_inputs=<span class="literal">True</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>一般来说当我们计算每一个样本所引起的梯度时，可以将 batch_size 设为1，然后分别求梯度。
但是这样是比较费时的，所以可以使用 <code>autograd.grad</code> 中的 <code>is_grads_batched</code> 选项 (Pytorch 1.11 版本)。
在<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/caa28ff4959c7cf7165dabf1ffae7c233b8e4b61/torch/autograd/__init__.py#L177">源代码</a>中对其这样描述：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">is_grads_batched (bool, optional): If ``True``, the first dimension of each tensor in ``grad_outputs`` will be interpreted as the batch dimension.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">grad= torch.autograd.grad(outputs=loss, inputs=W, retain_graph=<span class="literal">True</span>, only_inputs=<span class="literal">True</span>, is_grads_batched=<span class="literal">True</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="1-10-计算梯度的时间"><a href="#1-10-计算梯度的时间" class="headerlink" title="1.10. 计算梯度的时间"></a>1.10. 计算梯度的时间</h2><p>在我的实验终有一个计算每一样本对梯度贡献的需求，有两种方法计算：</p>
<ul>
<li>将 <code>batch_size</code> 设为1，然后使用 <code>torch.autograd.grad</code> 计算梯度。</li>
<li>用非1的 <code>batch_size</code>，计算 loss 时，不 reduce，这样得出来的 loss 是一个向量。遍历这个向量，对向量中每一个tensor使用 <code>torch.autograd.grad</code> 计算梯度。</li>
</ul>
<p>但是发现一个问题。
在 batch 下，平均每个样本的前向时间是要远小于不使用 batch。
但是平均每个样本的后向时间是要远大于不使用 batch。
（这里远小远大是指数量级）。</p>
<p>推测原因为如果遍历向量的话的话，获得的 tensor 中 <code>grad_fn</code> 是 UnbindBackward 而不是 nlllossbackward。
所以尝试在计算 loss 之前就对样本进行遍历，但是其实时间上和遍历 loss 是一样的。
因为是用 loss 计算梯度是要使用之前的计算图，遍历网络输出会使遍历的每一个输出的 <code>grad_fn</code> 变化。
用这种方式虽然看起来 loss 的 <code>grad_fn</code> 还是 nlllossbackward，但是在梯度的计算过程中还是会遇到 UnbindBackward。</p>
<p>所以这个问题没有想到具体的解决方法，就选取了耗费时间相对较短的方法。</p>
<h2 id="1-11-增加与删减维度"><a href="#1-11-增加与删减维度" class="headerlink" title="1.11. 增加与删减维度"></a>1.11. 增加与删减维度</h2><p>有时在对批数据进行乘法等矩阵操作时，时常需要对数据进行升维降维。
此处记录一下操作流程。</p>
<p>例如我们相对两个矩阵进行乘法，第一个矩阵唯度为[N, M]，第二个矩阵维度为[N, K]，其中 N 为该 batch 中样本数目。
我们期望通过得到一个维度为[N, M, K]的三维矩阵。
但是直接的矩阵相乘并不能起到升维的效果，所以在相乘之前要进行升维。
将两个矩阵分别升维到[N, M, 1]和[N, K, 1]。</p>
<p>此处用到两个方法：</p>
<ul>
<li><code>torch.squeeze(n)</code>：若第 n 维维度为1，则将此维度删除。</li>
<li><code>torch.unsqueeze(n)</code>：将第 n 为维度增加维度为1。</li>
</ul>
<p>有时在增加删减维度之后，需要对原始维度进行重新排序，此时可以用到<code>torch.permute()</code>方法。</p>
<h2 id="1-12-允许-batch-中的样本不等长"><a href="#1-12-允许-batch-中的样本不等长" class="headerlink" title="1.12. 允许 batch 中的样本不等长"></a>1.12. 允许 batch 中的样本不等长</h2><p>一般情况下 pytorch 中，每个 batch 的每一个样本都是等长的，如果不等长的话会报错。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: each element in list of batch should be of equal size</span><br></pre></td></tr></table></figure>
<p>一般来说，这是因为 Dataloader 中的参数 <code>collate_fn</code> 的默认值为 torch 自定义的 <code>default_collate</code>，<code>collate_fn</code> 的作用就是对每个batch进行处理，而默认的 <code>default_collate</code>处理出错。
自定义的 <code>default_collate</code> 的作用是将列表中的元素变成 tensor 的形式，详见<a target="_blank" rel="noopener" href="https://blog.csdn.net/SWEDEN_1003/article/details/84343496">这篇文章</a>，同时源码见<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/master/torch/utils/data/_utils/collate.py">这里</a>。</p>
<p>所以这个时候的处理方式是自定义一个 <code>collate_fn</code>，并在其中使用 padding，将每个样本扩充至等长，使得变为 tensor 这一过程不出错。</p>
<p>参考了<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44799217/article/details/115137820">这篇文章</a>。</p>
<h2 id="1-12-对-BatchNorm-的参数进行固定"><a href="#1-12-对-BatchNorm-的参数进行固定" class="headerlink" title="1.12. 对 BatchNorm 的参数进行固定"></a>1.12. 对 BatchNorm 的参数进行固定</h2><p>采用预训练模型的时候，其中经常包含 <code>BatchNorm</code> 层，在对模型进行改造的时候，有的时候会出现问题，这个时候就需要对 <code>BatchNorm</code> 层进行一个固定。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> net.modules():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">        m.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<h2 id="1-13-对使用线程数进行固定"><a href="#1-13-对使用线程数进行固定" class="headerlink" title="1.13. 对使用线程数进行固定"></a>1.13. 对使用线程数进行固定</h2><p>自己在使用 Pytorch 的时候发现，有时候一个文件会占用很多的 CPU 核心。
当提交多个任务时，其会将所有 CPU 快速占满，且难以高效运用，导致影响所有的实验任务。
于是对单个任务的 CPU 使用加以限制成为了一个需求。
此时可以使用以下命令来限制 torch 使用的线程数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.set_num_threads(<span class="number">1</span>) </span><br></pre></td></tr></table></figure>
<h1 id="2-设置"><a href="#2-设置" class="headerlink" title="2. 设置"></a>2. 设置</h1><h2 id="2-1-Dataloader-中的-num-workers-造成训练循环缓慢"><a href="#2-1-Dataloader-中的-num-workers-造成训练循环缓慢" class="headerlink" title="2.1. Dataloader 中的 num_workers 造成训练循环缓慢"></a>2.1. Dataloader 中的 num_workers 造成训练循环缓慢</h2><p>在本地跑实验，一个简单的网络的训练，发现 Dataloader 中 num_workers 设置的数目越大，在 batch 中训练越耗时，表示莫名其妙。在我的情形下将其设为8要比将其设为0慢了百倍以上。
仔细看了一下 mini-batch 的训练过程并且记录了一下时间，发现主要的时间开销发生于 for 循环遍历 loader 之后退出循环时。
所还还是将其设为了0。</p>
<p>造成这个的主要原因可能是 IO 耗时和模型前/后传耗时之间的 GAP 太大，导致进程间造成了阻塞</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://bbs.cvmart.net/topics/2066">PyTorch DataLoader 初探</a></li>
<li><a target="_blank" rel="noopener" href="https://liulin1995.github.io">Pytorch训练加速技巧</a></li>
</ul>
<h1 id="3-报错"><a href="#3-报错" class="headerlink" title="3. 报错"></a>3. 报错</h1><h2 id="3-1-RuntimeError-CUDA-error-device-side-assert-triggered"><a href="#3-1-RuntimeError-CUDA-error-device-side-assert-triggered" class="headerlink" title="3.1. RuntimeError: CUDA error: device-side assert triggered"></a>3.1. RuntimeError: CUDA error: device-side assert triggered</h2><p>参考<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1686771">此篇文章</a>。</p>
<p>一般来说这个报错存在于在 GPU 运行时，不易清晰定位到错误源，所以网络上大家给出的建议是去 CPU 上跑一下。
这个错误出现的原因是数据中的类标记label和网络中的类标记label不匹配。包括但不限于以下几种问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>pytorch识别的类别</th>
<th>数据中的类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>[0,1,2,3]</td>
<td>[1,2,3,4]</td>
</tr>
<tr>
<td>[0,1]</td>
<td>[0,1,2,3]</td>
</tr>
</tbody>
</table>
</div>
<p>解决方法只要找到矛盾发生的地方，对数据中类别的标签进行改动即可。当然有的时候也可能是网络格式写错。</p>
<h2 id="3-2-RuntimeError-CUDA-out-of-memory"><a href="#3-2-RuntimeError-CUDA-out-of-memory" class="headerlink" title="3.2. RuntimeError: CUDA out of memory"></a>3.2. RuntimeError: CUDA out of memory</h2><p>起因在于丢了49000张 mnist 数据进去没有分 batch，本来以为数据的大小只占了450m内存应该不会有问题，但是发现跑了一个前向就加了七八个g的显存，甚至一个模型直接把24g的显卡显存跑炸了。</p>
<p>分析原因应该是因为 batch size 较大的时候，前向输入模型，在某一层计算时申请了很大的 tensor 导致消耗了成倍与数据大小的显存。
这个在小 batch 的情况下应该并不会有太大影响，所以说还是需要使用 batch。</p>
<p>当然还是可以在需要的时候释放缓存，治标不治本。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.empty_cache() </span><br></pre></td></tr></table></figure></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38278334/article/details/105575403">这篇文章</a>简要介绍了 pytorch 的缓存机制。</p>
<h2 id="3-3-RuntimeError-Function-‘MulBackward0’-returned-nan-values-in-its-0th-output"><a href="#3-3-RuntimeError-Function-‘MulBackward0’-returned-nan-values-in-its-0th-output" class="headerlink" title="3.3. RuntimeError: Function ‘MulBackward0’ returned nan values in its 0th output."></a>3.3. RuntimeError: Function ‘MulBackward0’ returned nan values in its 0th output.</h2><p>其实很多类似的这种报错，只是 Function 不一样而已。
出现这种情况的原因是出现了梯度爆炸（gradient-explode），导致出现 NaN 值。
解决的方法是先定位，再处理。</p>
<p>定位可以使用 <code>detect_anomaly</code>，找到报错位置。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> autograd.detect_anomaly():</span><br><span class="line">    loss.backward()</span><br></pre></td></tr></table></figure></p>
<p>处理的话方法不定，一般来说是需要让梯度不要过大。
有一些人提到可以减小学习率，但是这个治标不治本（到底多少才算小呢？）。
所以比较好的方法还是在容易出现梯度爆炸的地方进行处理。
一般来说容易出现梯度爆炸的地方是 <code>log</code> 函数中，在对概率求熵时出现。
所以可以给概率值加上一个很小的数值，如下所示：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_entropy</span>(<span class="params">y_softmax</span>):</span><br><span class="line">    entropy = - torch.<span class="built_in">sum</span>(y_softmax * torch.log(y_softmax + <span class="number">1e-6</span>), dim = <span class="number">1</span>) <span class="comment"># Avoid gradient explode.</span></span><br><span class="line">    <span class="keyword">return</span> entropy</span><br></pre></td></tr></table></figure></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Pytorch 踩坑</p><p><a href="https://blog.superui.cc/programming/pytorch/">https://blog.superui.cc/programming/pytorch/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Superui</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-09</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-04-11</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/tags/Pytorch/">Pytorch</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/knowledge-from-growth/self-improvement/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">自我提升</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/reading-note/intimate-relationship/"><span class="level-item">亲密关系</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><script src="https://giscus.app/client.js" data-repo="SupeRuier/blog-giscus" data-repo-id="R_kgDOHC5FJQ" data-category="Announcements" data-category-id="DIC_kwDOHC5FJc4CON5R" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar_rui_2.jpg" alt="Rui"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Rui</p><p class="is-size-6 is-block">PhD Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shenzhen, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">66</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">49</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/SupeRuier" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/SupeRuier"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Artificial-Intelligence/"><span class="level-start"><span class="level-item">Artificial Intelligence</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-science-engineering/"><span class="level-start"><span class="level-item">Computer Science and Engineering</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/economy-finance/"><span class="level-start"><span class="level-item">Economy &amp; Finance</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Interesting-Stuff/"><span class="level-start"><span class="level-item">Interesting Stuff</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/knowledge-from-growth/"><span class="level-start"><span class="level-item">Knowledge from Growth</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/paper-reading/"><span class="level-start"><span class="level-item">Paper Reading</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/reading-note/"><span class="level-start"><span class="level-item">Reading Note</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/research/"><span class="level-start"><span class="level-item">Research</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/software-tools/"><span class="level-start"><span class="level-item">Software Tools</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EA/"><span class="tag">EA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hackintosh/"><span class="tag">Hackintosh</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS-divergence/"><span class="tag">JS-divergence</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-divergence/"><span class="tag">KL-divergence</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MacOS/"><span class="tag">MacOS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Master-Ma/"><span class="tag">Master Ma</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ray-Dalio/"><span class="tag">Ray-Dalio</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research/"><span class="tag">Research</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/active-learning/"><span class="tag">active-learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithms/"><span class="tag">algorithms</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cloud/"><span class="tag">cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/contrastive-learning/"><span class="tag">contrastive-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs-seminar/"><span class="tag">cs-seminar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/distribution/"><span class="tag">distribution</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/entropy/"><span class="tag">entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/few-shot-learning/"><span class="tag">few-shot-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gaussian-process/"><span class="tag">gaussian-process</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/imitation-learning/"><span class="tag">imitation-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/info-theory/"><span class="tag">info-theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interesting/"><span class="tag">interesting</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/latex/"><span class="tag">latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/logic/"><span class="tag">logic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loss/"><span class="tag">loss</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine-learning</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/neural-network/"><span class="tag">neural-network</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/search/"><span class="tag">search</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/self-supervised-learning/"><span class="tag">self-supervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sorting/"><span class="tag">sorting</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/survey/"><span class="tag">survey</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8E%86%E5%8F%B2/"><span class="tag">历史</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%84%9F%E6%82%9F%E6%80%BB%E7%BB%93/"><span class="tag">感悟总结</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"><span class="tag">翟东升</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%BB%E4%B9%A6/"><span class="tag">读书</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AC%E8%BD%BD/"><span class="tag">转载</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BE%A9%E8%AE%BA/"><span class="tag">辩论</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo_superui1.svg" alt="Rui&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Superui</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>