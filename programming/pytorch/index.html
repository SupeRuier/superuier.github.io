<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Pytorch 踩坑 - Rui&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Rui&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Rui&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="使用 Pytorch 时学到的一些知识"><meta property="og:type" content="blog"><meta property="og:title" content="Pytorch 踩坑"><meta property="og:url" content="https://superuier.github.io/programming/pytorch/"><meta property="og:site_name" content="Rui&#039;s Blog"><meta property="og:description" content="使用 Pytorch 时学到的一些知识"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://superuier.github.io/img/og_image.png"><meta property="article:published_time" content="2020-12-09T06:55:50.000Z"><meta property="article:modified_time" content="2020-12-09T06:55:50.000Z"><meta property="article:author" content="Superui"><meta property="article:tag" content="Python"><meta property="article:tag" content="Pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://superuier.github.io/programming/pytorch/"},"headline":"Rui's Blog","image":["https://superuier.github.io/img/og_image.png"],"datePublished":"2020-12-09T06:55:50.000Z","dateModified":"2020-12-09T06:55:50.000Z","author":{"@type":"Person","name":"Superui"},"description":"使用 Pytorch 时学到的一些知识"}</script><link rel="canonical" href="https://superuier.github.io/programming/pytorch/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Rui's Blog" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo_superui1.svg" alt="Rui&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-09T06:55:50.000Z" title="2020-12-09T06:55:50.000Z">2020-12-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-12-09T06:55:50.000Z" title="2020-12-09T06:55:50.000Z">2020-12-09</time></span><span class="level-item"><a class="link-muted" href="/categories/programming/">Programming</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Pytorch 踩坑</h1><div class="content"><p>使用 Pytorch 时学到的一些知识</p>
<a id="more"></a>
<h1 id="1-用法"><a href="#1-用法" class="headerlink" title="1. 用法"></a>1. 用法</h1><h2 id="1-1-随机种子"><a href="#1-1-随机种子" class="headerlink" title="1.1. 随机种子"></a>1.1. 随机种子</h2><blockquote>
<p>在导入文件之前，先导入与随机种子相关的包，这样导入的文件随机数也被确定。</p>
</blockquote>
<p>在文件的开头添加以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seed_torch</span>(<span class="params">seed=<span class="number">1029</span></span>):</span></span><br><span class="line">	random.seed(seed)</span><br><span class="line">	os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed) <span class="comment"># 为了禁止hash随机化，使得实验可复现</span></span><br><span class="line">	np.random.seed(seed)</span><br><span class="line">	torch.manual_seed(seed)</span><br><span class="line">	torch.cuda.manual_seed(seed)</span><br><span class="line">	torch.cuda.manual_seed_all(seed) <span class="comment"># if you are using multi-GPU.</span></span><br><span class="line">	torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">	torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">seed_torch()</span><br></pre></td></tr></table></figure>
<h2 id="1-2-zero-grad-optimizer-or-net？"><a href="#1-2-zero-grad-optimizer-or-net？" class="headerlink" title="1.2. zero_grad optimizer or net？"></a>1.2. zero_grad optimizer or net？</h2><blockquote>
<p><code>model.zero_grad()</code> and <code>optimizer.zero_grad()</code> are the same IF all your model parameters are in that optimizer. 
It is safer to call <code>model.zero_grad()</code> to make sure all grads are zero. 
e.g. if you have two or more optimizers for one model.</p>
</blockquote>
<h2 id="1-3-初始化网络"><a href="#1-3-初始化网络" class="headerlink" title="1.3. 初始化网络"></a>1.3. 初始化网络</h2><p>网络参数初始化会对模型表现产生影响，一般通过一些随机的方式初始化参数。具体的影响可以见<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25110150">这篇博文</a>。
具体如何实现网络权重初始化，可以通过对模型每一层遍历赋值实现，参见如下代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line">torch.nn.init.xavier_uniform(layer) <span class="keyword">for</span> layer <span class="keyword">in</span> params</span><br></pre></td></tr></table></figure>
<h2 id="1-4-nn-module-中-call-vs-forward"><a href="#1-4-nn-module-中-call-vs-forward" class="headerlink" title="1.4. nn.module 中 __call__ vs forward"></a>1.4. nn.module 中 <code>__call__</code> vs <code>forward</code></h2><blockquote>
<p>call 方法中调用了 forward 函数，区别主要在于如果使用 forward 函数来进行前向传播，则无法使用 pytorch 提供的 hook 功能。</p>
</blockquote>
<h2 id="1-5-NLLLoss-amp-CrossEntropyLoss"><a href="#1-5-NLLLoss-amp-CrossEntropyLoss" class="headerlink" title="1.5. NLLLoss &amp; CrossEntropyLoss"></a>1.5. NLLLoss &amp; CrossEntropyLoss</h2><p>从文档中：</p>
<blockquote>
<p>This CrossEntropyLoss criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.</p>
</blockquote>
<p>可以简单理解为：</p>
<blockquote>
<p>Softmax + CrossEntropyLoss == LogSoftmax + NLLLoss</p>
</blockquote>
<p>那我们为什么要用 LogSoftmax 呢？</p>
<blockquote>
<p>因为在实现上，算log值更加便捷，如果直接计算指数值，可能会出现极大或者极其接近0的情况。
所以使用 LogSoftmax 的话数值稳定性可能会更好。
参考<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/358069078/answer/912691444">此链接</a>。</p>
</blockquote>
<h2 id="1-6-tensor-非-contiguous-导致无法使用-view"><a href="#1-6-tensor-非-contiguous-导致无法使用-view" class="headerlink" title="1.6. tensor 非 contiguous 导致无法使用 view()"></a>1.6. tensor 非 contiguous 导致无法使用 view()</h2><p>当使用 tensor 操作时，新建了一份 tensor 元信息，并重新制定 stride，导致其不连续，无法使用 view()。</p>
<p>最简单的解决方法是使用<code>tensor.contiguous()</code>, 此时会重新开辟一块内存储存底层数据。</p>
<p>若不介意底层数据是否使用了新的内存，用<code>reshape()</code>则更方便。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64551412">这篇文章</a>提供了一个非常完善的解释。</p>
<h2 id="1-7-pytorch-中-hook-的使用"><a href="#1-7-pytorch-中-hook-的使用" class="headerlink" title="1.7. pytorch 中 hook 的使用"></a>1.7. pytorch 中 hook 的使用</h2><p>Pytorch 中的 hook 为我们提供了一个较为方便的方式来访问网络某一层的输入与输出（前向的话返回 feature，反向的话返回梯度。）</p>
<p>具体的使用方法，首先要在相应的层上打开前向或者反向的 hook：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># forward</span></span><br><span class="line"><span class="comment"># 定义 forward hook function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hook_fn_forward</span>(<span class="params">module, <span class="built_in">input</span>, output</span>):</span></span><br><span class="line">    print(module) <span class="comment"># 用于区分模块</span></span><br><span class="line">    print(<span class="string">&#x27;input&#x27;</span>, <span class="built_in">input</span>) <span class="comment"># 首先打印出来</span></span><br><span class="line">    print(<span class="string">&#x27;output&#x27;</span>, output)</span><br><span class="line">    total_feat_out.append(output) <span class="comment"># 然后分别存入全局 list 中</span></span><br><span class="line">    total_feat_in.append(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add hook on the layer you want</span></span><br><span class="line">modules = model.named_children() <span class="comment"># </span></span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> modules:</span><br><span class="line">    module.register_forward_hook(hook_fn_forward)</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################</span></span><br><span class="line"><span class="comment"># backward</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hook_fn_backward</span>(<span class="params">module, grad_input, grad_output</span>):</span></span><br><span class="line">    print(module) <span class="comment"># 为了区分模块</span></span><br><span class="line">    <span class="comment"># 为了符合反向传播的顺序，我们先打印 grad_output</span></span><br><span class="line">    print(<span class="string">&#x27;grad_output&#x27;</span>, grad_output) </span><br><span class="line">    <span class="comment"># 再打印 grad_input</span></span><br><span class="line">    print(<span class="string">&#x27;grad_input&#x27;</span>, grad_input)</span><br><span class="line">    <span class="comment"># 保存到全局变量</span></span><br><span class="line">    total_grad_in.append(grad_input)</span><br><span class="line">    total_grad_out.append(grad_output)</span><br><span class="line"></span><br><span class="line">modules = model.named_children()</span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> modules:</span><br><span class="line">    module.register_backward_hook(hook_fn_backward)</span><br></pre></td></tr></table></figure>
<p>注意 register 函数接受的是一个函数，会为传入的函数传递三个参数 module， grad_input， grad_output。
这里的 input 和 output 都是以前向网络的方向来进行标记的。</p>
<p>反向传播中对于线性模块：o=W*x+b ，它的输入端包括了W、x 和 b 三部分，因此 grad_input 就是一个包含三个元素的 tuple。
而在 forward hook 中，input 是 x，而不包括 W 和 b。</p>
<p>详见这篇非常好的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75054200">讲解</a>。</p>
<h2 id="1-8-查看某一层梯度"><a href="#1-8-查看某一层梯度" class="headerlink" title="1.8. 查看某一层梯度"></a>1.8. 查看某一层梯度</h2><p>hook 是一种提取梯度的方法，同样的，还有其他方法可以提取梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个全链接层举例</span></span><br><span class="line"><span class="built_in">list</span>(model.modules())[<span class="number">5</span>].weight.grad</span><br></pre></td></tr></table></figure>
<h2 id="1-9-计算某一层梯度"><a href="#1-9-计算某一层梯度" class="headerlink" title="1.9. 计算某一层梯度"></a>1.9. 计算某一层梯度</h2><p>其实如果使用 <code>loss.backward()</code> 然后再利用 hook来提取梯度会有一些耗费时间，因为反向传播是要从尾到头的，如果你只需要倒数几层的梯度的话，其实可以直接计算。</p>
<p><code>torch.autograd.grad</code> 方法提供了一个计算梯度的方式，可以看以下例子，此方法返回的对象是一个元祖。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算梯度</span></span><br><span class="line"><span class="comment"># 如果需要多次计算的话记得保留计算图</span></span><br><span class="line">grad= torch.autograd.grad(outputs=loss, inputs=W, retain_graph=<span class="literal">True</span>, only_inputs=<span class="literal">True</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="1-10-计算梯度的时间"><a href="#1-10-计算梯度的时间" class="headerlink" title="1.10. 计算梯度的时间"></a>1.10. 计算梯度的时间</h2><p>在我的实验终有一个计算每一样本对梯度贡献的需求，有两种方法计算：</p>
<ul>
<li>将 <code>batch_size</code> 设为1，然后使用 <code>torch.autograd.grad</code> 计算梯度。</li>
<li>用非1的 <code>batch_size</code>，计算 loss 时，不 reduce，这样得出来的 loss 是一个向量。遍历这个向量，对向量中每一个tensor使用 <code>torch.autograd.grad</code> 计算梯度。</li>
</ul>
<p>但是发现一个问题。
在 batch 下，平均每个样本的前向时间是要远小于不使用 batch。
但是平均每个样本的后向时间是要远大于不使用 batch。
（这里远小远大是指数量级）。</p>
<p>推测原因为如果遍历向量的话的话，获得的 tensor 中 <code>grad_fn</code> 是 UnbindBackward 而不是 nlllossbackward。
所以尝试在计算 loss 之前就对样本进行遍历，但是其实时间上和遍历 loss 是一样的。
因为是用 loss 计算梯度是要使用之前的计算图，遍历网络输出会使遍历的每一个输出的 <code>grad_fn</code> 变化。
用这种方式虽然看起来 loss 的 <code>grad_fn</code> 还是 nlllossbackward，但是在梯度的计算过程中还是会遇到 UnbindBackward。</p>
<p>所以这个问题没有想到具体的解决方法，就选取了耗费时间相对较短的方法。</p>
<h1 id="2-设置"><a href="#2-设置" class="headerlink" title="2. 设置"></a>2. 设置</h1><h2 id="2-1-Dataloader-中的-num-workers-造成训练循环缓慢"><a href="#2-1-Dataloader-中的-num-workers-造成训练循环缓慢" class="headerlink" title="2.1. Dataloader 中的 num_workers 造成训练循环缓慢"></a>2.1. Dataloader 中的 num_workers 造成训练循环缓慢</h2><p>在本地跑实验，一个简单的网络的训练，发现 Dataloader 中 num_workers 设置的数目越大，在 batch 中训练越耗时，表示莫名其妙。在我的情形下将其设为8要比将其设为0慢了百倍以上。
仔细看了一下 mini-batch 的训练过程并且记录了一下时间，发现主要的时间开销发生于 for 循环遍历 loader 之后退出循环时。
所还还是将其设为了0。</p>
<p>造成这个的主要原因可能是 IO 耗时和模型前/后传耗时之间的 GAP 太大，导致进程间造成了阻塞，详见<a target="_blank" rel="noopener" href="https://bbs.cvmart.net/topics/2066">这篇文章</a>。</p>
<h1 id="3-报错"><a href="#3-报错" class="headerlink" title="3. 报错"></a>3. 报错</h1><h2 id="3-1-RuntimeError-CUDA-error-device-side-assert-triggered"><a href="#3-1-RuntimeError-CUDA-error-device-side-assert-triggered" class="headerlink" title="3.1. RuntimeError: CUDA error: device-side assert triggered"></a>3.1. RuntimeError: CUDA error: device-side assert triggered</h2><p>参考<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1686771">此篇文章</a>。</p>
<p>一般来说这个错误出现的原因是数据中的类标记label和网络中的类标记label不匹配。包括但不限于以下几种问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>pytorch识别的类别</th>
<th>数据中的类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>[0,1,2,3]</td>
<td>[1,2,3,4]</td>
</tr>
<tr>
<td>[0,1]</td>
<td>[0,1,2,3]</td>
</tr>
</tbody>
</table>
</div>
<p>解决方法只要找到矛盾发生的地方，对数据中类别的标签进行改动即可。当然有的时候也可能是网络格式写错。</p>
<h2 id="3-2-RuntimeError-CUDA-out-of-memory"><a href="#3-2-RuntimeError-CUDA-out-of-memory" class="headerlink" title="3.2. RuntimeError: CUDA out of memory"></a>3.2. RuntimeError: CUDA out of memory</h2><p>起因在于丢了49000张 mnist 数据进去没有分 batch，本来以为数据的大小只占了450m内存应该不会有问题，但是发现跑了一个前向就加了七八个g的显存，甚至一个模型直接把24g的显卡显存跑炸了。</p>
<p>分析原因应该是因为 batch size 较大的时候，前向输入模型，在某一层计算时申请了很大的 tensor 导致消耗了成倍与数据大小的显存。
这个在小 batch 的情况下应该并不会有太大影响，所以说还是需要使用 batch。</p>
<p>当然还是可以在需要的时候释放缓存，治标不治本。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.empty_cache() </span><br></pre></td></tr></table></figure></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38278334/article/details/105575403">这篇文章</a>简要介绍了 pytorch 的缓存机制。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Pytorch 踩坑</p><p><a href="https://superuier.github.io/programming/pytorch/">https://superuier.github.io/programming/pytorch/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Superui</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-09</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-12-09</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/tags/Pytorch/">Pytorch</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/knowledge-from-growth/self-improvement/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">自我提升</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/reading-note/intimate-relationship/"><span class="level-item">亲密关系</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar_rui_2.jpg" alt="Rui"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Rui</p><p class="is-size-6 is-block">PhD Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shenzhen, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">30</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/SupeRuier" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/SupeRuier"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/computer-science-engineering/"><span class="level-start"><span class="level-item">Computer Science and Engineering</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/economy-finance/"><span class="level-start"><span class="level-item">Economy &amp; Finance</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/knowledge-from-growth/"><span class="level-start"><span class="level-item">Knowledge from Growth</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/paper-reading/"><span class="level-start"><span class="level-item">Paper Reading</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/reading-note/"><span class="level-start"><span class="level-item">Reading Note</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/research/"><span class="level-start"><span class="level-item">Research</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/software-tools/"><span class="level-start"><span class="level-item">Software Tools</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hackintosh/"><span class="tag">Hackintosh</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MacOS/"><span class="tag">MacOS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Master-Ma/"><span class="tag">Master Ma</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research/"><span class="tag">Research</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/active-learning/"><span class="tag">active-learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cloud/"><span class="tag">cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs-seminar/"><span class="tag">cs-seminar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/few-shot-learning/"><span class="tag">few-shot-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gaussian-process/"><span class="tag">gaussian-process</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/imitation-learning/"><span class="tag">imitation-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loss/"><span class="tag">loss</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine-learning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/math/"><span class="tag">math</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/neural-network/"><span class="tag">neural-network</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/survey/"><span class="tag">survey</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%84%9F%E6%82%9F%E6%80%BB%E7%BB%93/"><span class="tag">感悟总结</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"><span class="tag">翟东升</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%BB%E4%B9%A6/"><span class="tag">读书</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AC%E8%BD%BD/"><span class="tag">转载</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo_superui1.svg" alt="Rui&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Superui</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>