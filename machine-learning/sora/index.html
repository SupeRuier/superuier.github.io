

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon.svg">
  <link rel="icon" href="/images/favicon.svg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Superui">
  <meta name="keywords" content="">
  
    <meta name="description" content="今日震撼于 OpenAI 视频生成模型 Sora 的产出效果，在此对技术报告进行阅读学习。 在文末我也会加入一些自己的看法。">
<meta property="og:type" content="article">
<meta property="og:title" content="Sora 技术报告，阅读与思考">
<meta property="og:url" content="https://blog.superui.cc/machine-learning/sora/index.html">
<meta property="og:site_name" content="Superui&#39;s Blog">
<meta property="og:description" content="今日震撼于 OpenAI 视频生成模型 Sora 的产出效果，在此对技术报告进行阅读学习。 在文末我也会加入一些自己的看法。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.superui.cc/gallery/covers/sora.jpg">
<meta property="article:published_time" content="2024-02-16T09:00:00.000Z">
<meta property="article:modified_time" content="2024-02-16T09:00:00.000Z">
<meta property="article:author" content="Superui">
<meta property="article:tag" content="machine-learning">
<meta property="article:tag" content="neural-network">
<meta property="article:tag" content="diffusion">
<meta property="article:tag" content="video">
<meta property="article:tag" content="generative-model">
<meta property="article:tag" content="OpenAI">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://blog.superui.cc/gallery/covers/sora.jpg">
  
  
  
  <title>Sora 技术报告，阅读与思考 - Superui&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.superui.cc","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Superui's Blog" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>一只超级 Rui</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/board/">
                <i class="iconfont icon-cliplist"></i>
                <span>留言板</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/photography/">
                <i class="iconfont icon-images"></i>
                <span>摄影</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/gallery/covers/sora.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Sora 技术报告，阅读与思考"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-02-16 17:00" pubdate>
          2024年2月16日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          43 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Sora 技术报告，阅读与思考</h1>
            
            
              <div class="markdown-body">
                
                <!-- omit in toc -->
<p>今日震撼于 OpenAI 视频生成模型 Sora 的产出效果，在此对技术报告进行阅读学习。
在文末我也会加入一些自己的看法。</p>
<span id="more"></span>
<h2 id="Sora-生成效果">Sora 生成效果</h2>
<p>被生成的效果所震撼，尤其是视频 3 中列车通过阴影时车窗反射出的倒影。</p>
<p><video width="80%" height="80%"  src="https://cdn.openai.com/tmp/s/title_0.mp4"  autoplay controls loop></video>
<video width="80%" height="80%"  src="https://cdn.openai.com/sora/videos/closeup-of-womans-eye.mp4"  autoplay controls loop></video>
<video width="80%" height="80%"  src="https://cdn.openai.com/sora/videos/train-window.mp4"  autoplay controls loop></video></p>
<h2 id="技术报告内容">技术报告内容</h2>
<blockquote>
<p>This technical report focuses on (1) our method for turning visual data of all types into a unified representation that enables large-scale training of generative models, and (2) qualitative evaluation of Sora’s capabilities and limitations. Model and implementation details are not included in this report.</p>
</blockquote>
<p>首先指出报告主要由两部分组成，第一部分是将各种类型的视觉数据转换为统一的表示，以便大规模训练生成模型。第二部分是对 Sora 的能力和局限性进行定性评估。模型和实现细节不包括在此报告中。</p>
<blockquote>
<p>Sora is a generalist model of visual data—it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a full minute of high definition video.</p>
</blockquote>
<p>首先指出先前模型的缺点，引出了 Sora，它可以生成各种长度、分辨率、比例的视频。
主要有以下几个关键步骤。</p>
<h3 id="1-Turning-visual-data-into-patches">1. Turning visual data into patches</h3>
<p>同样是使用大模型，在互联网级别的数据上进行训练。
受到语言模型对于 token 操作的启发，Sora 将视觉数据转换为补丁（patches）。</p>
<div style="width:100%;margin:auto"><img src="/machine-learning/sora/figure-patches.png" srcset="/img/loading.gif" lazyload class=""></div>
<p>宏观来看，先将视频压缩到低维空间，然后再将其解码到时空补丁（spacetime patches）。</p>
<h3 id="2-Video-compression-network">2. Video compression network</h3>
<p>训练一个 1 中提到的将原始视频降维的神经网络。</p>
<blockquote>
<p>This network takes raw video as input and outputs a latent representation that is compressed both temporally and spatially.</p>
</blockquote>
<p>其中时间和空间信息同被压缩。</p>
<blockquote>
<p>Sora is trained on and subsequently generates videos within this compressed latent space.</p>
</blockquote>
<p>Sora 之后的生成过程都在这个压缩的潜在空间中进行。</p>
<blockquote>
<p>We also train a corresponding decoder model that maps generated latents back to pixel space.</p>
</blockquote>
<p>同样的，训练一个解码器，将潜在空间的数据映射回像素空间。</p>
<h3 id="3-Spacetime-Latent-Patches">3. Spacetime Latent Patches</h3>
<blockquote>
<p>Given a compressed input video, we extract a sequence of spacetime patches which act as transformer tokens. This scheme works for images too since images are just videos with a single frame.</p>
</blockquote>
<p>这些 patches 在训练时被当作 transformer 的 token 进行处理。
视频和图像有着相同的处理方式。</p>
<blockquote>
<p>Our patch-based representation enables Sora to train on videos and images of variable resolutions, durations and aspect ratios.</p>
</blockquote>
<p>这种表示方式使得 Sora 可以在不同分辨率、持续时间和宽高比的视频和图像上进行训练。</p>
<blockquote>
<p>At inference time, we can control the size of generated videos by arranging randomly-initialized patches in an appropriately-sized grid.</p>
</blockquote>
<p>在推理时，可以通过将随机初始化的补丁排列在适当大小的网格中来控制生成的视频的大小。</p>
<h3 id="4-Scaling-transformers-for-video-generation">4. Scaling transformers for video generation</h3>
<blockquote>
<p>Sora is a diffusion model; given input noisy patches (and conditioning information like text prompts), it’s trained to predict the original “clean” patches.
Importantly, Sora is a <strong>diffusion transformer</strong>.</p>
</blockquote>
<p>Sola 是一个 <strong>diffusion transformer</strong>，它通过输入噪声补丁（和文本提示等条件信息），训练来预测原始的“干净”补丁。</p>
<div style="width:100%;margin:auto"><img src="/machine-learning/sora/figure-diffusion.png" srcset="/img/loading.gif" lazyload class=""></div>
<blockquote>
<p>In this work, we find that diffusion transformers scale effectively as video models as well. Below, we show a comparison of video samples with fixed seeds and inputs as training progresses. Sample quality improves markedly as training compute increases.</p>
</blockquote>
<p>在这项工作中，我们发现 diffusion transformer 在视频模型中也能有效扩展。随着训练计算量的增加，样本质量显著提高。</p>
<h3 id="5-Variable-durations-resolutions-aspect-ratios">5. Variable durations, resolutions, aspect ratios</h3>
<blockquote>
<p>Past approaches to image and video generation typically resize, crop or trim videos to a standard size – e.g., 4 second videos at 256x256 resolution. We find that instead training on data at its native size provides several benefits.</p>
</blockquote>
<p>之前的方法都会将视频调整到标准大小，例如 4 秒的视频，分辨率为 256x256。
但我们发现，训练原始大小的数据提供了几个好处。</p>
<ol>
<li>采样的灵活性：从 1920<em>1080 到 1080</em>1920 中的任意尺寸。</li>
<li>构图上的提升：不容易出现主体仅部分存在于画面的情况。</li>
</ol>
<h3 id="6-Language-understanding">6. Language understanding</h3>
<blockquote>
<p>Training text-to-video generation systems requires a large amount of videos with corresponding text captions. We apply the re-captioning technique introduced in DALL·E 330 to videos.</p>
</blockquote>
<p>将 DALL·E 330 中的重新标注技术应用到视频中。</p>
<blockquote>
<p>We first train a highly descriptive captioner model and then use it to produce text captions for all videos in our training set.</p>
</blockquote>
<p>先训练一个描述模型对所有视频进行描述。</p>
<blockquote>
<p>We find that training on highly descriptive video captions improves text fidelity as well as the overall quality of videos.
Similar to DALL·E 3, we also leverage GPT to turn short user prompts into longer detailed captions that are sent to the video model.</p>
</blockquote>
<p>同样使用 GPT 将短提示转换为详细的描述。</p>
<h3 id="7-Prompting-with-images-and-videos">7. Prompting with images and videos</h3>
<blockquote>
<p>Sora can also be prompted with other inputs, such as pre-existing images or video.
This capability enables Sora to perform a wide range of image and video editing tasks—creating perfectly looping video, animating static images, extending videos forwards or backwards in time, etc.</p>
</blockquote>
<p>同样可以使用照片以及视频作为提示，这使得 Sora 可以执行各种图像和视频编辑任务。</p>
<h3 id="8-Image-generation-capabilities">8. Image generation capabilities</h3>
<blockquote>
<p>The model can generate images of variable sizes—up to 2048x2048 resolution.</p>
</blockquote>
<p>模型可以生成不同尺寸的图像，最高分辨率为 2048x2048。</p>
<h3 id="9-Emerging-simulation-capabilities">9. Emerging simulation capabilities</h3>
<blockquote>
<p>We find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world.</p>
</blockquote>
<p>我们发现，当大规模训练视频模型时，会出现一些有趣的新能力。这些能力使得 Sora 可以模拟一些来自物理世界的人、动物和环境的一些方面。</p>
<ol>
<li>3D consistency：在摄像机移动时，模型能够保持物体的一致性。</li>
<li>Long-range coherence and object permanence：即使物体被遮挡或者离开了屏幕，模型也能够保留它的存在。</li>
<li>Interacting with the world：视频中具体的交互行为会留下痕迹，比如画痕和咬痕。</li>
<li>Simulating digital worlds：比如我的世界中的玩家行为视频。</li>
</ol>
<h2 id="个人感想">个人感想</h2>
<p>总的来说，在语言模型之外，再一次证明了堆数据量的可靠性。
那么在大规模数据下，工程上如何设计任务便成了重中之重。
从当下表现的角度，同时考虑到未来一段时间可能的飞速进展，我有着以下几个问题，以及一些自己的看法。</p>
<h3 id="从大量的训练视频中到底学到了什么信息？">从大量的训练视频中到底学到了什么信息？</h3>
<p>首先不必多言的就是 low-level 的表征信息，即“如何读视频”。
在海量的数据输入下，类似于 LLM，Sora 已经可以学到视频的统计信息。</p>
<p>但更重要的，我认为是 high-level 的信息，即“视频中那些不言而喻的正确事实”。
浅层一些就是“石头是硬的”，“玻璃是脆的”，“河是流动的”，“船是浮着的”。
深层一些就是，在视觉下，所有的宏观物理定律都投影在了二维平面上。
这也是为什么在生成的视频中，基本上都满足物理规律以及几何原理。
个人觉得如果将这个手段用于科学模拟以及发现会比较有意思。</p>
<h3 id="于-2D-相比我们是否需要-3D？">于 2D 相比我们是否需要 3D？</h3>
<p>这就引出了第二个问题，作为人而言，我们接触的世界是三维的，但是我们的视觉输入是二维的。
初看 Sora 的时候，我还以为他会进行一些三维的推断，但是实际上并没有。
这也许是因为 2D 的信息已经足够了，或者说 2D 的信息已经包含了 3D 的信息。
这个也和特斯拉的纯视觉方案有些类似，其并未使用激光雷达三维点云。
所以我们还需要 3D 吗？</p>
<p>这个问题或许可以拆成：</p>
<ol>
<li>在哪里我们一定需要 3D 以及为什么？（如果我们绝大多数的输入是以 2D 呈现的话）</li>
<li>如果有一定需要 3D 的场景，2D 训练数据生成的方式是否可以？（目前已经产生了良好的透视关系）</li>
</ol>
<h3 id="相比于图像，视频有着什么优势？应用场景在哪里？">相比于图像，视频有着什么优势？应用场景在哪里？</h3>
<p>图像就是单帧的视频。
个人作为摄影爱好者一直在思考这个问题，目前仍没有明确的答案。
或许之后可以新开一篇文章，可能会形而上一些。</p>
<p>但是从 Sora 的角度来看，它似乎第一次证明了视频的生成质量。
可以用于之前大部分使用图像进行宣传的地方，比如广告、电商、游戏等。
其还可以用于影视行业起到一些降本增效的辅助作用，比如特效、动画等。
那么之外呢？如果说视频的生产成本降低了，那是不是视频会越来越多呢？
换句话说是否会有更广阔的视频呈现空间（而不是其他空间）来冲刷大家的有限的空闲时间呢？</p>
<h1>Reference</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://openai.com/research/video-generation-models-as-world-simulators">Video generation models as world simulators</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Machine-Learning/" class="category-chain-item">Machine Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/machine-learning/">#machine-learning</a>
      
        <a href="/tags/neural-network/">#neural-network</a>
      
        <a href="/tags/diffusion/">#diffusion</a>
      
        <a href="/tags/video/">#video</a>
      
        <a href="/tags/generative-model/">#generative-model</a>
      
        <a href="/tags/OpenAI/">#OpenAI</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Sora 技术报告，阅读与思考</div>
      <div>https://blog.superui.cc/machine-learning/sora/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Superui</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年2月16日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/computer-vision/detr/" title="从 DETR 出发，目标检测再学习">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">从 DETR 出发，目标检测再学习</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/reading-note/special-privilege-and-rent-seeking/" title="《特权和寻租的经济学》读书笔记">
                        <span class="hidden-mobile">《特权和寻租的经济学》读书笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"SupeRuier/blog-giscus","repo-id":"R_kgDOHC5FJQ","category":"Announcements","category-id":"DIC_kwDOHC5FJc4CON5R","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"bottom","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
