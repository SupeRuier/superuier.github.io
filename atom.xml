<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rui&#39;s Blog</title>
  
  
  <link href="https://superuier.github.io/atom.xml" rel="self"/>
  
  <link href="https://superuier.github.io/"/>
  <updated>2021-11-24T13:30:00.000Z</updated>
  <id>https://superuier.github.io/</id>
  
  <author>
    <name>Superui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>人工智能中的逻辑</title>
    <link href="https://superuier.github.io/artificial-intelligence/ai-logic/"/>
    <id>https://superuier.github.io/artificial-intelligence/ai-logic/</id>
    <published>2021-11-24T13:30:00.000Z</published>
    <updated>2021-11-24T13:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>将逻辑作为基于知识的 Agent 的一类通用表示，这样的 Agent 通过对信息的组合荷载组合以适应各种用途。本文一部分参考了这位同学的<a href="https://blog.csdn.net/rectsuly/article/details/73104723">笔记</a>。</p><a id="more"></a><p>Logics: formal languages for representing knowledge to extract conclusions</p><h1 id="基于知识的-Agent"><a href="#基于知识的-Agent" class="headerlink" title="基于知识的 Agent"></a>基于知识的 Agent</h1><ul><li>知识库（KB）：基于知识的 Agent 的核心部件。是一个“语句”集合。</li><li>语句（sentence）：用知识表示语言表达，表示了关于世界的某些断言。</li><li>公理：当某语句是直接给定而不是推导得到的时候，我们将其称为公理。</li></ul><p>每次调用 Agent 程序，他做三件事：</p><ol><li>Agent TELL 知识库他所感知到的内容。</li><li>Agent ASK 知识库应该执行什么行动。<ul><li>在此过程中可能会对于世界的当前状态，可能行动队列进行大量推理。</li></ul></li><li>Agent TELL 知识库他采取的行动，并执行该行动。</li></ol><h1 id="逻辑知识与概念"><a href="#逻辑知识与概念" class="headerlink" title="逻辑知识与概念"></a>逻辑知识与概念</h1><p>逻辑：一种形式语言，可以表示能得出结论的信息 </p><ul><li>语法（Syntax）：定义了语言中的句子 </li><li>语义（Semantics）：定义了句子的意思，即语义定义了每个语句关于每个可能世界的真值 </li></ul><p>蕴涵（Entailment）</p><ul><li>蕴涵意为一个语句逻辑上跟随另一个语句而出现：$KB |= \alpha$</li><li>知识库 KB 蕴涵句子 $\alpha$ 当且仅当在 KB 为真的每个世界中，$\alpha$也为真</li><li>蕴涵是句子间的关系，其基于语义。</li><li>例如，x=0 蕴含 xy=0。</li></ul><p>逻辑推理（inference）：</p><ul><li>如果推理算法 i 可以根据 KB 导出 $\alpha$，我们表示为：$KB |-_{i} \alpha$，读为“i 从 KB 导出 $\alpha$”</li><li>KB的所有推论集合是一个干草堆，α是针，蕴含=干草堆里的针，推理=找到它 </li><li>对于推理算法 i：<ul><li>可靠性 Sound：不会虚构事实，只导出语义蕴涵句。</li><li>完备性 Completeness：可以生成任一蕴涵句。</li></ul></li></ul><h1 id="命题逻辑"><a href="#命题逻辑" class="headerlink" title="命题逻辑"></a>命题逻辑</h1><p>Syntax 语法：</p><ul><li>原子语句：命题符号P1，P2等是句子，代表一个或为真或为假的命题 </li><li>复合句： <ul><li>如果S是一个句子，则┐S也是一个句子（negation 非，否定式） </li><li>如果S1和S2是句子，则S1∧S2是句子（conjunction 与，合取式） </li><li>如果S1和S2是句子，则S1∨S2是句子（disjunction 或，析取式） </li><li>如果S1和S2是句子，则S1=&gt;S2是句子（implication 蕴涵，蕴涵式） </li><li>如果S1和S2是句子，则S1&lt;=&gt;S2是句子（biconditional 当且仅当，双向蕴涵式）</li></ul></li></ul><p>语义：</p><ul><li>定义了判定特定模型中语句真值的规则。</li><li>可以用真值表总结</li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/truth-table.png" class=""></div><p>其中=&gt;的真值表比较令人困惑。</p><ul><li>不要用如果 P 那么 Q的思路来理解。<ul><li>命题逻辑不要求 P/Q 间的相关性或因果关系。</li></ul></li><li>以“如果 P 为真，那我主张 Q 为真，否则无可奉告”来理解。<ul><li>前提为假的任意蕴含都为真。</li><li>该语句为假的唯一条件是 P 为真而 Q 为假。</li></ul></li></ul><p>算符具有一定的运算性质（逻辑等价）：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/property.png" class=""></div><p>Implication 的几形式变换，真值可能会发生变换：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/implication.png" class=""></div><h2 id="推导和证明"><a href="#推导和证明" class="headerlink" title="推导和证明"></a>推导和证明</h2><p>下列表示意为，给定任何形式的上方语句，就可以推导出下方语句：</p><ul><li>Modus Ponens: 假言推理原则 $\frac{\alpha \Rightarrow \beta, \quad \alpha}{\beta}$</li><li>Modus Tollens: 假言推理原则 $\frac{\alpha \Rightarrow \beta, \quad \neg \beta}{\neg \alpha}$</li><li>Addition: $\frac{\alpha}{\alpha \vee \beta}$</li><li>Simplification/And-Elimination: $\frac{\alpha \wedge \beta}{\beta}$</li><li>Disjunctive-syllogism: $\frac{\alpha \vee \beta, \quad \neg \alpha}{\beta}$</li><li>Hypothetical-syllogism: $\frac{\alpha \Rightarrow \beta, \quad \beta \Rightarrow \gamma}{\alpha \Rightarrow \gamma}$</li></ul><p>Search for proofs is a more efficient way than enumerating models: </p><ul><li>Truth tables have an exponential number of models.</li><li>The idea of inference is to repeat applying inference rules to the KB.</li><li>Inference is sound, but how about completeness?</li></ul><h2 id="如何来保证完备性？"><a href="#如何来保证完备性？" class="headerlink" title="如何来保证完备性？"></a>如何来保证完备性？</h2><ul><li>Proof by resolution</li><li>Forward or Backward chaining</li></ul><h3 id="归结（Resolution）"><a href="#归结（Resolution）" class="headerlink" title="归结（Resolution）"></a>归结（Resolution）</h3><p>类似于 Disjunctive-syllogism。如果两个中必存在一个，而又不是第一个，则是第二个。</p><p>单元归结（Unit resolution）</p><script type="math/tex; mode=display">\frac{\ell_{1} \vee \cdots \vee \ell_{k} \quad m}{\ell_{1} \vee \cdots \vee \ell_{i-1} \vee \ell_{i+1} \vee \cdots \vee \ell_{k}}</script><p>全归结（Full resolution）</p><script type="math/tex; mode=display">\frac{\ell_{1} \vee \cdots \vee \ell_{k} \quad m_{1} \vee \cdots \vee m_{n}}{\ell_{1} \vee \cdots \vee \ell_{i-1} \vee \ell_{i+1} \vee \cdots \vee \ell_{k} \vee m_{1} \vee \cdots \vee m_{j-1} \vee m_{j+1} \vee \cdots \vee m_{n}}</script><p>其中 $\ell_{i}$ 和 $m_{j}$ 是互补文字。</p><h3 id="合取范式（CNF）"><a href="#合取范式（CNF）" class="headerlink" title="合取范式（CNF）"></a>合取范式（CNF）</h3><p>以子句的合取式表达的语句被称为合取范式或者 CNF， 合取式不易阅读，但其将成为归结过程的输入：</p><ul><li>消去等价词</li><li>消去蕴含次</li><li>否定词只出现在文字前边（而不是括号前面）</li></ul><h3 id="归结算法"><a href="#归结算法" class="headerlink" title="归结算法"></a>归结算法</h3><p>为了证明 $KB |= \alpha$，需要证明 $(KB \wedge \neg\alpha)$是不可满足的，通过推倒矛盾来证明。</p><ul><li>先将 $(KB \wedge \neg\alpha)$ 转化为 CNF。</li><li>对子句运用归结规则，产生新子句，如果其尚未出现过，则将其加入子句集，直到：<ul><li>没有可以添加的新语句。</li><li>两个子句归结出空子句，等价于 False。（函数返回 True）</li></ul></li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/pl-resolution.png" class=""></div><blockquote><p><strong>基本归结定理</strong>：如果子句集是不可满足的，那么这些子句的归结闭包包含空子句。</p></blockquote><h3 id="Forward-or-Backward-chaining"><a href="#Forward-or-Backward-chaining" class="headerlink" title="Forward or Backward chaining"></a>Forward or Backward chaining</h3><p>前向链接 Forward Chaining：</p><ul><li>判断单个命题词是否被限定子句的知识库所蕴含。</li><li>这个算法运行的时间是线性的。</li><li>data-driven</li></ul><p>反向链接 Backward Chaining：</p><ul><li>从查询开始进行推理，如果查询为真则停止，否则，从知识库寻找以 q 为结论的蕴含式，如果前提都为真，则为真。</li><li>这个算法运行的时间也是线性的。</li><li>goal-driven</li></ul><h3 id="DPLL-Algorithm"><a href="#DPLL-Algorithm" class="headerlink" title="DPLL Algorithm"></a>DPLL Algorithm</h3><ul><li>Check the satisfiablity of a sentence in propositional logic.</li><li>类似 backtracking 但是运用了很多启发式的技术，例如早停、纯符号启发式、单元子句启发式等。</li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/DPLL.png" class=""></div><h1 id="一阶逻辑-First-Order-Logic（FOL）"><a href="#一阶逻辑-First-Order-Logic（FOL）" class="headerlink" title="一阶逻辑 First Order Logic（FOL）"></a>一阶逻辑 First Order Logic（FOL）</h1><p>可以作为 Propositional Logic 的替代。（命题逻辑表达能力很弱。）</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/FOL.png" class=""></div><h1 id="总结-Summary"><a href="#总结-Summary" class="headerlink" title="总结 Summary"></a>总结 Summary</h1><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/summary.png" class=""></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;将逻辑作为基于知识的 Agent 的一类通用表示，这样的 Agent 通过对信息的组合荷载组合以适应各种用途。
本文一部分参考了这位同学的&lt;a href=&quot;https://blog.csdn.net/rectsuly/article/details/73104723&quot;&gt;笔记&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://superuier.github.io/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://superuier.github.io/tags/AI/"/>
    
    <category term="logic" scheme="https://superuier.github.io/tags/logic/"/>
    
  </entry>
  
  <entry>
    <title>国际经济形势与中美关系</title>
    <link href="https://superuier.github.io/economy-finance/seminar-talks/china-us-relationship/"/>
    <id>https://superuier.github.io/economy-finance/seminar-talks/china-us-relationship/</id>
    <published>2021-11-14T04:39:46.000Z</published>
    <updated>2021-11-14T04:39:46.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>翟东升 2021-10-28 于海南讲座。</p><a id="more"></a> <p>本次讲座涉及四个 Topic。</p><h2 id="1-疫情冲击何时结束"><a href="#1-疫情冲击何时结束" class="headerlink" title="1. 疫情冲击何时结束"></a>1. 疫情冲击何时结束</h2><ul><li>疫情传播似乎更加普及，但是疫苗的使用下，死亡率重症率下降。</li><li>11月8日开始世界大国开始放开人员往来。</li><li>中国可能在较长一段时间保持是否开门的难题。</li><li>由于疫情，东亚供应链可能重新收缩为中国供应链，一部分产能试图回中国，但是目前看来我们也不愿意接受。</li></ul><h2 id="2-美联储是否有能力加息缩表"><a href="#2-美联储是否有能力加息缩表" class="headerlink" title="2. 美联储是否有能力加息缩表"></a>2. 美联储是否有能力加息缩表</h2><ul><li>美国当前通胀率很高。</li><li>70年代中后期，婴儿潮，美国通胀率也高。美国政府主要挑战就是国内控制通胀。控制通胀的目的是来打击国内左翼激进工会势力。</li><li>长周期十年国债收益率大方向可以测，由人口结构预测。</li><li>以前08年也大量印钞票但没有使通胀大幅上升，因为钱没有进老百姓口袋。</li><li>这次疫情很多资金直接进入了老百姓口袋，零售急速上升，供给跟不上，直接导致通胀。</li><li>美国上升，其他地方也会上升，我们也会，只是暂时还没传导到下游消费。</li><li>每天嚷嚷的缩表只是象征性的，不断印钱才是常态。</li><li>主流流氓国家国债总量指数上升（尽管美国有扩有缩）。</li><li>央行独立性不能迷信。</li><li><strong>明年一月份，美联储大概率换人，鲍威尔不连任</strong><ul><li>未来两个月加息缩表会比较严重</li><li>但是明年二月开始政策会继续宽松，原因因为疫情还不是个头</li></ul></li></ul><h2 id="3-中美关系未来走向"><a href="#3-中美关系未来走向" class="headerlink" title="3. 中美关系未来走向"></a>3. 中美关系未来走向</h2><ul><li>目前是暴跌之后的小反弹，可能四年。<ul><li>高盛前总裁桑顿去新疆参观。</li><li>戴琦说不脱钩，要重新挂钩，务实坦率。</li></ul></li><li>中国应对美国策略，合作进化，tit for tat新型大国关系。</li><li>中美安全领域互信重建困难。</li><li>近期拜登对华态度软化（背景是拜登上台七个月民意死亡交叉）<ul><li>过去四年一群成人哄老小孩玩，现在一个老头带大家玩</li><li>现在拜登懂政治且固执，手段足够，且拜登中期选举必输。</li></ul></li><li>目前美国政治形式拜登参议院50+1对50，众议院民主党领先8票。<ul><li>中期选举众议院执政党一定会丢掉一些票，平均丢27.5，众议员管钱，丢掉众议院意味着大规模财政开支基建计划全部完蛋。</li><li>大概率参议院众议院全丢，所以真正有效执政只有是前两年。</li><li>拜登意识到这一点已经放弃连任幻想，按照自己的想法实施，需要立自己的历史遗产。</li></ul></li><li>三年机会之窗，新型大国关系，平等不冲突<ul><li>现在中国也硬了，现在有机会窗口</li><li>民主党2024可能出大事，共和党重来，中美关系暴跌</li></ul></li></ul><h2 id="4-海南自贸港建设的前瞻和思考"><a href="#4-海南自贸港建设的前瞻和思考" class="headerlink" title="4. 海南自贸港建设的前瞻和思考"></a>4. 海南自贸港建设的前瞻和思考</h2><ul><li>冻结的人与人交流即将放开，海南可以争取放开的优先权，外国人进入中国的缓冲通道。</li><li>争取建立多个领馆。</li><li>高端服务业来海南。</li><li>推进金融开放。</li><li>吃海外人员回流福利。</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;翟东升 2021-10-28 于海南讲座。&lt;/p&gt;</summary>
    
    
    
    <category term="Economy &amp; Finance" scheme="https://superuier.github.io/categories/economy-finance/"/>
    
    
    <category term="翟东升" scheme="https://superuier.github.io/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>距离矩阵</title>
    <link href="https://superuier.github.io/machine-learning/distance-matrix/"/>
    <id>https://superuier.github.io/machine-learning/distance-matrix/</id>
    <published>2021-11-05T08:48:00.000Z</published>
    <updated>2021-11-05T08:48:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>在看 k-center 的时候发现自己对其距离矩阵的计算不是很清楚，于是在此记录。</p><a id="more"></a><h2 id="距离矩阵的计算及-Python-实现"><a href="#距离矩阵的计算及-Python-实现" class="headerlink" title="距离矩阵的计算及 Python 实现"></a>距离矩阵的计算及 Python 实现</h2><p>给定 $m\times n$ 矩阵 $X$, $X = [x_1, x_2,…,x_n]$，这里第 $i$ 列向量 $x_i$ 是 $m$ 维向量，任务是计算出一个 $n\times n$ 矩阵，使得：$D_{ij}=||x_i-x_j||^2$。</p><p>具体的，$D_{ij} = (x_i - x_j)^T(x_i-x_j)=x^T_ix_i-2x^T_ix_j+x^T_jx_j$。</p><p>用 Gram Matrix 表示，$D_{ij}=G_{ii}-2G_{ij}+G_{jj}$。</p><p>放在矩阵的尺度来看，$D = H + K -2G$。其中，$H_{ij} = G_{ii}, K_{ij} = G_{jj}$。</p><p>根据最后一个式子，计算的时候可以避免循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_dist_matrix</span>(<span class="params">X</span>):</span></span><br><span class="line">  m,n = X.shape</span><br><span class="line">  G = np.dot(X.T, X)</span><br><span class="line">  H = np.tile(np.diag(G), (n, <span class="number">1</span>)) <span class="comment"># Construct an array by repeating the number of times.</span></span><br><span class="line">  <span class="keyword">return</span> H + H.T - <span class="number">2</span>*G</span><br></pre></td></tr></table></figure><p>Reference:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/21341296">斯坦福CS231N课程笔记（三）-距离矩阵的计算方法</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;在看 k-center 的时候发现自己对其距离矩阵的计算不是很清楚，于是在此记录。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://superuier.github.io/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://superuier.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>原则读书笔记</title>
    <link href="https://superuier.github.io/reading-note/principles/"/>
    <id>https://superuier.github.io/reading-note/principles/</id>
    <published>2021-10-21T05:00:00.000Z</published>
    <updated>2021-10-21T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>《原则》  Ray Dalio<a id="more"></a></p><h2 id="极简简介"><a href="#极简简介" class="headerlink" title="极简简介"></a>极简简介</h2><p>桥水基金创始人 Ray Dalio 在本书中向我们介绍了其多年的人生经历，并由此引出他的主要观点——原则的建立和使用。书中极其详细的分条陈述了 Ray 的生活原则和工作原则。在展示原则之外，Ray 希望本书促使读者以最合适的方式发现改进反思自己的原则，这将有助于做出更好的决定，并让别人更好理解你。</p><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>这本书断断续续看了一个多月吧。是冲着 Ray 的名气买的，读完之后确实受用。受限于目前的阅历和社会分工，其实很多要点暂时还离我比较遥远，以后一定是会重读此书的。</p><ol><li>个人觉得这本书最厉害的一点不是给我们展现 Ray 的厉害的原则，而是在对他的原则进行阐述和解释过程中，教导我们原则的重要性以及如何构建自己的原则，这是最有价值的地方。</li><li>这本书更像是一本人生说明书或者指导手册，以一本工具书的形式，提出了大道理，也提出了很多解决方案。</li><li>我认为处于社会不同位置的人都能从此书中学到不少东西。首先是作为一个“自然人”对自己的管理，要用原则规范提升自己。其次是作为一个“社会人”在工作岗位中作为管理者或者被管理者，如何基于原则高效的沟通和行动。</li><li>本书也在很多阐述的地方不经意的提起一些很常见的思维误区，有利于大家反思自己的思维方式。</li><li>这本书不仅是 Ray 的人生准则，其实也包含很多他相信的“道理”，需要批判看待。</li></ol><h3 id="自己的感想"><a href="#自己的感想" class="headerlink" title="自己的感想"></a>自己的感想</h3><ol><li>原则构建<ol><li>要清楚的知道自己的原则。</li><li>清楚原则还不够，需要“知行合一”。如果存在矛盾，则需要记录，并改进原则。</li></ol></li><li>个人成长<ol><li>使自己“可信”，首先要把事情做成功。</li><li>不固执己见，客观看待自己以及其他人，否则会一次次的栽在自己或其他人的弱点上。</li><li>历史在不停地重现，只是可能不重现在你的身上。性价比高的做法是从他人身上学习，这就需要头脑开放。</li></ol></li><li>对待问题<ol><li>对问题准确的定义十分重要。</li><li>不能容忍问题，否则前功尽弃。</li><li>在团队工作中，Ray 有一个非常好的诊断问题的流程值得学习。包括但不限于问题是哪来的，有多严重，谁该负责，如何改进，甚至包括对问题的诊断应该进行到什么程度。我觉得这一部分其实可以单独写一篇博客来学习一下。</li></ol></li><li>团队管理<ol><li>在团队管理中，很需要对成员开放式思考进行构建。</li><li>分清建议和批评的区别。</li></ol></li></ol><h3 id="有趣的发现"><a href="#有趣的发现" class="headerlink" title="有趣的发现"></a>有趣的发现</h3><ol><li>历史真的是在不断重复。<ul><li>例如1982年墨西哥违约，债务危机，美联储增加货币供给，美国大通胀。但是经济没有崩溃，通胀率下降同时经济增长加速。这是因为资金撤出借债国，回流美国，美元升值，通缩压力。所以美联储可以在不加剧通胀的情况下降息。（我指的是资金回流美国这一点重复，例如2020新冠疫情。）</li></ul></li><li>Ray对王岐山有着极高的评价，两人似乎很熟，有空可以八卦一下。</li></ol><hr><h1 id="Ray-的原则"><a href="#Ray-的原则" class="headerlink" title="Ray 的原则"></a>Ray 的原则</h1><h3 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h3><ol><li>独立思考并决定：你想要什么？事实是什么？面对事实，你如何实现自己的愿望？请保持谦逊和心胸开阔，以便你能动用自己的最佳思维。</li><li>以可信度加权的方式做决定。</li><li>遵照原则做事。</li><li>以系统化的方式来做决策。考察影响你的那些事物的规律，从而理解其背后的因果关系，并学习有效应对这些事务的原则。</li></ol><h3 id="生活原则"><a href="#生活原则" class="headerlink" title="生活原则"></a>生活原则</h3><p>此处仅记录一些相对较大的条目：</p><ul><li><strong>拥抱现实，应对现实：</strong>  做一个超级现实的人； 真相（对现实的准确理解）是任何良好结果的根本依据； 做到头脑极度开放、极度透明； 观察自然，学习现实规律； 进化是生命最大的成就和回报； 理解自然提供的现实教训； 痛苦+反思=进步； 考虑后续与再后续的结果； 接受结果； 从更高的层次俯视机器。</li><li><strong>用五步流程实现你的人生愿望：</strong>  有明确的目标； 找出问题，并且不容忍问题； 诊断问题，找到问题的根源； 规划方案； 坚定的从头至尾执行方案； 谨记：如果你找到了解决方案，弱点是不重要的； 理解你和其他人的“意境地图”与谦逊性。</li><li><strong>做到头脑极度开放：</strong>  理解你的两大障碍； 奉行头脑极度开放； 领会并感激：深思熟虑的意见分歧； 和可信的、愿意表达分歧的人一起审视你的观点； 识别你应当注意的头脑封闭和头脑开放的不同迹象； 理解你如何做到头脑极度开放。</li><li><strong>理解人与人大不相同：</strong>  明白你与其他人的思维方式能带来的力量； 有意义的工作和有意义的人际关系不仅是我们做出的美好选择，而且是我们天生的生理需求； 理解大脑里的主要斗争，以及如何控制这些斗争； 认识自己和他人的特性； 无论你要实现什么目标，让合适的人各司其职以支持你的目标是成功的关键。</li><li><strong>学习如何有效决策：</strong>  要认识到：影响好决策的最大威胁是有害的情绪；决策是一个先了解后决定的两步流程； 综合分析眼前的形势； 综合分析变化中的形势； 高效地综合考虑各个层次； 综合分析现实、理解如何行动的最好工具是逻辑、理性和常识； 根据预期价值计算做决策； 比较更多信息带来的价值和不做决定造成的成本，决定优先顺序； 简化； 使用原则； 对你的决策进行可信度加权； 把你的原则转换成算法，让计算机和你一起决策； 在深刻理解人工智能之前不要过度信赖它。</li></ul><hr><h1 id="按节讨论-摘录"><a href="#按节讨论-摘录" class="headerlink" title="按节讨论/摘录"></a>按节讨论/摘录</h1><p>以下是大篇幅的摘抄，取自文章中的三个大章节。不能保证重要信息全记录。摘抄的原因是看到这些话的时候有一星半点的赞同或感触。此处的摘录比较糙，以后有空重读的话可以精炼消化一下。</p><h3 id="1-我的历程"><a href="#1-我的历程" class="headerlink" title="1. 我的历程"></a>1. 我的历程</h3><ul><li>不管我一生中取得了多大的成功，其主要原因都不是我知道多少事情，而是我知道在无知的情况下自己应该怎么做。</li><li>不幸的是，大多数的人并不能清楚地解释他们的原则。</li><li>尽管使用他人的原则不一定是一件坏事，但不假思索地采用他人的原则有可能将你置于风险之中。</li><li>“正确的失败”：痛苦的失败中获得教训。“错误的失败”：因为失败而被踢出局。</li><li>当政府决策者向你承诺他们不会允许货币贬值发生时，不要相信他们。</li><li>拥有有意义的工作和人际关系要比赚钱好得多。有意义的工作是一项我能全身心投入的使命；有意义的人际关系是指我既深深的关心对方，对方也深深的关心我。</li><li>把赚钱作为你的目标是没有意义的，因为金钱并没有固定的价值，金钱的价值来自他能买到的东西，但是金钱并不能买到一切。</li><li>要一个孩子是我迄今做过的最艰难的决定，因为当时的我显然不知道养孩子将是一种个什么样的经历，而且这个决定是不可撤回的。但事实证明这是我做出的最好的决定。</li><li>每当出现收益率曲线倒挂，对冲通胀的资产价格都会下跌，经济下滑。</li><li>以一国货币计价的债务，可以在该国政府的帮助下成功重组，而且在各国央行同时提供刺激时，通胀和通缩能够互相对冲。</li><li>我学到了一种很好的恐惧犯错的意识，这把我的思维定式从认为“我是对的”变成了问自己“我怎么知道我是对的”。</li><li>使人们相互对立的观点公开化，并对其进行分析，让我对人们的思考方式有了更多的了解。通常我们遵循我们的自然秉性做事时，考虑不到自身的弱点，走向失败，成功的人改变他们的做法，使他们能够继续利用优势，并弥补自身的不足，而不成功的人则不会这样做。</li><li>只有当你能承认甚至接受自身弱点是，你才能做出对自身有益的改变。</li><li>面对你都需要胆识看起来相互矛盾的东西时，耐心地做出选择。</li><li>“靠水晶球谋生的人注定要吃碎在地上的玻璃”：最重要的事不是预知未来，而是知道在每一个时间点上如何针对可获得的信息做出合理的回应。</li><li>确立一个“风险中性”的基准仓位，在进行慎重的冒险时偏离这个仓位。</li><li>我从来不愿仅仅因为投资产品会买的好就去设计他们，尤其是常规投资产品，我想要的只是进行市场交易，建立人际关系，设身处地地为我们的客户服务。</li><li>成熟意味着你可以放弃一些好的选择，从而追求更好的选择。</li><li>所有了不起的投资者和投资策略都是有弱点的，在弱点呈现时就对其失去信心是一种常见的错误，就像在其有效时对其过于迷恋一样。</li><li>拥有吧事情探究明白的能力，要比拥有某件事的具体知识更重要。</li><li>追求商业卓越和追求个人价值的实现，不一定是相互排斥的，而是可以相辅相成的。</li><li>一个管理者能够实现的最大成功就是能够阻止他人在没有你的情况下把事情做好。次好的情况是你自己能把事情做好。最糟糕的事连你自己都做不好。</li><li>我问他在火箭学方面有没有背景，他说没有。“我刚开始读这方面的书。”他说。这就是塑造者典型的思考和行为模式。</li><li>王岐山：“有能力的人居安思危。安然无忧的是愚人。假如冲突能在变得尖锐之前被解决的话，世界上就不会有英雄了。”</li><li>当我就权力制衡这个问题询问他时，他以尤里乌斯·凯撒推翻罗马元老院和共和国为例，说明确保任何人的权利都不能凌驾于制度之上是多么重要。</li><li>发现自己的性格，过与性格相适应的生活，才是最幸福的。</li></ul><h3 id="2-人生原则章节"><a href="#2-人生原则章节" class="headerlink" title="2. 人生原则章节"></a>2. 人生原则章节</h3><ul><li>创造伟大事物的人不是空想者，而是彻底地扎根于现实。</li><li>不要固守你对事物“应该”是什么样的看法，这将使你无法了解真实的情况。</li><li>通过快速试错以适应现实是无价的。</li><li>你的未来取决于你的视角。你在一生中取得什么样的成就，取决于你如何看待事物，以及你关心什么人、什么东西（你的家庭、社区、国家、人类、整个生态系统）。</li><li>没有痛苦就没有收获。</li><li>大多数人在痛苦时不愿反思，而一旦痛苦消失他们的注意力就会转移，所以他们难以通过反思得到教益。</li><li>不管在生活中遇到什么情况，如果你能负起责任，进行良好的决策，而不是抱怨你无法控制的东西，你将更有可能成功并找到幸福。</li><li>对人来说，最难做的事情之一是客观地在自身所处环境（即机器）中看待自身，从而成为机器的设计者和管理者。</li><li>大部分人犯下的最大错误是不客观看待自己以及其他人，这导致他们一次次的栽在自己或其他人的弱点上。</li><li>在你不擅长的领域请教擅长的其他人，这是一个你无论如何都应该培养的出色技能，这将帮你建立安全护栏，避免自己做错事。</li><li>不要混淆你的愿望和事实。</li><li>不要为自身形象而担心，只需要关心能不能实现你的目标。</li><li>不要把不好的结果归咎于任何人，从自己身上找原因。</li><li>5个步骤：目标、问题、诊断、方案、践行。你要成功就必须做好每一步，而且按照顺序一步一步来。这个过程是层层递进的：认真做好每一步，你将获得必须的信息，以便进行到下一步并将其做好。</li><li>你只需要知道什么时候需要这些技能，你能从哪里学到这些技能。</li><li>尽管你几乎可以得到你想要的任何东西，但不可能得到你想要的所有东西。</li><li>不要混淆目标和欲望（不要拿欲望当目标）。</li><li>不要把成功的装饰误认为成功本身。</li><li>在逆境中，你的目标应该是守住自己的成绩，尽量减少损失，或者直面不可挽回的损失。</li><li>承认弱点并不是像弱点投降，而是克服弱点的第一步。</li><li>要精准的找到问题所在。如果问题的原因是某种固有的弱点，你也许需要寻求他人的帮助，或者改变你扮演的角色。</li><li>不要把问题的某个原因误认为问题本身。</li><li>容忍问题和找不到问题一样。只要你没有战胜问题的意志，你就处于毫无希望的境地。你必须养成一种对任何性质的恶习都绝不容忍的习惯，无论其是重是轻</li><li>把你的方案写下来，让所有人都能看到，并对照方案执行。</li><li>建立清晰的衡量评估标准来确保你在严格执行方案。理想的做法是让其他人客观评估并报告你的进度。</li><li>每个人都至少有一个最大的弱点阻碍其成功，找到你的这个弱点并处理它。</li><li>成功有两条路：（1）自己拥有成功所需的要素，（2）从其他人那里得到成功所需的要素。</li><li>要有效行事，你就绝不能允许“想要自己正确”的需求压倒“找出真相”的需求。</li><li>很自然，人们无法理解自己看不到的东西。</li><li>当你住处某个人的心里弱点时，对方的反应通常像你指出他的身体缺陷一样感到不舒服。</li><li>出现意见分歧的各方通常始终坚信自己是对的，而且往往以彼此发怒而告终。</li><li>亚里士多德把悲剧定义为：人的致命缺陷导致的可怕结果。在我看来，自我意识和思维盲点这两大障碍就是人的致命缺陷。</li><li>听听其他人的观点并加以考虑，绝不会削弱你独立思考、自主决策的自由，只会让你在决策时有更宽广的视角。</li><li>要做到头脑开放，你必须高度接受自己错了的可能性，可以鼓励其他人告诉你错在哪里。</li><li>谨记，你是在寻找最好的答案，而不是你自己能得出的最好的答案。最好的答案不一定是你想出来的。</li><li>我定义的“可信”的人有两个特征：曾反复的在相关领域成功找到答案（三次），在被问责的情况下能对自己的观点做出很好的解释。</li><li>当两个人的观点截然相反时，很有可能一个人是错的。搞明白是不是你错了，对你有好处。深思熟虑的意见分歧中，你的目标并不是让对方相信你是对的，而是弄明白谁是对的，并决定应该怎么做。</li><li>你应该考虑和思索各种互相冲突的可能性，也应根据了解到的情况，随时迅速地调整自己的想法，接受可能正确的东西。一种检验你做的好不好的方式是，把和你有分歧的人的观点，向对方复述一遍，瑞过他觉得你服输的对，就说明你做的很好。</li><li>很多人都会和你产生分歧，但你不应该考虑所有人的观点。跟任何人都头脑开放不一定有好处，你应该花时间和你能找到的最可信的人探讨观点。</li><li>头脑封闭的人<ul><li>不喜欢看到自己的观点被挑战。他们通常会因无法说服对方而沮丧，而不是好奇对方为什么看法不同。</li><li>喜欢做陈述而不是提问</li><li>更关心是否被理解，而不是理解其他人</li><li>经常说“我可能错了，但这是我的观点”，暗示自己是开明的</li><li>阻挠他人发言</li><li>难以同时持有两种想法，使自己的观点独大</li><li>缺乏深刻的谦逊意识</li></ul></li><li>头脑开放的人<ul><li>更想了解为什么会出现分歧</li><li>真诚地相信自己可能是错的，提出真诚的问题</li><li>经常觉得有必要从对方的视角看待事物</li><li>知道何时做陈述，何时提问</li><li>喜欢倾听而不是发言，鼓励其他人表达观点</li><li>考虑其他人观点的同时保留自己深入思考的能力</li><li>时刻在心底担忧自己是错的</li></ul></li><li>假如你是一个头脑封闭的人，又在自己有盲点的领域形成了一种观点，结果可能是致命的。</li><li>重视证据，并鼓励其他人也这么做。</li><li>知道什么时候应当停止为自己的观点辩护，信任自己的决策程序。</li><li>如果你不了解人（包括你自己）的特性就对他们抱有期待，你肯定会遇到麻烦。</li><li>当我的潜意识给我想法和提示时，我不是马上按照其行动，而是先用我的理性意识去分析他们。</li><li>你能做的最重要的决定之一是决定问谁。</li><li>不要听到什么信什么，要区分事实和观点。</li><li>所有东西都是放在眼前看更大，所以你应该跳出去以看到全局，有时候可以过一段时间再做决定。</li><li>“当你问一个东西对不对而对方告诉你并不完全对时，那它大致是对的。”</li><li>不要做完美主义者。完美主义者花太多时间关注边缘性的微小因素，影响对重大因素的考虑。</li><li>用“基线以上”和“基线以下”来确定谈话位于哪一层。当一段分析混乱，令人迷惑时，通常是因为谈话者限于基线以下的细节之中，而没有重新把细节与要点联系起来。</li><li>知道什么之后不要去押注，和知道什么注值得押同样重要。</li><li>先把你的“必做之事”做完，再做你的“想做之事”。</li></ul><h2 id="3-工作原则章节"><a href="#3-工作原则章节" class="headerlink" title="3. 工作原则章节"></a>3. 工作原则章节</h2><ul><li>创意择优：1. 开诚布公的亮出你的观点。2. 针对分歧认真讨论。3. 遵循所形成的共识，消除过去的分歧。</li><li>为人要正直，也要求他人保持正直</li><li>若不想当面议论别人，背地里也不要说，要批评别人就当方面指出来。</li><li>大多数人做工作都希望出最少的里而赚尽可能多的钱。</li><li>学校里学习最好的学生可能往往是那些最不善于从错误里学习的人，因为他们已经习惯把做错题当成失败的代名词，而不是把犯错看成学习的机会。</li><li>不要纠结于一时的成败，要放眼于达成目标。不要纠结于“埋怨”还是“赞美”，而要专注于“准确”还是“不准确”。</li><li>没有人能客观的看待自己。</li><li>问题一般源自两个主要原因：简单的误解和根本上存在分歧。求取同步就是以开放而自信的心态修正双方立场的过程。</li><li>知道怎样求取共识和掌控分歧<ul><li>把可能的分歧摆到桌面上</li><li>区别苍白的抱怨和有助于改进工作的诉求</li><li>要记住每个故事都有另一面</li></ul></li><li>保持开放的心态，同时也要坚定果断<ul><li>区别心态开放和封闭的人</li><li>远离心态封闭的人，不管他们知道多少，心态封闭的人都会浪费你的世界。如果你必须与他们打交道，要注意除非他们变得开明，否则无任何裨益。</li><li>提防那些羞于承认自己无所不知的人。他们可能更关注外在形象，而不是达成目标。</li><li>确保工作负责人以开放的心态对待问题和他人的意见。</li><li>意识到求取共识是双向的责任。通常沟通困难在于人们的思维方式不一样。<ul><li>有一些简单的技巧会很有用，比如重复以便你刚听到的别人的观点，确保你理解正确。</li><li>假设你自己或者是没有沟通好，或是没听清，为不实先去责怪对方。要吸收自己沟通不理的教训，避免再犯。</li></ul></li><li>实质重于形式：问题重于沟通方式。</li><li>自己要通情达理，也期待别人通情达理。</li><li>其建议、提问题与批评是不一样的，别混淆<ul><li>提建议并未下结论说有错误，只是想确保考虑了风险，有没有疏忽（并不是真的忽略）</li><li>有人把建设性问题当成职责，反弹强烈，这是不对的。</li></ul></li></ul></li><li>如果由你主持会议，应把握好会话<ul><li>明确主持人和会议的服务对象，如果没有明确的主持人，可能会陷入丧失方向和低效的境地。</li><li>表达清晰，以免造成困惑。</li><li>根据目标和优先次序决定采用什么样的沟通方式。</li><li>谨防“跑题”，列出议程让大家看到进展。</li><li>坚持对话的逻辑性。</li><li>不要因集体决策而丧失个人责任。对个人职责的分派要十分明确。</li><li>你必须让人用两分钟不受打扰地解释自己观点，再插话表达自己意见。</li><li>当心讲起话来不容置疑的“快嘴王”，你的责任是讲清楚事情，有一点没讲清楚都不要继续往下降。作为主持人可以说“抱歉我比较迟钝，希望你慢点说”</li><li>让对话慎始善终，进行总结，结束讨论。同时，人们不必对任何事情都意见一致。</li><li>运用沟通手段，分出优先次序。</li></ul></li><li>3-5人的效率高于20人。边际效益递减。</li><li>珍惜志同道合者，既然有人在你最重要的方面价值观相同，也与你有实践价值观的相同做法，就要确保与这些人为伍。</li><li>如果你发现自己无法调和相互间的主要分歧—尤其是价值观层面的—要考虑是否值得维持这种关系。</li><li>最佳决策应该是创意择优中按观点的可信度高低得出来的。有可信度的观点来自多次成功解决了相关问题的人，能够有逻辑地解释结论背后因果关系的人。</li><li>如果你自己无法成功完成某件事，就不要想着知道别人如何完成。</li><li>关注可信度最高，与你观点不一致的人，尽量理解其推理过程。<ul><li>若某人并无经验，但是所讲道理符合逻辑且可以经受压力测试，一定要试一试。</li><li>关注推理过程而非结论。</li><li>没经验的人也不乏好点子，不会限制在过去的套路。</li></ul></li><li>考虑你要扮演老师、学生、同事中的哪个角色？说教、提问还是辩论？<ul><li>学生理解老师比老师理解学生更重要。</li></ul></li><li>要了解人们提出意见的过程和逻辑<ul><li>要仔细考虑向谁提问，问可信度强，准备好的人。如果自己可信度不强，不要分享自己的观点。</li><li>让每个人都可以肆意评论其他人的观点，此举低效且浪费时间。</li><li>梳理员工工作记录。</li></ul></li><li>每个人都有权利和义务去设法了解重要的事情。</li><li>要关注决策机制是否公允，而非是否如你自己所愿。</li><li>相互达成协议时不能忽略原则。</li><li>不要吧发牢骚、提建议、公开辩论的权力与决策权混淆</li><li>不要对重大分歧不闻不问<ul><li>别被小事烦扰</li><li>不要被分歧束缚：提交上级、或者投票</li></ul></li><li>一旦做出决定，所有人必须服从，即便有不同意见。</li><li>在一家健康的机构中，应该是员工与低层次的自我进行竞争，而不是员工与员工互相竞争。</li><li>你最重要的决策是选好工作的责任人<ul><li>最重要的责任人是在高层负责订立目标、规划成果和组织实施的人</li><li>负最终责任的人应是对行为后果承担责任的人。</li><li>确保每个人都有上级领导，要有人对他问责。</li></ul></li><li>学习成绩不能充分证明这个人是否具备你想要的价值观和能力<ul><li>评估常识、眼界、创造力、决事能力，学习成绩价值有限。</li></ul></li><li>警惕不切实际的理想主义者</li><li>考虑薪酬时，要提供稳定性，也要让人看到机会<ul><li>依人发薪，而不是依工作岗位发薪</li><li>想着把蛋糕做大，而不是给自己把蛋糕切大。</li></ul></li><li>准确评价人，不做好好先生。</li><li>对人的观察不要讳莫如深。开诚布公的考察他们。</li><li>评估人时，你可能犯的两个最大错误是：对自己的评估过于自信，无法取得共识。</li><li>换岗是为了人尽其才，有利于整个团队。</li><li>不断把结果和你的目标进行对照。制定量化评价工具。</li><li>应对每个问题的手段都要服务于两种目的：让你与目标更为接近，能够对机器进行培训和测试。</li><li>如果出现问题，要在两个层面进行讨论：机器层面为什么，案例层面怎么办。</li><li>管理者必须确保自己负责的领域运转有效。他可以通过以下方式：把员工管理好；或者下沉去做本不该自己做但下属做不好的工作；把管理不好的领域提交给上级管理。</li><li>出售管理者的标志是他不必亲自做任何事。管理者应视自己陷入细枝末节为不良信号。</li><li>了解员工及其工作的动力，因为人是你最重要的资源。</li><li>明确职责。记住谁付什么责任，防止角色错位。如果问题出乎你的意料，可能是因为你远离了你的下属和工作流程或者你对下属和留存可能导致的不同后果缺乏足够认识。</li><li>让问责过程透明，而非私下问责。同时欢迎别人问着你，因为没有人能客观看待自己。</li><li>像公司的拥有者那样思考，要求你的同事也这样做。</li><li>不要担心你的员工是不是喜欢你，不要让他们告诉你如何做事，你要操心的是尽可能的做出最佳决策，因为不管你做什么很多人都会说你做得不对。</li><li>不要发号施令让别人服从你，要努力为人所理解，并理解他人，以达成共识。</li><li>当心那些混淆目标和任务的人，因为如果他们分不清楚就不能信任他们并给他们委派职责。</li><li>在无法充分完成时，这时将问题提交给上级解决，把问题提交给上级并不意味着失败而是一种责任。</li><li>在分析问题时要非常具体不要泛泛而谈，不要用我们他们这种不指名道姓的说法，掩盖个人责任。每个人都必须有一位有可信度的热情，高标准的人来监督。</li><li>每个人都必须有一位有可信度的，奉行高标准的人来监督。</li><li>不要仅盯着你自己的工作，还要关注如果你不在场工作会如何展开？</li><li>如果某些职位不是全职的，且需要高度专业化的知识，我宁愿交给顾问或者外部人。</li><li>描绘一幅金字塔形的组织架构，图任何两条有塔顶向下连接塔底的线不应产生交叉。遇到跨部门或附属部门的问题是让金字塔交汇点上的人处理。 </li><li>保持适当的监控让谎言没有可乘之机。</li><li>要不断思考如何产生以小搏大的杠杆效应，我一般在工作中运用50:1的杠杆，意思是说，每当我用一个小时与下属讨论工作，他们都要花大约50个小时的推进相关项目。</li><li>几乎做每件事所花费的时间和资金都比你预期的要多。</li><li>给人员分配任务是最好把各项任务记在检查清单上。完成的任务划掉，这可以做任务的提醒也可以做任务的确认，但是每个人不是只是完成在检查清单上的任务。</li><li>为了促进真正的行为改变，必须内化学习或养成习惯。</li><li>把原则阐述清楚，运用各种工具和行为准则来推进实施，形成信任公平的氛围，使任何结论都可以通过跟踪其背后的逻辑和数据来加以评估。</li><li>为了取得成功，所有机构都必须建立制衡机制。要确保公司里没有任何人比体系更强大，也没有任何人重要到不可替代。</li><li>在所有决策方法中，构建创意择优是最佳的方法。让创意择优发挥作用，人们需要做三件事：坦承自己最诚实的想法；让大家公开讨论理性的表达分歧，以便大家进行高质量的辩论，拓展思路，尽量形成最优的集体决策；用创意择优来处理所有不同意见。</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;《原则》  Ray Dalio</summary>
    
    
    
    <category term="Reading Note" scheme="https://superuier.github.io/categories/reading-note/"/>
    
    
    <category term="Ray-Dalio" scheme="https://superuier.github.io/tags/Ray-Dalio/"/>
    
  </entry>
  
  <entry>
    <title>约束满足问题（CSPs）</title>
    <link href="https://superuier.github.io/artificial-intelligence/ai-csp/"/>
    <id>https://superuier.github.io/artificial-intelligence/ai-csp/</id>
    <published>2021-10-19T07:50:00.000Z</published>
    <updated>2021-10-19T07:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能中的约束满足问题（Constraint Satisfaction Problems 问题）学习笔记。</p><a id="more"></a><h1 id="约束满足问题"><a href="#约束满足问题" class="headerlink" title="约束满足问题"></a>约束满足问题</h1><p>约束满足问题的目标是在一定的约束下，寻找符合条件的状态。这种问题在生活中比较常见，以大学排课为例，已知教授的授课可以授课的时间，寻求满足所有教授时间的排课课程表。常见的一些约束满足问题有：</p><ul><li>八皇后问题</li><li>图着色问题</li><li>填字游戏</li><li>数独</li></ul><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>CSPs 包含以下三个要素：</p><ul><li>A set of variables（变量）, $X={X_{1},\ldots ,X_{n}}$</li><li>A set of domains （值域） for each variable: $D={D_{1},\ldots ,D_{n}}$</li><li>A set of constraints $C={C_{1},\ldots ,C_{m}}$ （限制条件） that specify allowable combinations of values. Every constraint $C_{j}\in C$ is in turn a pair $\langle t_{j},R_{j}\rangle$ , where $t_{j}\subset X$ is a subset of k variables and $R_{j}$ is a k-ary relation (among k variables) on the corresponding subset of domains $D_{j}$.</li></ul><p>问题的状态由对部分或者全部变量的定值（assignment）来确定：</p><ul><li>如果定值不违反任何的限制条件，我们说他是无矛盾的（consistent）</li><li>如果定值包含了所有的变数，我们说他是完备的（complete）</li><li>如果定值是无矛盾的且完备的，我们说这个定值是一个解（solution），这样的定值就是 CSP 的解。</li></ul><p>一个图着色问题的例子：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-csp/map-color.png" class=""></div><p>一个八皇后问题的例子：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-csp/eight-queen.png" class=""></div><p>一般来说 CSPs 使用的都是绝对约束，如果是非绝对的约束（偏好性），这样的问题称为约束优化问题（COP），在此不做讨论。</p><h1 id="求解-CSPs"><a href="#求解-CSPs" class="headerlink" title="求解 CSPs"></a>求解 CSPs</h1><h2 id="CSPs-形式化的优点"><a href="#CSPs-形式化的优点" class="headerlink" title="CSPs 形式化的优点"></a>CSPs 形式化的优点</h2><ol><li>快速消减庞大的搜索空间</li><li>发现某部分不是解迅速丢弃，直观看到哪一部分变量赋值违反约束。</li><li>CSP 具有可交换性（commutative）</li></ol><h2 id="CSPs-中的局部相容性（consistency）"><a href="#CSPs-中的局部相容性（consistency）" class="headerlink" title="CSPs 中的局部相容性（consistency）"></a>CSPs 中的局部相容性（consistency）</h2><p>在 CSPs 中，算法可以<strong>搜索</strong>，也可以做一种称作约束传播的<strong>推理</strong>。推理的目的是用约束减小一个变量的合法取值范围。可以把推理作为搜索前的预处理步骤。核心思想是增强局部相容性，使不相容的结点取值被删除。</p><ul><li>节点相容（Node-consistency）：来自节点本身的一元约束</li><li>弧相容（Arc-consistency）：某变量所有取值满足该变量所有的二元约束。<ul><li>最流行的算法是 AC-3，维护一个弧相容队列。<ul><li>从队列弹出一条弧，使其一个节点弧相容，如果其值域无变化，则处理下一条弧。</li><li>如果其值域发生变化，那么每个指向这个节点的弧必须重新插入队列准备检验。</li></ul></li></ul></li><li>路径相容（Path-consistency）：通过观察变量得到隐式约束并以此来加强二元约束。<ul><li>比如说有三个连接节点，却只有两种颜色。</li><li>所有的 n-ary 约束都可以转换为 binary 约束。</li></ul></li></ul><h2 id="具体解法：回溯搜索"><a href="#具体解法：回溯搜索" class="headerlink" title="具体解法：回溯搜索"></a>具体解法：回溯搜索</h2><p>仍然使用搜索来求解，一般来说使用 Backtracking Search（BTS）回溯搜索。用于深度优先之中，每次为一个变量选择一个赋值，当没有合法的值时就回溯。由于可交换性，我们只用搜索组合而不是排列，所以叶节点个数至多为$d^n$个（不回溯的情况）。</p><p>在回溯搜索中，也需要考虑如下问题来对搜索进行改进：</p><ul><li>下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？</li><li>每步搜索应该进行怎样的推理？是否能预见失败？</li><li>当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？</li></ul><h3 id="1-下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？"><a href="#1-下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？" class="headerlink" title="1. 下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？"></a>1. 下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？</h3><p>选取变量：</p><ul><li>最少剩余值启发式 Minimum Remaining Value (MRV)，选择合法取值最少的变量赋值。这样通过早期有效剪枝有助于最小化节点数。</li><li>对于第一个节点而言，最小剩余值相同，应该选用度启发式，选择与其他未赋值变量约束最多的变量来试图降低未来的分支因子。</li></ul><p>选取赋值：</p><ul><li>最小约束值 Least Constraining Value (LCV)，试图为剩余变量赋值留下最大的空间。这里只需要找到一个解，所以优先考虑最可能的值。</li></ul><h3 id="2-每步搜索应该进行怎样的推理？是否能预见失败？"><a href="#2-每步搜索应该进行怎样的推理？是否能预见失败？" class="headerlink" title="2. 每步搜索应该进行怎样的推理？是否能预见失败？"></a>2. 每步搜索应该进行怎样的推理？是否能预见失败？</h3><p>搜索和推理应当交替进行。推理的目的是减小值域，减小搜索空间。当我们决定给某个变量某个值时，都有机会推理其邻接变量的值域空间。</p><ul><li>最简单的形式是向前检验 Forward Checking（FC）。跟踪维护所有为选取变量的可能取值，当任何一个变量没有合法取值时结束。联合使用 MRV 和前向检验，很多问题的搜索将更有效。但是前向检验只使当前变量弧相容，却不向前看使其他变量弧相容。</li><li>MAC 维护弧相容，递归传播约束。对一个变量赋值后，使用 AC-3，从临接的未赋值变量开始进行约束传播，如果值域为空，则调用失败立即回溯。</li></ul><h3 id="3-当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？"><a href="#3-当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？" class="headerlink" title="3. 当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？"></a>3. 当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？</h3><ul><li>简单的时序回溯。退回到上一个变量</li><li>冲突指导的回溯。退回到可能解决当前问题的变量（因为上一个变量可能无力于解决当前冲突）。构建一个冲突集，回溯到冲突集中时间最近的赋值。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能中的约束满足问题（Constraint Satisfaction Problems 问题）学习笔记。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://superuier.github.io/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://superuier.github.io/tags/AI/"/>
    
    <category term="search" scheme="https://superuier.github.io/tags/search/"/>
    
  </entry>
  
  <entry>
    <title>对抗搜索问题和 Minimax 算法</title>
    <link href="https://superuier.github.io/artificial-intelligence/ai-adversarial-search/"/>
    <id>https://superuier.github.io/artificial-intelligence/ai-adversarial-search/</id>
    <published>2021-10-12T03:30:00.000Z</published>
    <updated>2021-10-12T03:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能中的对抗搜索学习笔记。</p><a id="more"></a><h1 id="对抗搜索问题"><a href="#对抗搜索问题" class="headerlink" title="对抗搜索问题"></a>对抗搜索问题</h1><p>对抗搜索其实可以看作游戏场景，存在一个我们不能控制的对手。相比于搜索，我们不是要找一个值或一系列序列，而是要找一个策略（strategy/policy）来对对手的行为进行反馈。而游戏是人工智能中一个比较难的方向，它可以分为以下几类。</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-adversarial-search/game-types.png" class=""></div><h2 id="正式化-Formalization"><a href="#正式化-Formalization" class="headerlink" title="正式化 Formalization"></a>正式化 Formalization</h2><p>将对抗搜索的问题抽象化，正式化，我们会得到以下要素：</p><ul><li>$s$: state, $s \in S$.</li><li>$p$: $p \in P(s)$, defines which <strong>player</strong> has the move in state $s$. Usually taking turns.</li><li>$a$: <strong>action</strong>, $a \in A(s)$, returns the set of legal moves in $s$.</li><li>$T(s,a)$: $S \times A \rightarrow S$, <strong>transition function</strong>, defines the result of a move.</li><li>$u(s,p)$: <strong>utility function</strong> or objective function for a game that ends in terminal state s for player p. It describes the earning at the end of the game.</li><li>$\pi(s): S  \rightarrow A$, <strong>strategy</strong>, output an action given a state.</li></ul><h1 id="Minimax-算法"><a href="#Minimax-算法" class="headerlink" title="Minimax 算法"></a>Minimax 算法</h1><p>这里很多内容参考了 <a href="https://yzhang-gh.github.io/notes/others/minimax.html#问题定义">Yu Zhang 的笔记</a>。</p><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>这里不再是广义的游戏背景，一般来说做出了一些限制。Minimax 算法常用于<strong>「有限状态，零和，完全信息，两个玩家（Max/Min）」</strong>博弈问题，比如棋类。</p><h2 id="算法概要"><a href="#算法概要" class="headerlink" title="算法概要"></a>算法概要</h2><p>存在两个玩家，Max（希望最大化自己的收益），Min（希望最小化 Max 的收益）。从初始状态开始，通过两个玩家选用不同动作交替操作，可以形成一个树，树中的每一个节点都代表一个状态$s$。我们的目标是找到一个给 Max 的最优策略，使在游戏结束时的状态拥有最大的效用函数，这是一个在树中搜索的问题。</p><p>在 minimax 算法中，我们认为每一个状态 $s$ 都拥有一个 minimax 值（递归得到）。这个值表示从当前状态 s 开始，<strong>双方均采取最优策略直至游戏结束</strong>时玩家 Max 的<strong>效用值</strong>具体到计算过程中，如果状态为终止状态，那么它就是当下的效用值；如果是中间状态，则是子状态 minimax 值中的（最大值，Max 操作，目的最有利于自己；最小值，Min 操作，目的最不利于 Max）：</p><script type="math/tex; mode=display">\text{minimax}(s)=\left\{     \begin{aligned}     &u(s, \text{Max})                   & & \text{if GameOver}(s) \\     &\max_{a \in A(s)}\text{minimax}(T(s,a)) & & \text{if Max's turn}\\     &\min_{a \in A(s)}\text{minimax}(T(s,a)) & & \text{if Min's turn}    \end{aligned} \right.</script><p>对于算法的解释</p><ul><li>对于游戏树的 DFS 搜索，从终点回推过程节点的 minimax 值。</li><li>最优/最终的节点可以出现于任何深度。</li><li>在 Max 使用最优策略的情况下：<ul><li>如果对手 Min 使用最优策略，那么一个节点只要计算出了 minimax 值，就已经看到了游戏的结局（效用值）。</li><li>如果对手 Min 不使用最优策略，那么 Max 的最终效用只会更高。</li></ul></li></ul><p>一个简单的例子，自下而上的递归推导。</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-adversarial-search/minimax-example.png" class=""></div><h2 id="Alpha-Beta-剪枝"><a href="#Alpha-Beta-剪枝" class="headerlink" title="Alpha-Beta 剪枝"></a>Alpha-Beta 剪枝</h2><p>假设 game tree 的深度为 $m$，每个节点有 $b$ 种走法，则该算法的时间复杂度为$O(b^m)$，在实际情况中是不现实的。相应的，其空间复杂度为$O(bm)$。哪怕是在最简单的一字棋（tic-tac-toe）游戏中，这个数量级也相对较大：存在 $9!=362880$ 个终止节点。</p><p>所以我们必须要进行一定的手段来对搜索空间进行限制，来保证搜索的实际可行性。具体的思路是，我们其实不必要遍历所有的点，因为很多点是必然不会经历/不需要考虑的。例如下图，虚线框的值不必考虑，因为 C 节点的 minimax 值必然小于 2（Min 只会选取最小节点），所以在 A 节点上选取是必然不会考虑 C 节点。</p><div style="width:100%; margin:auto"><img src="/artificial-intelligence/ai-adversarial-search/ab-example.png" class=""></div><p>所以，在此算法上：</p><ul><li>对于每一个节点，我们维护一组上下限 $[\alpha, \beta]$，表示在当前节点 Minimax 值的范围，初始设置为 $[-\infty, \infty]$。[Max 至少能实现的收益, Max 最多能实现的收益]</li><li>对于一个 Max 节点 $s_{max}$，我们向上更新他的 $\alpha$ 值，将其子节点 $m$ 的 $\beta(m)$ 值与当前的 $\alpha$ 做比较：<ul><li>如果 $\beta(m) \leq \alpha$，则后续分支可以剪掉（直接 return）。<ul><li>若 $m$ 的一个子节点 $n$ 上，$\beta(n) \leq \alpha$，则 $\beta(m)$ 必然小于 $\alpha$。</li></ul></li><li>对于 $\beta(m) &gt; \alpha$，则需要更新 $s_{min}$ 上的 $\alpha$ 值。</li></ul></li><li>对于一个 Min 节点 $s_{min}$，我们向下更新他的 $\beta$ 值，将其子节点 $m$ 的 $\alpha(m)$ 值与当前的 $\beta$ 做比较<ul><li>如果 $\alpha(m) \geq \beta$，则后续分支可以剪掉（直接 return）。<ul><li>若 $m$ 的一个子节点 $n$ 上，$\alpha(n) \geq \beta$，则 $\alpha(m)$ 必然不小于 $\beta$。</li></ul></li><li>对于 $\alpha(m) \lt \beta$，则需要更新 $s_{min}$ 上的 $\beta$ 值。</li></ul></li><li>对于叶节点 $k$， $\alpha(k) = \beta(k) = \text{utility}(k, p)$</li></ul><blockquote><p><strong>TIP</strong></p><p>即使使用了 alpha-beta 剪枝，在实际中也基本不可能搜索到游戏结束，这就需要使用启发式评估函数 (heuristic evaluation function) 来代替游戏结束时的效用函数，来对一些较深层的状态进行评估，这里不再展开。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能中的对抗搜索学习笔记。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://superuier.github.io/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://superuier.github.io/tags/AI/"/>
    
    <category term="search" scheme="https://superuier.github.io/tags/search/"/>
    
  </entry>
  
  <entry>
    <title>排序算法</title>
    <link href="https://superuier.github.io/computer-science-engineering/sorting/"/>
    <id>https://superuier.github.io/computer-science-engineering/sorting/</id>
    <published>2021-10-08T11:30:00.000Z</published>
    <updated>2021-10-08T11:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>最近看了一篇比较有趣的文章<a href="https://mp.weixin.qq.com/s/_N_vbYEisNJ7yddaRjgZdQ">《比冒泡算法还简单的排序算法：看起来满是bug的程序，居然是对的》</a>，看了半天才看懂。发现自己其实已经不太记得各种排序方法了，此处做一个复习总结。（给自己看的笔记也不会很详细，毕竟大部分也都实现过，这里主要记录intuition。）主要参考了这篇知乎的博文，<a href="https://zhuanlan.zhihu.com/p/335048580">《八大经典排序算法详解》</a>。</p><a id="more"></a><h2 id="鸽巢排序"><a href="#鸽巢排序" class="headerlink" title="鸽巢排序"></a>鸽巢排序</h2><ul><li>基本思想：空间换时间，建立一个足够长的数组，按照数值的大小放到相应的位置，最后遍历删除空位置。</li><li>时间复杂度为 O(n)。但是如果需要排序的数中有特别大的，则数组需要建立的特别大，不方便使用。</li></ul><h2 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h2><p>上述鸽巢排序可以看作一种极端的（桶数很多的）桶排序：</p><ul><li>基本思想：空间换时间，将待排序的序列分到若干个桶中（桶具有顺序），每个桶内的元素再进行基于比较的排序。</li><li>时间复杂度为 O(k+n)，k 为最大值。</li><li>是稳定的排序方法。</li><li>限制比较多：只能int，空间消耗大，只有对于均匀数列效果好</li></ul><h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><ul><li>基本思想：将待插入样本按其值的大小插入前面已经排序的文件中适当位置上，直到全部插入完为止。</li><li>时间复杂度为 O(n^2)。</li><li>是稳定的排序方法。</li></ul><h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h2><ul><li>基本思想：在待排序的元素任取一个元素作为基准(通常选第一个元素，称为基准元素），将待排序的元素进行分块，比基准元素大的元素移动到基准元素的右侧，比基准元素小的移动到作左侧，从而一趟排序过程，就可以锁定基准元素的最终位置，对左右两个分块重复以上步骤直到所有元素都是有序的（递归过程）。</li><li>快速排序平均时间复杂度为 O(nlogn)，最坏情况为 O(n^2)，n越大，速度越快。</li><li>不是稳定的排序算法。</li></ul><h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><ul><li>基本思想：每一次从待排序的数据元素中选出最小的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。</li><li>时间复杂度 O(n^2)。</li><li>选择排序是不稳定的排序方法。（存在不相邻元素的互换）</li></ul><h2 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h2><ul><li>基本思想：设置一定的步长序列 [a,b,c,1]（最后一个需要为1），然后根据步长来构建分组（以 a 为例，每个分组中都是相隔为a的一组样本：i, i+a, i+2a…），然后对分组里的样本进行排序，之后合并为新序列。a 步长进行完之后，在新的序列上使用下一个步长 b 得到下一个序列，如此往复。最后一个步长需要为1。</li><li>时间复杂度 平均时间 O(nlogn) 最差时间O(n^2)</li><li>是不稳定的排序方法。</li></ul><h2 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h2><ul><li>基本思想：利用最大堆或最小堆，先将所有值放入堆中储存，再一一取出，则排好序。</li><li>堆排序是一种选择排序,其时间复杂度为 O(nlogn)。堆排序是不稳定的</li></ul><h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><ul><li>基本思想：将待排序的数组分成前后两个部分，再递归的将前半部分数据和后半部分的数据各自归并排序，得到的两部分数据，然后使用merge合并算法将两部分数据合并到一起。</li><li>最好、最坏和平均时间复杂度都是 O(nlogn)，空间复杂度是 O(n)。</li><li>是稳定的排序算法。</li></ul><h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><ul><li>基本思想：持续比较相邻的元素。如果第一个比第二个大，就交换他们两个。直到没有任何一对数字需要比较。</li><li>冒泡排序最好的时间复杂度为 O(n)，冒泡排序的最坏时间复杂度为 O(n^2)，因为循环轮数不确定。因此冒泡排序总的平均时间复杂度为 O(n^2)。</li><li>算法适用于少量数据的排序。</li><li>是稳定的排序方法。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i = <span class="number">1</span> to n <span class="keyword">do</span></span><br><span class="line"><span class="keyword">for</span> j = i + <span class="number">1</span> to n <span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> A[i] &gt; A[j] then</span><br><span class="line">swap A[i] <span class="keyword">and</span> A[j]</span><br></pre></td></tr></table></figure><h2 id="Bug-满满的“数组升序排序”"><a href="#Bug-满满的“数组升序排序”" class="headerlink" title="Bug 满满的“数组升序排序”"></a>Bug 满满的“数组升序排序”</h2><p>这个方法第一次见于<a href="https://mp.weixin.qq.com/s/_N_vbYEisNJ7yddaRjgZdQ">《比冒泡算法还简单的排序算法：看起来满是bug的程序，居然是对的》</a>。伪代码如下。这个代码相对于冒泡排序看起来有两个地方写错了，一个是判断时的小于号，一个是第二个 for 循环中的开始项。但是这个算法竟然可以惊讶地得到正确的结果。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i = <span class="number">1</span> to n <span class="keyword">do</span></span><br><span class="line"><span class="keyword">for</span> j = <span class="number">1</span> to n <span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> A[i] &lt; A[j] then</span><br><span class="line">swap A[i] <span class="keyword">and</span> A[j]</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;最近看了一篇比较有趣的文章
&lt;a href=&quot;https://mp.weixin.qq.com/s/_N_vbYEisNJ7yddaRjgZdQ&quot;&gt;《比冒泡算法还简单的排序算法：看起来满是bug的程序，居然是对的》&lt;/a&gt;，看了半天才看懂。
发现自己其实已经不太记得各种排序方法了，此处做一个复习总结。
（给自己看的笔记也不会很详细，毕竟大部分也都实现过，这里主要记录intuition。）
主要参考了这篇知乎的博文，&lt;a href=&quot;https://zhuanlan.zhihu.com/p/335048580&quot;&gt;《八大经典排序算法详解》&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Science and Engineering" scheme="https://superuier.github.io/categories/computer-science-engineering/"/>
    
    
    <category term="sorting" scheme="https://superuier.github.io/tags/sorting/"/>
    
    <category term="algorithms" scheme="https://superuier.github.io/tags/algorithms/"/>
    
  </entry>
  
  <entry>
    <title>Contrastive Learning 学习记录</title>
    <link href="https://superuier.github.io/machine-learning/contrastive-learning/"/>
    <id>https://superuier.github.io/machine-learning/contrastive-learning/</id>
    <published>2021-09-30T06:02:00.000Z</published>
    <updated>2021-09-30T06:02:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>之前总是会断断续续看到一些自监督学习的工作/想法。同时也总是看到对比学习这个词，不明所以，所以对此进行一个简单的学习。本文可以看作对<a href="https://zhuanlan.zhihu.com/p/367290573">《对比学习（Contrastive Learning）:研究进展精要》</a>这片知乎文章的阅读笔记。</p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>自监督学习有着从无标记样本中学习表征的能力。比较出名的是自然语言模型 Bert 的预训练。对比学习是一种自监督学习的方式，主要用在图像领域。</p><p>目前，对比学习貌似处于<strong>无明确定义、有指导原则</strong>的状态，它的指导原则是：通过自动构造相似实例和不相似实例，要求习得一个表示学习模型，通过这个模型，使得相似的实例在投影空间中比较接近，而不相似的实例在投影空间中距离比较远。</p><p>对比学习的关键点：</p><ul><li>如何构造相似实例，以及不相似实例</li><li>如何构造能够遵循上述指导原则的表示学习模型结构</li><li>以及如何防止模型坍塌(Model Collapse)</li></ul><p>目前的对比学习方法分类</p><ul><li>基于负例的对比学习方法</li><li>基于对比聚类的方法</li><li>基于不对称网络结构的方法</li><li>基于冗余消除损失函数的方法</li></ul><h1 id="几种分类"><a href="#几种分类" class="headerlink" title="几种分类"></a>几种分类</h1><h2 id="基于负例：SimCLR"><a href="#基于负例：SimCLR" class="headerlink" title="基于负例：SimCLR"></a>基于负例：SimCLR</h2><p>首先我们需要构建正例和负例。负例的话，同一个 batch 的其他样本可以当作此样本的负例。正例的话一般通过图像增强来实现，如下图所示。</p><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/augmentation.jpg" class=""></div><p>模型层面，SimCLR 具有上下两个 Branch，通过学到的表征来计算 Similarity。需要注意的是，相似度计算需要正则化。</p><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/SimCLR.jpg" class=""></div><p>其中的相似度损失使用 infoNCE，其中$τ$为温度参数：</p><script type="math/tex; mode=display">L_i=-log (exp(S(z_i,z_i^+ )⁄τ)/∑_{(j=0)}^Kexp(S(z_i,z_j )⁄τ) )</script><p>温度接近0的时候，该损失基本退化为 Triplet（对很相似样本的区分）。</p><p>为什么 SimCLR 投影操作要做两次非线性变换，而不是直接在Encoder后，只经过一次变换？</p><ul><li>在 Moco 中并没有 Projector，在 SimCLR 加入 projector 后效果提升明显。</li><li>SimCLR 论文中表示，Encoder后的特征表示，会有更多包含图像增强信息在内的细节特征，而这些细节信息经过Projector后，很多被过滤掉了。</li></ul><h2 id="基于负例：Moco-V2"><a href="#基于负例：Moco-V2" class="headerlink" title="基于负例：Moco V2"></a>基于负例：Moco V2</h2><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/moco-v2.jpg" class=""></div><p>其有以下特点：</p><ul><li>相比于 Moco 增加了 projector。</li><li>相比于 SimCLR，从整个未标记数据集选取负例。</li><li>上分枝反向传播，下分枝使用移动平均机制更新参数。</li></ul><h2 id="基于对比聚类：SwAV"><a href="#基于对比聚类：SwAV" class="headerlink" title="基于对比聚类：SwAV"></a>基于对比聚类：SwAV</h2><p>通过上分枝预测下分枝打出的类别伪标记（由聚类得来），同时也要用下分枝预测上分枝。具体损失函数采用 $z_i$ 和聚类 Prototype 中每个类中心向量的交叉熵表示。</p><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/SwAV.jpg" class=""></div><h2 id="基于不对称结构：BYOL"><a href="#基于不对称结构：BYOL" class="headerlink" title="基于不对称结构：BYOL"></a>基于不对称结构：BYOL</h2><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/byol.jpg" class=""></div><p>Target 分枝结构类似 Moco V2对应下分枝的 Moving Average 动量更新方式。Predictor 的存在保证了模型不坍缩（具体为何没有定论）。</p><h2 id="基于冗余消除：Barlow-Twins"><a href="#基于冗余消除：Barlow-Twins" class="headerlink" title="基于冗余消除：Barlow Twins"></a>基于冗余消除：Barlow Twins</h2><div style="width:100%;margin:auto"><img src="/machine-learning/contrastive-learning/barlow-twins.jpg" class=""></div><p>Barlow Twins 并没有去除向量的长度因素，它在Batch维度，对 Aug1 和 Aug2 里的正例分别做了类似 BN 的正则。之后，顺着 Batch 维，对 Aug1 和 Aug2 两个正例表示矩阵做矩阵乘法，求出两者的互相关性矩阵（cross-correlation matrix），其损失函数定义在这个互相关矩阵$C$上。希望互相关矩阵为对角元素为1的单位矩阵，增强元素间的独立性。</p><h1 id="现状与展望"><a href="#现状与展望" class="headerlink" title="现状与展望"></a>现状与展望</h1><h2 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h2><p>BYOL，SwAV，DeepCluster-v2 都在 many-shot（ImageNet上学，再迁移到其他数据集） 和 few-shot 上取得了比较好的表现。其中在 many-shot 上甚至超过有监督。数据来源于这篇论文，“How Well Do Self-Supervised Models Transfer?”。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol><li>数据偏置问题：ImageNet 相对于普通网上能获取的数据还是太干净了。</li><li>正例构建问题：除了图像遮挡不变性和颜色不变性，对于其它的常见不变性，比如视角不变性、照明不变性等，对比学习模型的效果要明显弱于监督学习。</li><li>对于复杂任务缺乏像素级学习能力：当下都是采用判别模型。</li></ol><h2 id="我的看法"><a href="#我的看法" class="headerlink" title="我的看法"></a>我的看法</h2><p>其实从2019年就已经陆陆续续见过很多自监督学习的工作了，一直也没有静下心来学习一下。这次通过对这篇介绍性博文的学习，加上之前一些自己的见闻，也算是对这个自监督学习方向有了一个粗浅的理解。</p><p>总的来说，自监督学习是希望在完全无标记的样本集中学习一个富有信息的表征。由于无标记，所以在学习表征的过程中，我们需要创建一些辅助任务来帮助学习表征。这些辅助任务包括但不限于：</p><ul><li>某种填空（类似 bert 的预训练，图像中的补全）</li><li>某种相似度量（对比学习）</li><li>etc.</li></ul><p>所以自监督学习问题的关键其实在于如何构建这个辅助任务：</p><ul><li>从当下的了解来看，判别式的方法是主流，都是通过生成正负样本来构建辅助任务。</li><li>在我的角度看，知乎这篇文章的分类，除了 BYOL 之外，还都是通过正负样本的判别来实现的，只是如何判别略有不同，但还是在一个范式下面。</li><li>这种基于判别的辅助任务其实是很简单的（同时在简单的分类问题上起到了很好的表现），但这种基于简单任务学到的表征在复杂任务上的适用性还不清楚（或许不太好，文章中提到的“像素级构建能力”）。</li><li>或许设计更加复杂但是可行的辅助任务，能提取到更为合适且富含信息的表征。</li></ul><p>与其他领域的关系：</p><ul><li>背景上：自监督学习的出现背景还是存在大量未标记数据，其实也是在标记数据不足这个局限性下做的尝试。</li><li>目的上：与其他研究领域尝试学模型不同，自监督学习的主要目的是在学表征。</li></ul><p>总的来说，我第一次见到这类方法的时候就觉得很直观且很巧妙，经过近年的发展，它的可用性已经得到了验证，个人认为在表征学习的这个道路上，自监督学习还是比较靠谱的。但是放到具体的下游任务上，面临标记数据的匮乏时，用主动学习选取标注才是合理之选。或许将来的可以实用的大模型都会包含一个离线的自监督学习表征模块，和一个在线的主动学习模块。这样既可以缓解主动学习在深度表征上的乏力，也可以高效的在表征确定的时候找到目标模型。</p>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;之前总是会断断续续看到一些自监督学习的工作/想法。
同时也总是看到对比学习这个词，不明所以，所以对此进行一个简单的学习。
本文可以看作对&lt;a href=&quot;https://zhuanlan.zhihu.com/p/367290573&quot;&gt;《对比学习（Contrastive Learning）:研究进展精要》&lt;/a&gt;这片知乎文章的阅读笔记。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://superuier.github.io/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://superuier.github.io/tags/machine-learning/"/>
    
    <category term="contrastive-learning" scheme="https://superuier.github.io/tags/contrastive-learning/"/>
    
    <category term="self-supervised-learning" scheme="https://superuier.github.io/tags/self-supervised-learning/"/>
    
  </entry>
  
  <entry>
    <title>人工智能的中的搜索</title>
    <link href="https://superuier.github.io/artificial-intelligence/ai-search/"/>
    <id>https://superuier.github.io/artificial-intelligence/ai-search/</id>
    <published>2021-09-27T08:00:00.000Z</published>
    <updated>2021-09-29T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能中关于搜索的一些最基础的知识。</p><a id="more"></a><h2 id="AI-中的搜索"><a href="#AI-中的搜索" class="headerlink" title="AI 中的搜索"></a>AI 中的搜索</h2><p>对于一个 goal-based agent，搜索是使其找到一个动作或者一系列动作来达到目标。有很多例子，比如走迷宫，寻路问题，8-queen 问题等。一般来说包含树搜索和图搜索等。</p><h2 id="对于考虑路径的搜索而言"><a href="#对于考虑路径的搜索而言" class="headerlink" title="对于考虑路径的搜索而言"></a>对于考虑路径的搜索而言</h2><p>评估策略需考虑以下四个维度：</p><ul><li>Completeness: Does it always find a solution if it exists?</li><li>Time complexity: # nodes generated/expanded.</li><li>Space complexity: maximum # nodes in memory.</li><li>Optimality: Does it always find the least-cost solution?</li></ul><p>存在两类搜索策略：</p><ul><li>Uniformed<ul><li>Breadth-first search (BFS): Expand shallowest node</li><li>Depth-first search (DFS): Expand deepest node</li><li>Depth-limited search (DLS): Depth first with depth limit</li><li>Iterative-deepening search (IDS): DLS with increasing limit</li><li>Uniform-cost search (UCS): Expand least cost node (the cost could be the length between nodes)</li></ul></li><li>Informed<ul><li>Greedy best-first search: Expand the node that appears to be closest to goal</li><li>A* search: Minimize the total estimated solution cost (to middle node + node to goal；f=g+h). BFS mode.</li><li>IDA<em>: IDS + A</em>. DLS mode. The cost of space is lower than A*.</li></ul></li></ul><p>对于 A* 中启发式策略而言（h）：</p><ul><li>A good heuristic must be admissible.</li><li>An admissible heuristic never overestimates the cost to reach the goal, that is it is optimistic</li><li>For admissible $h_1$ and $h_2$, if $h_1$(s) ≥ $h_2$(s) for ∀𝑠 ⇒ $h_1$ dominates $h_2$ and is more efficient for search.</li></ul><p>UCS vs Greedy Best First vs A*:</p><ul><li>UCS：f(n) = g(n) </li><li>Greedy Best First: f(n) = h(n) </li><li>A*: f(n)=g(n)+h(n)</li></ul><h2 id="对于不考虑路径的搜索"><a href="#对于不考虑路径的搜索" class="headerlink" title="对于不考虑路径的搜索"></a>对于不考虑路径的搜索</h2><p>Local search: the path doesn’t matter</p><ul><li>Hill climbing</li><li>Genetic algorithms</li><li>Simulated Annealing: Given a chance to jump out the local minimum</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能中关于搜索的一些最基础的知识。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://superuier.github.io/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://superuier.github.io/tags/AI/"/>
    
    <category term="search" scheme="https://superuier.github.io/tags/search/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib 学习笔记</title>
    <link href="https://superuier.github.io/programming/matplotlib/"/>
    <id>https://superuier.github.io/programming/matplotlib/</id>
    <published>2021-09-24T07:00:03.000Z</published>
    <updated>2021-09-24T07:00:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是个人的 Matplotlib 学习笔记。记录一些作图的过程。</p><a id="more"></a><h1 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h1><h2 id="减小空白边界"><a href="#减小空白边界" class="headerlink" title="减小空白边界"></a>减小空白边界</h2><p>由于使用 Latex 排版时需要严格控制图片位置、大小、排布方式，所以任何冗余的空间都是需要极力避免的。在做图的时候可以直接将图片空白边界抹去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.savefig(<span class="string">&#x27;test.png&#x27;</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure><p>但是这个方法有一个问题就是多个图片的留白可能不一致，导致如果多子图放置于 latex 文档中会出现排版无法对齐的情况。此时需要手动对边界进行设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.subplots_adjust(left=<span class="number">0.12</span>, right=<span class="number">0.97</span>, top=<span class="number">0.98</span>, bottom=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;这里是个人的 Matplotlib 学习笔记。
记录一些作图的过程。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="https://superuier.github.io/categories/programming/"/>
    
    
    <category term="Python" scheme="https://superuier.github.io/tags/Python/"/>
    
    <category term="Matplotlib" scheme="https://superuier.github.io/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>人工智能的基本概念</title>
    <link href="https://superuier.github.io/artificial-intelligence/ai-basics/"/>
    <id>https://superuier.github.io/artificial-intelligence/ai-basics/</id>
    <published>2021-09-07T09:00:00.000Z</published>
    <updated>2021-09-07T09:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能基础知识和一些概念。</p><a id="more"></a><h2 id="AI-是什么？"><a href="#AI-是什么？" class="headerlink" title="AI 是什么？"></a>AI 是什么？</h2><p>其实很多地方都给出了不同角度的定义，此处仅记录自己的看法。</p><blockquote><p>AI 是承载于机器或程序，人为设计或训练，并可以解决特定或一些列特定问题的能力。</p></blockquote><p>其涵盖多个计算机领域：机器学习/优化/搜索/etc.</p><h2 id="智能体"><a href="#智能体" class="headerlink" title="智能体"></a>智能体</h2><p>AI 承载于智能体（Agent），即我的定义中的机器或程序。</p><blockquote><p>Agent = Architecture + Program</p></blockquote><p>在解决问题的过程中，智能体通过传感器（Sensors）接受外界环境（Environment）的信号，并自我处理信息，之后作出相应行动（Action）。于是在对一个智能体进行定义时，通常要考虑 <strong>PEAS</strong>：</p><ul><li>Performance</li><li>Environment</li><li>Actuators</li><li>Senors</li></ul><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>环境有很多重要的类别：</p><ul><li>Fully observable (vs. partially observable)</li><li>Deterministic (vs. stochastic)</li><li>Episodic (vs. sequential)</li><li>Static (vs. dynamic)</li><li>Discrete (vs. continuous)</li><li>Single agent (vs. multi-agent)</li><li>Known (vs. Unknown)</li></ul><p>下面是一些具体的例子。</p><div class="table-container"><table><thead><tr><th>Environment</th><th>Observable</th><th>Agents</th><th>Deterministic</th><th>Static</th><th>Discrete</th></tr></thead><tbody><tr><td>8-puzzle</td><td>Fully</td><td>Single</td><td>Deterministic</td><td>Static</td><td>Discrete</td></tr><tr><td>Chess</td><td>Fully</td><td>Multi</td><td>Deterministic</td><td>(Semi)Static</td><td>Discrete</td></tr><tr><td>Poker</td><td>Partially</td><td>Multi</td><td>Stochastic</td><td>Static</td><td>Discrete</td></tr><tr><td>Backgammon</td><td>Fully</td><td>Multi</td><td>Stochastic</td><td>Static</td><td>Discrete</td></tr><tr><td>Car</td><td>Partially</td><td>Multi</td><td>Stochastic</td><td>Dynamic</td><td>Continuous</td></tr><tr><td>Cleaner</td><td>partially</td><td>Single</td><td>Stochastic</td><td>Dynamic</td><td>Continuous</td></tr></tbody></table></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能基础知识和一些概念。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://superuier.github.io/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://superuier.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>有趣的事物</title>
    <link href="https://superuier.github.io/interesting-stuff/interesting-stuff/"/>
    <id>https://superuier.github.io/interesting-stuff/interesting-stuff/</id>
    <published>2021-09-07T06:50:00.000Z</published>
    <updated>2021-09-07T06:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>一些有趣的东西。</p><a id="more"></a><ul><li><a href="https://csunplugged.org/en/">Computer Science without a computer</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些有趣的东西。&lt;/p&gt;</summary>
    
    
    
    <category term="Interesting Stuff" scheme="https://superuier.github.io/categories/Interesting-Stuff/"/>
    
    
    <category term="interesting" scheme="https://superuier.github.io/tags/interesting/"/>
    
  </entry>
  
  <entry>
    <title>Batch Normalization</title>
    <link href="https://superuier.github.io/machine-learning/batch-normalization/"/>
    <id>https://superuier.github.io/machine-learning/batch-normalization/</id>
    <published>2021-09-03T07:00:00.000Z</published>
    <updated>2021-09-03T07:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>此处记录对于 Batch Normalization 的学习。</p><a id="more"></a><h2 id="神经网络中存在的-ICS-问题"><a href="#神经网络中存在的-ICS-问题" class="headerlink" title="神经网络中存在的 ICS 问题"></a>神经网络中存在的 ICS 问题</h2><p>深度学习中存在 Internal Covariate Shift (ICS) 的问题。类比迁移学习中的 Covariate Shift 指源领域和目标领域数据 marginal distribution 的偏移。这里 ICS 指神经网络中，由于参数的变化，引起的每一层输出分布的差异变化，换句话说之后下一层的输入在参数变化后，可能基于了另一个分布。所以下一层在训练过程中就需要不断的去适应这种变化。</p><p>于是带来了以下问题：</p><ul><li>后面一层的参数需要适应不断变化的分布，训练效率降低。</li><li>对于饱和非线性激活函数，例如 sigmoid 和 tanh，容易落入饱和区。饱和区是指由于输入值极度偏离0点，导致梯度计算接近于0，从而难以起到学习效果。</li></ul><h2 id="如何解决-ICS-问题"><a href="#如何解决-ICS-问题" class="headerlink" title="如何解决 ICS 问题"></a>如何解决 ICS 问题</h2><p>此类由于分布变化带来不良影响的问题，最 naive 的解决方式一般来说都是对分布进行限制。就比如在迁移学习中，会将源域和目标域的样本来做一个统一（减小分布差异）。在 ICS 问题中，也可以对分布进行限制。</p><p>最初，白化（whitening）被提出，一般来说采用 <a href="http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/">PCA</a> 或者 ZCA 的方法，使所有特征分布均值为0，方差为1（PCA）或相同（ZCA）。白话的目的是去除数据特征之间相关性（独立），同时使其具有相同均值和方差（同分布）。这样每一层网络的输入分布被固定，加速网络收敛。</p><p>但是白化也存在一些问题：</p><ul><li>计算成本高</li><li>改变数据表达能力，一些参数信息会被丢失</li><li>不可微，难以通过反向传播训练</li></ul><p>所以说我们期望有一种计算代价低廉，且能使标准化的数据尽可能保有表达能力的方法。这就是 Batch Normalization 提出的背景。</p><h2 id="什么是-Batch-Normalization"><a href="#什么是-Batch-Normalization" class="headerlink" title="什么是 Batch Normalization"></a>什么是 Batch Normalization</h2><p>主要思路：</p><ul><li>既然白化计算过程比较复杂，那我们就放松限制一点，尝试只单独对每个特征进行标准化，使其均值为0，方差为1。</li><li>既然类白化操作减弱了网络中每一层输入数据表达能力，那再加入线性变换操作，让这些数据再能够尽可能恢复本身的表达能力，使其不因规范化而下降。</li></ul><p>通用变换框架如下所示，包含两次平移和伸缩变换，在使用 BN 之后，每层神经元输入的样本的均值仅由 $\boldsymbol{b}$ 决定，而不像之前由前面一层神经网络复杂的参数决定：</p><script type="math/tex; mode=display">h=f\left(\boldsymbol{g}\cdot\frac{\boldsymbol{x}-\boldsymbol{\mu}}{\boldsymbol{\sigma}}+\boldsymbol{b}\right)\\</script><p>但是好像这个第二次的仿射变换在理论上是否有用，需不需要用还有争议，日后可以再仔细看一下。（挖坑）</p><p>同时 BN 有一些变体，在这里不展开了：</p><ul><li>纵向规范化（最基础）</li><li>横向规范化</li><li>参数规范化</li><li>余弦规范化</li></ul><h2 id="如何使用-Batch-Normalization"><a href="#如何使用-Batch-Normalization" class="headerlink" title="如何使用 Batch Normalization"></a>如何使用 Batch Normalization</h2><p>适用场景：</p><ul><li>每个 mini-batch 比较大，数据分布比较接近。</li><li>在进行训练之前，要做好充分的 shuffle， 否则效果会差很多。</li><li>因此不适用于 动态的网络结构 和 RNN 网络</li></ul><p>测试阶段：</p><ul><li>保留训练时每一个 batch 的统计量 $\mu_{batch}$ 和 $\sigma^2_{batch}$。</li><li>使用整个样本的统计量来对Test数据进行归一化，具体来说使用均值与方差的无偏估计。<ul><li>$\mu_{test}=\mathbb{E} (\mu_{batch})$</li><li>$\sigma^2_{test}=\frac{m}{m-1}\mathbb{E}(\sigma^2_{batch})$</li></ul></li></ul><p>构建阶段：</p><ul><li>置于 Conv 层或全连接层之后</li><li>对于饱和非线性激活函数而言，BN 层需要放到 activation 之前。Dropout 则应当置于 activation layer 之后.</li><li>对于 ReLU 而言，目前并没有定论，不管是实验还是理论争论都比较多，目前看来 BN 放在 ReLU 之后可能表现更好，但是放在 ReLU 前的可能更多一些（BN 原论文是放在了前面）。（<strong>大误</strong>）</li></ul><h2 id="在-Pytorch-中的-Batch-Normalization"><a href="#在-Pytorch-中的-Batch-Normalization" class="headerlink" title="在 Pytorch 中的 Batch Normalization"></a>在 Pytorch 中的 Batch Normalization</h2><p>在 Pytorch 的实现中，BN 也包含两次平移和伸缩变换，其中第二次变换可以通过调整仿射变换参数 <code>affine=True</code> 选择是否打开。这里可能也体现了这个仿射变换是否有必要的争议。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/33173246">详解深度学习中的Normalization，BN/LN/WN - Juliuszh的文章 - 知乎</a></li><li><a href="https://zhuanlan.zhihu.com/p/34879333">Batch Normalization原理与实战 - 天雨粟的文章 - 知乎</a></li><li><a href="https://www.zhihu.com/question/318354788/answer/640006790">Batch Normalization 和激活函数的使用顺序是什么，神经元的饱和指的又是什么？ - 无双谱的回答 - 知乎</a></li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html">https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;此处记录对于 Batch Normalization 的学习。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://superuier.github.io/categories/Machine-Learning/"/>
    
    
    <category term="neural-network" scheme="https://superuier.github.io/tags/neural-network/"/>
    
    <category term="machine-learning" scheme="https://superuier.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Latex 图片排版记录</title>
    <link href="https://superuier.github.io/programming/latex/"/>
    <id>https://superuier.github.io/programming/latex/</id>
    <published>2021-08-30T03:00:00.000Z</published>
    <updated>2021-09-24T08:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>此处记录一些 Latex 的用法。</p><a id="more"></a><h2 id="图片排版"><a href="#图片排版" class="headerlink" title="图片排版"></a>图片排版</h2><h3 id="子图排版"><a href="#子图排版" class="headerlink" title="子图排版"></a>子图排版</h3><p>涉及子图的图片排版可以参考<a href="https://blog.csdn.net/a6822342/article/details/80533135">此链接</a>。在此就不再赘述。</p><h3 id="将图片放置于表格中"><a href="#将图片放置于表格中" class="headerlink" title="将图片放置于表格中"></a>将图片放置于表格中</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;</span><br><span class="line">   <span class="keyword">\centering</span></span><br><span class="line">   <span class="keyword">\caption</span>&#123;The table of figures&#125;</span><br><span class="line">   <span class="keyword">\hspace</span>*&#123;-0.15<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">   <span class="keyword">\begin</span>&#123;tabular&#125;&#123;cM&#123;0.25<span class="keyword">\linewidth</span>&#125;M&#123;0.25<span class="keyword">\linewidth</span>&#125;M&#123;0.25<span class="keyword">\linewidth</span>&#125;M&#123;0.25<span class="keyword">\linewidth</span>&#125;&#125;</span><br><span class="line">      <span class="keyword">\toprule</span></span><br><span class="line">        <span class="built_in">&amp;</span> A                                              <span class="built_in">&amp;</span> B                                              <span class="built_in">&amp;</span> C                                              <span class="built_in">&amp;</span> D                                              <span class="keyword">\\</span></span><br><span class="line">      <span class="keyword">\midrule</span></span><br><span class="line">      K <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="keyword">\\</span></span><br><span class="line">      L <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="keyword">\\</span></span><br><span class="line">      M <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="keyword">\\</span></span><br><span class="line">      N <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="built_in">&amp;</span> <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;figure.png&#125; <span class="keyword">\\</span></span><br><span class="line">      <span class="keyword">\bottomrule</span></span><br><span class="line">   <span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line">   <span class="keyword">\label</span>&#123;table:table-of-figures&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure><h3 id="子图超出行宽强制不换行"><a href="#子图超出行宽强制不换行" class="headerlink" title="子图超出行宽强制不换行"></a>子图超出行宽强制不换行</h3><p>这个需求是因为在写文章时有时模版会在子图间加距离，导致按比例设置大小的子图超出行距换行。另一种情况就是有时我们需要稍外超出一些行距来使图片更大一些。一般来说这里需要使用到 <code>\makebox</code> 命令。</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;</span><br><span class="line">   <span class="keyword">\centering</span></span><br><span class="line">   <span class="keyword">\makebox</span>[<span class="keyword">\textwidth</span>][c]&#123;</span><br><span class="line">   <span class="keyword">\subfigure</span>[Caption A]&#123;</span><br><span class="line">      <span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.3<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">         <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\textwidth</span>]&#123;figure/digit<span class="built_in">_</span>best.png&#125;</span><br><span class="line">      <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">\hspace</span>&#123;-0.05<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">   <span class="keyword">\subfigure</span>[Caption B]&#123;</span><br><span class="line">      <span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.3<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">         <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\textwidth</span>]&#123;figure/amazon<span class="built_in">_</span>best.png&#125;</span><br><span class="line">      <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">\hspace</span>&#123;-0.05<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">   <span class="keyword">\subfigure</span>[Caption C]&#123;</span><br><span class="line">      <span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.3<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">         <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\textwidth</span>]&#123;figure/office<span class="built_in">_</span>best.png&#125;</span><br><span class="line">      <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">\hspace</span>&#123;-0.05<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">   <span class="keyword">\subfigure</span>[Caption D]&#123;</span><br><span class="line">      <span class="keyword">\begin</span>&#123;minipage&#125;[b]&#123;0.3<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">         <span class="keyword">\includegraphics</span>[width=1<span class="keyword">\textwidth</span>]&#123;figure/imageCLEF<span class="built_in">_</span>best.png&#125;</span><br><span class="line">      <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">   &#125;&#125;</span><br><span class="line">   <span class="keyword">\caption</span>&#123;A box of figures.&#125;</span><br><span class="line">   <span class="keyword">\label</span>&#123;fig:box-figures&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><h2 id="表格排版"><a href="#表格排版" class="headerlink" title="表格排版"></a>表格排版</h2><h3 id="竖排表格中的文本"><a href="#竖排表格中的文本" class="headerlink" title="竖排表格中的文本"></a>竖排表格中的文本</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\rotatebox</span>&#123;90&#125;&#123;some rotated text&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;此处记录一些 Latex 的用法。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="https://superuier.github.io/categories/programming/"/>
    
    
    <category term="latex" scheme="https://superuier.github.io/tags/latex/"/>
    
  </entry>
  
  <entry>
    <title>中国为什么有前途</title>
    <link href="https://superuier.github.io/reading-note/china-bold-future/"/>
    <id>https://superuier.github.io/reading-note/china-bold-future/</id>
    <published>2021-08-25T18:04:00.000Z</published>
    <updated>2021-08-25T18:04:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>《中国为什么有前途》 翟东升老师</p><a id="more"></a><hr><h2 id="极简简介"><a href="#极简简介" class="headerlink" title="极简简介"></a>极简简介</h2><p>此处以两版的前言的节选来作简介。</p><h3 id="第三版前言"><a href="#第三版前言" class="headerlink" title="第三版前言"></a>第三版前言</h3><p>本书有2009年开始做了第一版，迄今为止已有第三版（2019年）。本书的若干语言和预警都得以兑现：</p><ul><li>2010年第一版提出逆全球化的风险</li><li>2015年第二版（撰写于2014年）预警美元强势周期导致人民币汇率下跌和资本外逃的恶性循环</li></ul><h3 id="第二版前言"><a href="#第二版前言" class="headerlink" title="第二版前言"></a>第二版前言</h3><p>宏观来看，中国的国际地位提高。但是微观来看，生活中的困境压的普通人喘不过气来。看整体国势，中国好像很有前途；但是看自己身边，好像又问题很大。写这本书是为了告诉读者，做一个21世纪的中国人，是艰辛却又令人骄傲的。</p><p>本书向读者指出一些基本事实和历史轨迹，包括：</p><ul><li>世界历史演进的趋势</li><li>当代中国体制的特质</li><li>中国已经具备巨大潜能</li></ul><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>这是一本全面的书，其以中国改革开放以来的政治经济为主线，涵盖货币，安全，投资，援助等方面，对认识中国当下经济政治政策的形成过程可以起到帮助作用。</p><p>这同样也是一本乐观的书，乐观地总结了中国从上世纪70年代以来的经济货币等政策变动，并乐观的展望了未来中国发展的趋势。为何说这本书乐观？是因为其总能从正反两面考虑过去的政策，甚至是“不那么好的政策”，并提取出有价值的经验。同时又通过分析历史和总结，在考虑到很多政策潜在弊端的情况下，对未来政策提出相对优良一些的改进或优化。</p><h3 id="感想-看法"><a href="#感想-看法" class="headerlink" title="感想/看法"></a>感想/看法</h3><p>本人从这本书收益良多，翟老师在自己的知识框架下对中国过去的走势和未来的发展做出了分析总结。对我个人而言，由于之前知识体系尚未构建，所以对翟老师的观点以认同居多，或许将来在不断学习后，可以更加批判看待书中观点。</p><p>仅从书中总结的事实来看，我个人对中国近年来的发展持乐观态度。可以从书中清晰地看到国内政策的调整与转变，尽管政策或许尚有不足，但是不断完善，向科学完备发展。</p><p>有一个明显有趣的点，就是可以看出翟老师的一些“双标”，总的来说就是我们察觉到了美国的货币霸权，不公平的优先发展权等，对其进行批判，但是我们的目标也是获得这一些权利。还有就是一些政策在我们国家使用的时候可以明显看出利弊，但是宣传给其他国家使用相同政策时则强调好处。这其实无可厚非，“人不为己，天诛地灭”，当然我还是更愿意相信当中国作为一个体系更中心的国家时，能更多的承担一些国际责任，可能要好于多数的民主大国。</p><p>在对外投资和援助上，我以前其实一直没搞清楚必要性重要性和利弊。这里看来或许翟老师已经一一阐述，之后可以新开一个 post 来做一下总结。但是总的来说，能说和不能说的好处都是存在的。此时就有涉及到另一个也很有趣的话题——“师出有名”。为自己的政策和潜在利益作出令人无法反驳的解释，还是很重要的。</p><p>还有一点就是这本书其实强化了一个我的认识。就是金融的本质，或者说最重要的点，是为社会活动提供资金，尤其是优化资金配置。以前我对这一认识并不清晰，觉得金融可能主要在于套利，或者保证市场有效（当然这个也很重要），所以一度觉得金融很虚，甚至有时会存在对其嗤之以鼻但又羡慕人家利润的看法。尤其是之前觉得很多金融人士致力于杀猪盘割韭菜，更是让我这行业持轻视态度（可能是吃不到葡萄说葡萄酸）。但是这本书在国家投资，主权基金，国企民企的陈述中，反复展现了优化资金的配置对于行业，对于国家的重要性，让我强化了金融这个行业负担起优化资本配置责任和义务的认知。所以个人认为，金融，尤其是中国金融，脱虚向实还是很有必要的。当然要能干的了实事，也得能抵御国外的金融攻击。（外行人的见解。）</p><p>其实书中大部分内容，翟老师在政经启翟中都有提到。这里只是在中国发展的维度进行展开。但是总的来说跳不出“人本主义政治经济学”的框架。本人虽然见识的社会比较少，但是对“人才是最重要的财富”深以为然。最后以 Ray Dalio 最近说的一番话结束这番感想。</p><blockquote><p>I encourage you to look at the trends and not misunderstand and over-focus on the wiggles.To understand what’s going on you need to understand that China is a state capitalist system which means that the state runs capitalism to serve the interests of most people and that policy makers won’t let the sensitivities of those in the capital markets and rich capitalists stand in the way of doing what they believe is best for the most people of the country.</p></blockquote><hr><h1 id="按节讨论-摘录"><a href="#按节讨论-摘录" class="headerlink" title="按节讨论/摘录"></a>按节讨论/摘录</h1><h2 id="第一章：世界市场体系的中央与外围"><a href="#第一章：世界市场体系的中央与外围" class="headerlink" title="第一章：世界市场体系的中央与外围"></a>第一章：世界市场体系的中央与外围</h2><p>四类国家：</p><ul><li>中央国家：依靠信心生活，美国</li><li>准中央国家：依靠理性生存，欧日</li><li>外围工业国家：依靠勤劳谋生，中国，印度，东亚，中东欧</li><li>原料提供国家：依靠运气生存，中东，拉美，非洲，东欧，中亚</li></ul><p>四类国家间主要存在<strong>两种关系</strong>：</p><ul><li>贸易关系：材料和产品的流动</li><li>融资关系：美元霸权</li></ul><p>世界市场体系的<strong>基本特点</strong>：</p><ul><li>无远弗届：很少有国家可以孤立于世界市场之外。</li><li>非常不公平的体系：中央国家比起外围国家更富有和稳定。<ul><li>“中央国家掌握自己的货币政策，外围国家难以掌握自己的货币政策。”—索罗斯</li><li>铸币税：信用货币与真实价值；外围投资与美元贬值。</li></ul></li><li>要素流动的选择性：不同要素流动程度不同，信息观念到商品服务到技术到人力资源流动程度递减。</li><li>自我强化功能：中心外围固化，强者恒强，弱者恒弱。（中短期效应）</li><li>周期的自我更新：伊利比亚半岛国家（葡萄牙和西班牙），荷兰，英国，美国<ul><li>人口规模越来越大：当大家都掌握了新的财富与权势要素，规模（人口，幅员）重新变得重要。</li><li>短期内“劫贫济富”，长期“损有余而补不足”。</li></ul></li><li>结构的鲁棒性：<ul><li>利益分布不均衡但是博弈论意义均衡。</li></ul></li></ul><p><strong>中央国家收益、代价和条件</strong>：</p><ul><li>获得的<strong>收益</strong>：<ul><li>提高人均财富拥有量。</li><li>提供对全球经济波动节奏的掌握和调控能力。</li><li>融资和负担转嫁能力。</li><li>语言、人才、政治自信、号召力。</li></ul></li><li>获取和保有中央地位的<strong>条件</strong>：<ul><li>货币霸权（参考如何成功开办和经营一家商业银行。）</li><li>资本实力</li><li>控制商业活动以自己货币进行</li><li>维系重要国家的关系获得支持</li><li>发行金融产品满足外围国家偏好</li><li>存款通过投资转化为资本<ul><li>自己的跨国公司有明显经营优势</li><li>全球市场开放性</li></ul></li></ul></li><li>中央国家承担的<strong>成本</strong>：<ul><li>产业外移，长期逆差，去工业化</li><li>控制战略地区的安全成本的</li></ul></li></ul><p><strong>外围国家发展道路上的常见陷阱</strong>：</p><ul><li>资源诅咒陷阱</li><li>欲速不达的赶超陷阱</li><li>发展过程中的政治陷阱</li></ul><p>寥寥几个外围国家<strong>逆袭</strong>的成功者，<strong>都符合以下特征</strong>：</p><ul><li>极度缺乏自然资源</li><li>人口增速适中</li><li>紧紧依附西方市场</li><li>政府对权力控制牢固</li></ul><h2 id="第二章：中国在体系中的足迹"><a href="#第二章：中国在体系中的足迹" class="headerlink" title="第二章：中国在体系中的足迹"></a>第二章：中国在体系中的足迹</h2><p>从人均角度来看，中国的<strong>比较优势</strong>不在于原材料而在于<strong>劳动力</strong>。改革开放以来实现<strong>“三外路线”</strong>：对外贸易、引进外资（外国直接投资）、对外货币安排。20世纪80年代，中国由外围原料出口国演变为外围工业国。2019年中国即将从外围工业国转变为中央工业国的临界区域（地位等同欧日）。</p><p><strong>“三外路线”</strong>的政策组合，形成了官方巨大的外汇储备：</p><ul><li>人民币大幅贬值锚定美元</li><li>引进外资</li><li>鼓励出口</li><li>经常项目人民币可兑换</li><li>强制结售汇</li></ul><p>“三外路线”的<strong>利弊</strong>：</p><ul><li>“三外路线”的利：<ul><li>就业、工业化、资本积累、对改革的推动、和平。</li></ul></li><li>“三外路线”的弊：<ul><li>本土工业形成挤压、环境资源代价、对外部资本及市场依赖、地区部门阶层间分配失衡</li><li>对中央国家的实质性纳贡，外商利用外汇在中国收益10%以上的年华，而中国用外汇投资收益接近0。</li><li>不可持续性：中国生产美国消费，中国放贷美国借债的循环模式不可持续。</li></ul></li></ul><p>“三外路线”的<strong>修正</strong>：</p><ul><li>科学发展观：以福利而不是 GDP 衡量政策成就。</li><li>外商回归国民待遇，招商引资到招商选资。</li><li>人民币渐进升值过程。</li><li>强调自主创新，培育自身<a href="/economy-finance/seminar-talks/xiaogang/" title="多层次资本市场">多层次资本市场</a>。</li><li>启动内需，减轻外部依赖。</li><li>对国有企业的扶持。</li></ul><p>“三外路线”在中国<strong>何以实现</strong>：</p><ul><li>工业化和现代化的历史使命：发挥比较优势，发展市场上有竞争力的产业，才能顺利实现工业化。</li><li>体制根源：国家权力彻底渗入动员和改造了中国社会，中央地方关系也同样重要。</li><li>思潮和意识形态因素：引入西方经济学，“科学发展观”。</li><li>要素禀赋，人口与资源：规模是竞争优势，也有着巨大的内需市场潜力。</li></ul><p>“三外路线”兴衰<strong>对中国外交的影响</strong>：</p><ul><li>20世纪90年代低调对外，“韬光养晦”。</li><li>2004年后，对西方依赖程度在逐步减轻，西方却更依赖中国。</li><li>2005年来，在联合国使用或声称使用否决权来迫使议案调整。</li><li>2012年以来，走出韬晦。</li></ul><h2 id="第三章：“三外路线”下的对外贸易"><a href="#第三章：“三外路线”下的对外贸易" class="headerlink" title="第三章：“三外路线”下的对外贸易"></a>第三章：“三外路线”下的对外贸易</h2><blockquote><p>即将到来的中国对外产业转移，需要我们思考这样一个问题：如何发展出一种独特的产业链编辑能力，以便尽可能按照我们的政治经济利益塑造地区乃至全球性的地缘经济和地缘政治格局。</p></blockquote><p><strong>中国对外贸易发展的轨迹</strong>：</p><ul><li>外贸惊人增长：<ul><li>贸易收支平衡方面持续顺差</li><li>外贸总量大幅升高和出口总量全球第一</li></ul></li><li>外贸结构改善：<ul><li>商品：原材料到劳动/资源密集型工业制成品到高新技术出口品</li><li>贸易性质：加工贸易比例先上升后下降。2005年之后，落后外资撤出，加工贸易下降，长期来看仍会下降。</li><li>出口目的地：从出口中央国家到出口目的地多元化。对外围地区的出口商由中资企业为主。</li><li>出口企业性质：外资比例稳步回落。</li></ul></li></ul><p><strong>中国对外贸易发展的动能</strong>：</p><ul><li><strong>观念</strong>的变迁：<ul><li>从使用苏联模式到接受西方自由主义经济学并成为主流。</li><li>进口替代型发展战略到出口导向型（不强调建立自己的完整产业体系），但是未极端化而是渐进融合。</li><li>比较优势和“竞争优势”。</li></ul></li><li><strong>制度</strong>的变迁：<ul><li>外贸管理体制市场化、国际化、法律化。</li><li>企业内部治理模式改革。</li><li>外贸经营权放开和扩大。</li></ul></li><li>鼓励出口的政策组合：<ul><li>外汇留成制度和人民币贬值</li><li>出口退税政策促进出口</li></ul></li></ul><p><strong>国际体系环境</strong>：</p><ul><li>日本产业转移，四小龙诞生</li><li>美国限制进口增速</li><li>中国招商引资</li><li>所以对美出口绕行到中韩台地区。</li></ul><h3 id="贸易、产业与地缘政治经济"><a href="#贸易、产业与地缘政治经济" class="headerlink" title="贸易、产业与地缘政治经济"></a>贸易、产业与地缘政治经济</h3><p>回答此章开头的问题。<code>对外贸易是否可以塑造一个有力的地缘政治经济环境？</code>基本思路在于培育“产业链编辑能力”。</p><blockquote><p>所谓产业链编辑能力（capacity of industrial chain editing, CICE），是指大国依靠<strong>资深市场规模</strong>以及<strong>对某些关键性生产要素的掌控</strong>而获得的一种特殊能力，借此可以在一定程度上按照自身国家利益的需要来<strong>主动调整地区性的甚至全球性的产业地理分布</strong>，以便从国家间不对称的相互依赖中获得优势和权利。</p></blockquote><p>今天，经济成长，吐故纳新，顺比较优势，我们之前的劳动力成本和环境成本不应该是优势了。</p><blockquote><p>用国内消费取代外需和投资拉动经济成长的中国经济转型，既是应对全球金融危机和经济衰退的必要举措，也是建设国内和谐社会和可持续发展的内在要求。</p></blockquote><p>所以产能向哪里转移？怎么转移？</p><ol><li>可以推动他国市场内在趋势加速，但是不能改变内在趋势。（斯里兰卡、缅甸、巴基斯坦、孟加拉转移纺织化工。）</li><li>集中力量深度介入少数经济体的经济建设和国家发展。</li><li>对周边单个国家依赖最小化，并让他们对我们依赖最大化。</li><li>中国已有的确保有效的编辑产业链的资源：<ul><li>部分产业的控制权</li><li>技术资本积累</li><li>越来越大的本土市场规模</li><li>政府高调控管治能力</li><li>巨大国家资本积累</li><li>未来国际大国的国际信用</li></ul></li></ol><blockquote><p>新问题：当替他大国也拥有上述资源和条件时，并试图运用这些资源实现与我们目标抵牾的地缘经济政治构造时，会发生什么情况？如何应对？</p></blockquote><h2 id="第四章：外商直接投资与中国的经济安全"><a href="#第四章：外商直接投资与中国的经济安全" class="headerlink" title="第四章：外商直接投资与中国的经济安全"></a>第四章：外商直接投资与中国的经济安全</h2><p>招商引资与<strong>缺口论</strong>：中国为什么要吸引外资？</p><ul><li>资金缺口论：缺钱。这是没有解释力的，不论是外汇还是储蓄。</li><li>技术缺口论：资金本身不是资本，只有资金与特定行业的技术、管理、营销能力结合在一起的时候才成为资本。但是仍没有解释力，技术并未转移。</li><li>制度缺口轮：中国对民营资本的歧视，而对外资无影响，形成外资对内资明显的竞争优势。</li></ul><blockquote><p>中国吸引外资并非政策成就，而是中国经济体制缺陷的症状表现。</p></blockquote><p><strong>渐变的外资政策</strong>：</p><ul><li>地缘上：点到线到面</li><li>行业上：出口加工到一般制造到服务业</li><li>引资方式：合资、合作、外资企业等方式</li><li>引资政策背后导向：进口替代到鼓励出口到促进产业结构升级和调整</li></ul><p><strong>外资的贡献</strong>：</p><ol><li>协助中国转变在全球分工中的角色。</li><li>帮助缓解就业和大城市挑战。</li><li>帮助积累外汇。</li><li>提升中国的技术能力和产业层次。<ul><li>竞争效应</li><li>示范模仿效应</li><li>联系效应</li><li>培训效应</li></ul></li></ol><h3 id="关于外资的争论：“恐外症”“崇外症”及其本质"><a href="#关于外资的争论：“恐外症”“崇外症”及其本质" class="headerlink" title="关于外资的争论：“恐外症”“崇外症”及其本质"></a>关于外资的争论：“恐外症”“崇外症”及其本质</h3><p>本质是带有非理性的思维特征，对中国企业中国人的特质与潜能缺乏最起码的信心。谈论这个问题首先要搞清楚：“谁是外资”、“什么是国家经济安全”、“什么是垄断”。</p><p><strong>恐外症</strong>：</p><ul><li>中国外资依存度过高（考虑实际使用外资规模总额/GDP）<ul><li>我们只算了直接投资，算上间接投资的话，依赖程度并不高</li><li>压低人民币价格情况下计算的GDP是有问题的。</li><li>有根据的统计数据是外资的对外出口占中国出口量的比重。</li></ul></li><li>“斩首策略”：独资企业或者控股合资，进入市场时，将中方品牌束之高阁取而代之。<ul><li>市场的首席裁判员应该是价格而不是政治，被斩首说明产业出了问题。</li></ul></li><li>诉诸情感和道德而不是理性和法理。</li></ul><p><strong>崇外症</strong>：</p><ul><li>外资的优越性和价值被捧得太高，反过来支撑着这个优势。</li><li>对外资迷信的背后，是部分人不愿正视历史和现实，不愿向事实低头，不愿承认中国民营资本的实力和潜力。</li></ul><h3 id="外资政策的未来趋势及政治和战略潜力"><a href="#外资政策的未来趋势及政治和战略潜力" class="headerlink" title="外资政策的未来趋势及政治和战略潜力"></a>外资政策的未来趋势及政治和战略潜力</h3><p><strong>未来的调整方向</strong>：</p><ul><li>取消外资超国民待遇</li><li>将国内市场吸引力而不是廉价要素作为吸引外国直接投资的核心竞争力：中国从全球生产基地转变为一个全球最大市场。</li><li>积极参与甚至推动国际多边投资规则的制定。</li><li>平衡的吸收外国直接投资和间接投资资金。</li></ul><p><strong>产业升级</strong>：</p><ul><li>产业升级难以靠外资实现，高价值就业机会是世界各国政府努力竞争、想尽办法留在本国的东西，在国际市场上本来就稀缺。</li><li>政府及其资本触角在推动中国产业赶超和升级过程中扮演了很重要的角色，但是不同行业中政策绩效存在明显差别。</li></ul><p>案例中的<strong>教益</strong>：</p><ul><li>面向家庭个人的消费品，向民营资本开放越早越彻底，创新能力越强。国企改革适合扮演财务投资者角色，从管资产到管资本。</li><li>中国最大的优势在于中国的市场规模。我们应该把产业发展的希望主要寄托在别国国民和家庭（而非政府）能主导的行业中。</li><li>政府官员要相信本国私人企业家的潜能和潜力，要意识到自己能力有限。政府需要做的是意识到哪些产业出现问题，哪些地方资源配置效率低，并为生产力提升打开空间。<strong>一个好政府的主要任务是，确保没有人能不劳而获，让人民都劳有所得。</strong></li></ul><h2 id="第五章：人民币汇率于人民币国际化"><a href="#第五章：人民币汇率于人民币国际化" class="headerlink" title="第五章：人民币汇率于人民币国际化"></a>第五章：人民币汇率于人民币国际化</h2><h3 id="汇率的政治经济学"><a href="#汇率的政治经济学" class="headerlink" title="汇率的政治经济学"></a>汇率的政治经济学</h3><p>一般观点：<strong>货币即是权力</strong>，即使是和平时期，金融业也是受制于政治需要的。</p><p><strong>不可能三角</strong>：</p><ul><li>资本流动、固定汇率、货币政策独立性三者不能同时成立。</li><li>固定汇率制度下财政政策有效，浮动汇率政策下货币政策有效。</li></ul><p><strong>不同立场的汇率偏好</strong>：</p><ul><li>出口海外投资型偏好汇率稳定，依靠国内市场的则更希望货币政策独立。</li><li>生产贸易品部门偏好固定汇率，生产非贸易品（金融业）部门偏爱浮动汇率。</li><li>中右翼政党更厌恶通货膨胀，左翼更关心失业率。</li><li>执政稳定政党汇率偏向弹性和高估（长远经济目标低通胀），执政不稳政党偏向干涉本币维持低估。</li></ul><h3 id="人民币汇率波动后的政治"><a href="#人民币汇率波动后的政治" class="headerlink" title="人民币汇率波动后的政治"></a>人民币汇率波动后的政治</h3><p><strong>人民币汇率制度的改革</strong>：</p><ul><li>1981-1984：盯住一揽子货币，双轨制，汇率下跌，扶持出口。</li><li>1985-1993：双轨外汇制度，管理浮动，汇率持续下跌，恶化国内通胀。</li><li>1994-2005：盯住美元，汇率长期稳定，促进经济发展。但是前期合理后期僵化，入世后应做调整。</li><li>2005-2013：盯住一揽子货币浮动管理，目标维持出口和就业稳定减少顺差，对美元稳定升值，导致套利行为，助长本土资本泡沫。</li><li>2013之后：参照一揽子货币双向波动，从汇率干预中逐步淡出，目标从被全球流动性绑架的货币政策中解放出来，波动性扩大但是保持强势和稳定，有助于打击套利，热钱流入减少。</li></ul><p><strong>对应的政治</strong>：</p><ul><li>1972-1980：人民币高估不利于出口，贬值又会在非贸易项目吃亏，于是双轨制，贸易非贸易采用不同汇率。</li><li>1985之后：中央地方博弈，政府企业博弈，官方汇率和市场汇率并存。</li><li>1997 亚洲金融危机宣布不贬值，考虑国际形象和香港金融的稳定，同时当时外汇储备高，中央财政资源增强。这一行为奠定了中国在争取东亚地区领导地位的国家信用基础。</li><li>1998年之后盯住美元，不愿意恢复弹性，是在当下结构性失业背景下提出的。</li><li>2005年之后发现汇率低估不利于产业升级，所以开始稳步升值。</li></ul><h3 id="人民币国际化"><a href="#人民币国际化" class="headerlink" title="人民币国际化"></a>人民币国际化</h3><blockquote><p>一个经济强国的货币在实现了自由兑换后，被其他国家接受，成为国际支付和处置手段，我们称这种货币为国际货币。</p></blockquote><p>人民币国际化的<strong>利弊</strong>衡量：</p><ul><li>好处：铸币税、节约外汇储备成本、降低汇率风险、扩大贸易投资、可以对外转移宏观经济风险。</li><li>负面代价和风险：<ul><li>低端产业挤出效应。</li><li>经济泡沫化风险（吸引巨量游资）。</li><li>放大汇率波动（大量流入流出）。</li><li>货币政策会收到海外存量货币的影响。</li></ul></li></ul><p>人民币国际化并不难，向外“送钱”即可。难的是让它的<strong>负面代价最小化</strong>。日本国际化就是我们的反面教训。</p><p>人民币国际化的<strong>机遇</strong>：</p><ol><li>2008年之后全球货币结构的动荡。</li><li>中国积累了足够的经济实力，且有良好的工业基础。</li><li>美欧亚并驾齐驱，但是在亚洲日元难堪重任。</li></ol><p>人民币国际化的进展：</p><ul><li>2012年人民币国际化指数0.56到15年3.91，18年4.84，在震荡中增长。</li><li>政府管制方式重大变化，顺应市场需求政革放权。</li><li>2013开始跨境结算支付规模上升，2017年下降至2012年来最低水平。</li><li>涉外部门统计和管理中人民币计价。</li><li>海外人民币清算行。</li><li>人民币跨境支付系统 CIPS。</li></ul><h3 id="人民币国际化和资本项目放开的政策辩论"><a href="#人民币国际化和资本项目放开的政策辩论" class="headerlink" title="人民币国际化和资本项目放开的政策辩论"></a>人民币国际化和资本项目放开的政策辩论</h3><p>央行支持主张放开。一部分经济学家，包括社科院北大的学者提出批判质疑，反对放开。两者展开了辩论：</p><ol><li>从利弊上看：<ul><li>支持者认为放开的好处：<ul><li>更多融投资机会，优化资源配置</li><li>创造非政府部门资本流出途径，避免实体经济硬着陆</li><li>倒逼国内改革</li></ul></li><li>反对者的焦虑：<ul><li>资金外流对国内产业负面冲击</li></ul></li></ul></li><li>从开放和改革的顺序上看<ul><li>央行认为可以同步审慎进行</li><li>一部分学者认为先改革再开放</li></ul></li><li>开放倒逼改革的理念<ul><li>反对者认为以外促内风险性高，历史上不乏失败案例</li></ul></li><li>要不要公布开放时间表<ul><li>反对者认为给出开放时间表不如给出推动国内结构性改革时间表</li><li>支持者认为时间表有必要。因为开放的实际利益受损者是权力部门，让受损者制定开放的方案推动起来会很难</li></ul></li></ol><p>辩论的<strong>三个特点</strong>：</p><ol><li>对风险的认知和态度存在很大差异。</li><li>双方都是列举归纳，缺乏整体主义视角。不完全归纳无法说服对方。需要有整体视角，用演绎法而不是归纳法。</li><li>双方对“应然”和“实然”的侧重。</li></ol><h3 id="国际化的条件和战略"><a href="#国际化的条件和战略" class="headerlink" title="国际化的条件和战略"></a>国际化的条件和战略</h3><p>阶段：</p><ol><li>区域性国际化，东亚与部分发展中国家展开。</li><li>成为国际金融活动媒介和国际金融资产。可以使用美元当年“先挂钩后脱钩”的策略来获取信心。</li></ol><p>步骤：</p><ol><li>国内多层次资本市场和银行体系改革</li><li>升级产业结构和提高技术能力</li><li>全球资产投资和并购渠道的建设</li></ol><h2 id="第六章：外汇管理政策与外汇储备"><a href="#第六章：外汇管理政策与外汇储备" class="headerlink" title="第六章：外汇管理政策与外汇储备"></a>第六章：外汇管理政策与外汇储备</h2><p><strong>外汇储备实际上是替外资保管的金银细软</strong>。但是也是一种前所未有的对外政策工具，政治上实现了“金融恐怖平衡”，大大弥补了中国整体国力尤其是军事能力方面的弱势。</p><h3 id="外汇管理制度的改革与储备的形成"><a href="#外汇管理制度的改革与储备的形成" class="headerlink" title="外汇管理制度的改革与储备的形成"></a>外汇管理制度的改革与储备的形成</h3><blockquote><p>外汇储备：当局（不包含民间）能够有效控制并可随时动用的对外资产。</p></blockquote><p>中国的外汇储备是在“强制结售汇政策”，“银行外汇周转头寸限制”，“盯住美元汇率政策”三位一体的制度安排下形成的。以10%的复合收益率估算，我们外汇储备规模远远小于外资在中国经济体内部的资产积累。</p><p><strong>之后外资撤出大量挤兑时怎么办？</strong>市场有风险，买卖自愿，人民币可以接受一定程度的本币贬值。</p><h3 id="外汇储备的经济含义"><a href="#外汇储备的经济含义" class="headerlink" title="外汇储备的经济含义"></a>外汇储备的经济含义</h3><ol><li><strong>为什么</strong>要积累巨额外汇储备？<ul><li>底部贸易赤字、保证偿付的外汇需求、维护汇率稳定、灾难时的战略储备。</li></ul></li><li>到底应该<strong>如何看待</strong>中国的外汇储备？<ul><li>外汇储备的高速不平衡增长源于国内金融体系的功能缺陷，效率低下，无法将储蓄转化为有效投资。</li><li>只要我国国内金融体系与国际金融体系存在较大的效率差异，我国就只能通过这种“体外”资本循环方式支持国内经济增长。</li><li>导致了巨大的机会成本</li></ul></li><li>中国积累多少外汇储备合适？外储如何实现<strong>保值升值</strong>？<ul><li>维持正常的需求，7000亿之内。</li><li>国债投资转为优质企业股权投资（例如淡马锡、阿布扎比投资局、挪威养老基金）。</li></ul></li><li>如何<strong>控制</strong>外汇储备的过度增长？<ul><li>改善国内金融市场，民间金融合法化</li><li>拓宽对外直接投资的空间</li><li>加大人民币汇率弹性，减少游资套利空间</li></ul></li></ol><h3 id="外汇储备与“中国-美国”"><a href="#外汇储备与“中国-美国”" class="headerlink" title="外汇储备与“中国-美国”"></a>外汇储备与“中国-美国”</h3><p>中国明知持有的美元存在贬值倾向，但是不能卖出，因为如果卖出美元，那么美元将出现恐慌性贬值，导致自己手中剩余的美元资产缩水。中国所能做的就是与美国政府谈判，警告他们不要做出背叛的行为，否则两败俱伤。</p><blockquote><p><strong>金融恐怖平衡</strong>：我们（美国）依赖的是他国不对美国赤字融资所需偿付的代价，（也即）他国一旦停止融资需要偿付的代价（是如此之大），确保了他国将继续融资。</p></blockquote><p>中美之间数十年相对成熟稳定的主要原因是因为存在“核恐怖平衡”和“金融恐怖平衡”。平衡中中国处于相对弱势。随着中国新世纪出口多元化，对美依赖减轻，谈判地位强弱之势悄然异位。</p><p>中国意识到这种关系不可持续，所以逐步从“三外路线”循环中脱离。中美关系少了重要的稳定器，如何维持一个较低成本的可持续和平环境？并且全球经常项目和资本项目顺差在中国周边大规模聚集是存在安全和政治前提的，就是东亚和平与稳定。</p><blockquote><p>由于美国目前仍然主导着东亚地区的和平与安全格局，那就潜在的出现了一个巨大的套利机会：跳起某个地区性的冲突并放手升级之，结果将是东亚资本的极速外逃，美国的融资问题一夜间获得解决，尽管这是一种杀鸡取卵的不可持续的解决方法。</p></blockquote><h3 id="储备多元化及其政策后果"><a href="#储备多元化及其政策后果" class="headerlink" title="储备多元化及其政策后果"></a>储备多元化及其政策后果</h3><p>中国持有大量美元，但其实是美元的<strong>空头</strong>，而不是多头。华尔街跟庄，中国外汇储备增大时，他们就做空美元做多欧元，减小时就相反。那常识为什么错了？外管局结售汇过程中收入的资产重新配置为美元资产和非美元资产。就是买入外汇资金然后配置。买入端美元比例极高（例如80:20）（由于美元可获得性高），然后配置时比例（50:50），其实是在卖出美元，买入非美货币。所以当资产配置在美元上绝对数目多时，其实已经售出了大量的美元。</p><p>作为美元的空头，中国外汇储备面临何种风险？当然是美元上升周期。</p><ul><li>外汇储备名义价值下降，欧日元资产贬值。</li><li>金融系统投入矿业和原油的信贷将面临风险。</li><li>不能陷入被逼空的状态。</li></ul><p><strong>美元的上行一般由以下因素驱动</strong>：</p><ul><li>美国经济领先于日欧复苏</li><li>失业率下跌到6.5%以下</li><li>美国能源独立导致逆差减少</li><li>中国因素（空头力量其实在衰减）</li></ul><p>被<strong>全面逼空</strong>的前提条件：</p><ol><li>美元超级强势周期</li><li>巨额资本逃离</li><li>出现新制造业大国</li><li>国内通胀高企，人民币没有贬值空间</li><li>中国产业转型面临失败</li></ol><h2 id="第七章：中国对外资本输出"><a href="#第七章：中国对外资本输出" class="headerlink" title="第七章：中国对外资本输出"></a>第七章：中国对外资本输出</h2><p>中国正在从一个（产业）资本净输入国变成净输出国。</p><h3 id="中国企业“走出去”"><a href="#中国企业“走出去”" class="headerlink" title="中国企业“走出去”"></a>中国企业“走出去”</h3><p>中国企业“走出去”对提升巩固中国在世界市场体系中的地位具有重大意义。政府也改革投资体制，鼓励本地企业国际直接投资。</p><p>“走出去”的<strong>动机</strong>：</p><ul><li>获得市场</li><li>获得外部生产要素：能源、原材料、技术、研发能力、品牌</li><li>往返程投资：打扮成外资回归</li></ul><p>“走出去”的<strong>问题和挑战</strong>：</p><ul><li>国有企业的体制问题：监管不到位容易贪污和资本外逃</li><li>民营企业融资担保和保险问题</li><li>企业和个人要在行为方式上严格约束自己，要合规合法道德</li><li>企业对外直接投资的政策体系和服务体系不完善</li></ul><p>自主品牌国际推广过程为<strong>中国国际公关提供政策杠杆</strong>：成为西方媒体的大客户，则会拥有对他们施加压力的重要杠杆，他们在报道中国的时候会有所顾忌。</p><h3 id="中国资本输出的现状和未来"><a href="#中国资本输出的现状和未来" class="headerlink" title="中国资本输出的现状和未来"></a>中国资本输出的现状和未来</h3><p>输出的现状：</p><ul><li>1978-2000：建立经济特区吸引资本</li><li>2001-2012：加入 WTO 引入输出并重，央企海外并购</li><li>2013-至今：输出为主，兼顾引入</li></ul><p>输出的<strong>主体</strong>：</p><ul><li>国有企业为主：效率低下，动机模糊，意识形态上被怀疑</li><li>民营企业很少：天赋惊人，家族地缘为基础信用网络融资，但是目光短视</li></ul><p><strong>战略方向和地缘空间</strong>：</p><ul><li>金砖体系、一带一路</li><li>西南西北产业聚集带</li><li>西部大开发升级</li></ul><h2 id="第八章：国际投资规则的制定权争夺"><a href="#第八章：国际投资规则的制定权争夺" class="headerlink" title="第八章：国际投资规则的制定权争夺"></a>第八章：国际投资规则的制定权争夺</h2><h3 id="主权财富基金的发展及其投资规则之争"><a href="#主权财富基金的发展及其投资规则之争" class="headerlink" title="主权财富基金的发展及其投资规则之争"></a>主权财富基金的发展及其投资规则之争</h3><p>主权财富基金是一种政府金融投资工具。与外汇储备不同，它偏好更高收益率。从资金来源看，主权财富基金可以分为三类：</p><ul><li>贸易外汇盈余</li><li>资源出口外汇盈余</li><li>国际援助</li></ul><p>2007年开始，西方政界开始担心主权投资中钱的所有者之意图和潜能，担心出于政治和战略目的而不是商业盈利目的的大规模买卖。所以下方一直主张制定一些“国际制度”来约束我们。<strong>西方国家一方面想要这个资金，另一方面又害怕金融核武器。</strong>目前来看，国际新规者制定主导权基本掌握在美欧手中。但是其实美欧之间，各大经济体内部也存在分歧。但是仍有一些<strong>共同诉求</strong>：</p><ul><li>通过非正式国际立法来约束和规范主权基金，并将规则的制定权和监督过程掌握在美欧控制的 IMF 和 OECD 手中。</li><li>从道义上贬低、法律上禁止实践中防范各国主权基金出于政治与安全动机的投资行为。</li><li>要求主权基金提高透明度。</li><li>在此前提下，维持各国资本市场的开放。</li></ul><p>于是美欧采取了一些明确的策略和措施：</p><ol><li>以美欧主导的多边经济组织作为工具，制定规则，拉拢引诱世界各国接受作为未来谈判的基础。</li><li>制造国际舆论并炒作形成国际共识</li><li>分而治之，压迫小国主权基金满足规范，塑造国际惯例。</li></ol><blockquote><p>我们在贸易、裁军、气候变迁等各种全球治理问题谈判中，已经反复得到如下经验和教训：参与到国际规则的制定中是维护国家利益的第一步，也往往是最关键的一步。</p></blockquote><p><strong>中方立场</strong>：</p><ol><li>鼓励而不是禁止出于政治目的的投资</li><li>提高透明度应该是在坚持联系原则和自主原则两大基本前提下进行。</li><li>维持美欧资本市场开放下是对主权基金东道国的合理补偿，也是维持全球金融经济秩序稳定可持续的基本前提。</li></ol><p>当越来越多的资产和股权被划为非卖品的时候，他们所支撑的货币将会不可挽回的越来越疲软。</p><h3 id="当前谈判地位和可选策略"><a href="#当前谈判地位和可选策略" class="headerlink" title="当前谈判地位和可选策略"></a>当前谈判地位和可选策略</h3><p>当前逆来顺受，被动妥协。</p><p>措施和策略：</p><ol><li>搞一个功能性同盟，把有共同利益的国家拉到一起，成立一个新的投资者俱乐部。团结有大量资本的依附性小国。</li><li>扶持急需外来投资的中小国，塑造我们的国际惯例。</li><li>自主研讨会，探讨全球主权基金投资规则。</li><li>假如能团结几大主权基金，则在谈判桌上能制定有利于资方的规则。</li></ol><h3 id="国际投资法与中国的选择"><a href="#国际投资法与中国的选择" class="headerlink" title="国际投资法与中国的选择"></a>国际投资法与中国的选择</h3><p>世界范围<strong>投资法的发展</strong>：</p><ul><li>多边国际投资法尝试，但是普遍失败</li><li>双边投资条约的发展</li></ul><p>中国处于一个吸收投资和资本输出的双重身份中。但是大背景是投资规模会超过吸纳投资：所以中国新世纪以来的投资协定，采纳了类似美式范本的高标准投资保护机制。</p><h2 id="第九章：超越“能源安全”"><a href="#第九章：超越“能源安全”" class="headerlink" title="第九章：超越“能源安全”"></a>第九章：超越“能源安全”</h2><p>不论是从人均还是未来前景看，中国都缺能源。国际能源炒家以能源安全剥削中国。但是高油价也许并非坏事，中国进口量远小于体系中央国家。如果油价使中央财富流向边缘，那么可以通过对边缘国家的出口把钱赚回来。所以要跳出有人营造的恐慌情绪，跳出那些直接的局部的利益得失，才能冷静的全面辩证看待能源在中国国家战略中的意义。</p><h3 id="能源问题的若干基本常识"><a href="#能源问题的若干基本常识" class="headerlink" title="能源问题的若干基本常识"></a>能源问题的若干<strong>基本常识</strong></h3><ol><li>能源生产消费在地域分布上严重失衡。</li><li>能源结构走向多元化，化石能源仍是主体。</li><li>能源是世界上贸易规模最大的大宗商品。</li><li>能源问题被高度政治化。</li></ol><h3 id="中国的能源安全"><a href="#中国的能源安全" class="headerlink" title="中国的能源安全"></a>中国的能源安全</h3><p>什么是能源安全？狭义：可以安全供应，是可以充分稳定经济的获取发展所需要的能源。</p><p>中国的能源安全可以分解为<strong>四个环节</strong>：</p><ol><li>能源供给安全：有时是非卖品，所以需要同时使用市场和外交两种手段</li><li>能源价格安全：并不是越廉价越好</li><li>能源运输安全：防范被截断</li><li>能源消费安全：环境气候危害</li></ol><p>中国的能源缺口是常见的夸大之处，其实缺口不大，有时甚至供大于求。能源安全运输也被夸大，马六甲海峡其实可以替代。</p><h3 id="高油价利于中国崛起"><a href="#高油价利于中国崛起" class="headerlink" title="高油价利于中国崛起"></a>高油价利于中国崛起</h3><blockquote><p>为了中国整体国家利益的最大化，中国在适当的时候有必要托起石油价格。</p></blockquote><ol><li>较高油价可以维持有利于中国的全球战略平衡。<ul><li>我们希望确保美国在任何时候都无法集中足够的力量、意志和盟友资源对华实施战略摊牌。</li><li>能源价格越高，中东地区财政力量越强，越有能力为美国及其盟友制造麻烦。</li><li>如果能源价格暴跌，很多国家包括俄罗斯都会陷入财政困境。</li></ul></li><li>托举油价在经济上也是合算的<ul><li>油价维持较高位置，有利于中国扩大对外围体系国家出口投资，将托市成本赚回来。</li><li>适度托举油价有利于提升中国在国际能源市场上的定价权。</li><li>拥有巨额石油储备之后，可以避免逼空。</li></ul></li><li>熨平能源价格波动是大国的国际责任<ul><li>帮助发展中国家应对能源诅咒</li><li>我们的战略储备基地已经竣工</li></ul></li></ol><h2 id="第十章：原材料市场中国的定价权"><a href="#第十章：原材料市场中国的定价权" class="headerlink" title="第十章：原材料市场中国的定价权"></a>第十章：原材料市场中国的定价权</h2><h3 id="原材料市场的三个关键问题"><a href="#原材料市场的三个关键问题" class="headerlink" title="原材料市场的三个关键问题"></a>原材料市场的三个关键问题</h3><ol><li>市场结构与定价权。即便我们在生产规模和莫呕血消费规模上是最大的，但是如果市场分散无序，在国际市场上仍不会有定价权。所以对国内市场整合，用国内的联合协作对付国际上跨国公司的联合垄断，才能扭转地位。</li><li>资源配置到底应该以价格还是权力为杠杆？以价格为杠杆可以让整体福利和效率最大化。但是国际市场非充分开放。中国应该用现实主义确保自己的安全利益，再用理想主义去推动开放。</li><li>资源能源与金融和货币关系。一个国家在拥有国际影响力的大宗交易产品市场，那么该国在争夺相关商品全球定价权时便获得了不可小视的技术型便利。</li></ol><h3 id="开放经济环境下的中国粮食安全"><a href="#开放经济环境下的中国粮食安全" class="headerlink" title="开放经济环境下的中国粮食安全"></a>开放经济环境下的中国粮食安全</h3><p>粮食具有作为重要战略资源的政治经济特性。其需求刚性生产周期性，价格弹性小。</p><blockquote><p>当前分工：外围国家从美国及其盟友进口粮食，自己则专门生产经济作物。当年管仲所用的战略模式，今天在体系大国和外围小国之间悄悄重演。</p></blockquote><p>对中国人来说，中国人什么都吃，是这个民族历史上所受苦难的遗迹和明证。目前来看，从供求关系来看，中国粮食自给有余，基本平衡；从战略态势来看，中国是在勉强防守，态势堪忧。</p><p>当前的平衡能维持，是因为中央政府比较富裕。如果不能维持，则要内部深度挖掘潜力，等待人口总量下降。但是未来三十年，我们<strong>通过内部挖潜维持平衡的难度将越来越大</strong>：</p><ol><li>人民币汇率上涨，粮食美元计价成本高，维持粮食产量则需要增大补贴（杠杆成倍放大补贴）。</li><li>工业化城市化，精耕细作失去其劳动力基础。</li><li>水资源匮乏限制粮食增长。</li></ol><p><strong>对于全球粮食格局的三个基本判断</strong>：</p><ol><li>全球人口增加将为粮食安全带来巨大挑战，为美国国家权势反弹埋下伏笔。</li><li>世界不缺耕地，也不缺潜能，缺的是耕地与高科技农业劳动力的错配。</li><li>粮食安全不能单纯依赖市场，必须有大国出来平抑粮价。</li></ol><p>中国未来粮食安全的长期<strong>解决出路</strong>是大规模农业资本输出：</p><ol><li>政府出面包租购买土地。出资本管理技术，粮食按比例分成。</li><li>合同由政府签，经营由市场吸引国内农业企业承包。</li><li>控制中方农技人员数量与东道国结合。</li><li>中方企业粮食分成由中国官方投资机构保价收购，返销国内，或者在其他地区建立储备库用于平抑波动。</li><li>国内建立更大规模粮食储备能力。</li></ol><h3 id="疯狂的石头：铁矿石进口及其谈判"><a href="#疯狂的石头：铁矿石进口及其谈判" class="headerlink" title="疯狂的石头：铁矿石进口及其谈判"></a>疯狂的石头：铁矿石进口及其谈判</h3><p>乌克兰中国铁矿石储量大，但是贫矿多富矿少，含铁量低。从铁产量上来看，澳大利亚和巴西是最主要的两个铁矿石生产大国。世界最大的铁矿石厂商位于巴西的淡水河谷，86亿吨高品位铁矿石储量。铁矿石主要进口方是中日韩欧。</p><p>在铁矿石价格谈判中，中方2003年开始参与。宝钢作为代表参与谈判。宝钢在谈判中没有考虑到其他钢企的利益。2009年宝钢退出谈判，中钢协接手。他们站在维护国家整体利益的立场谈判，“宁可谈判破裂也不妥协”，但是对于企业实际需求和市场谈判经验不足。2010年，宝钢重新占据谈判主导权。2012年初，铁矿石现货交易平台启动。2012年以来进口地区经济增长放缓，铁矿石产量却屡创新高，价格走低，转变为买方市场。2014年，我国开始涉足铁矿石期货的金融服务，旨在推动人名币计价、清算和结算铁矿石，是金融市场的创新，也满足实体经济套期保值的需求。</p><p>中国决策者意识到美元存款的不可靠和矿藏价格低迷的机遇。于是鼓励国企央企走出国门收购海外矿山资源。2009中国铝业收购力拓赔了夫人又折兵。五矿收购 OZ Minerals 旗下核心资产则获得良好收益。</p><p>有专家认为，如果要改善目前处境则需要在内部贸易和公平性下功夫，改变国内钢企一盘散沙的局面。也有学者提出取消钢铁产品出口退税。</p><h3 id="稀土"><a href="#稀土" class="headerlink" title="稀土"></a>稀土</h3><p>我国稀土储量占全球71.1%，产量95%。却不能像石油和铁矿一样控制全球价格，这是因为企业互相杀价，导致价格低位运行。（其实国外也有大量的未开采稀土矿，因为其相对于中国稀土不经济所以仍未开采。）</p><p>中国政府试图实现稀土行业全行业整合。2009年对我国储量产量第一的三种矿保护性开采。并鼓励企业走出去收购国际重要稀土矿资源。对保护性开采，西方国家强烈反对。但是这并没有违背国际贸易准则，且符合国际惯例。</p><blockquote><p>联合国《建立新的国际秩序宣言》：每个国家对自己的自然资源和一切经济活动拥有充分的永久主权。为了保卫这些资源，每个国家都有权采取适合自己的手段，对本国资源及其开发实行有效控制……任何一国都不应遭受经济、政治或其他形式的协迫，以致不能自由地和充分地行使这一不容剥夺的权利。</p></blockquote><p>中国稀土政策的若干选项：</p><ol><li>提高关税，控制出口配额：有利于内外价差，和新能源产业的先手。</li><li>对矿企征收高额环境税和资源税：利益留在中国，抬高全球价格，但是没有保护国内科技企业利益。</li><li>稀土金融化、货币化、储备化（像黄金一样）：财富增值，但是降低其使用价值。</li></ol><h2 id="第十一章：中国的对外援助"><a href="#第十一章：中国的对外援助" class="headerlink" title="第十一章：中国的对外援助"></a>第十一章：中国的对外援助</h2><h3 id="中国援外的历史和现实"><a href="#中国援外的历史和现实" class="headerlink" title="中国援外的历史和现实"></a>中国援外的历史和现实</h3><ol><li>新中国成立后30年：<ul><li>中国对外经济技术援助八项原则</li><li>大力援外并不是过度承担国际义务，影响自身发展，而要与当时冷战的背景结合理解。（但是这里也没说怎么理解。）</li><li>第一代领导人，世界革命的背景</li><li>谋势，用较小成本获得国家声望</li></ul></li><li>“三外路线”下的援外<ul><li>随着人民币贬值，受援国感到援助力度减小</li><li>自身经济扩张，援助占本国财政份额下降</li><li>第二代领导人，优先本国经济发展</li><li>无偿援助变贴息贷款，大型项目变中小型项目等</li><li>谋利，不求改变体系而是融入体系</li></ul></li><li>援外工作新高潮<ul><li>为了确保能源原材料供给，重新活跃</li><li>与西方国家口惠而不实形成对比</li><li>强调双赢</li><li>美欧认为中国援助：<ul><li>涉及一些对专制政权的援助</li><li>不干涉内政不利于改善全球治理水平</li><li>利用援助做为争夺原材料的辅助手段</li><li>很少雇佣当地人，不利于当地经济发展</li></ul></li></ul></li></ol><h3 id="构建中国特色援外理论"><a href="#构建中国特色援外理论" class="headerlink" title="构建中国特色援外理论"></a>构建中国特色援外理论</h3><p>自利利人的<strong>审慎道德</strong>原则：重塑对外援助的政治伦理基础</p><ul><li>援助宣传中的道德主义是一种陷阱，大家的援助都被诟病的原因在于，大家普遍使用很高的道德标准来要求和评价援助行为。</li><li>援助和意识形态的捆绑，无益于国家间的稳定和良性互动。</li><li>国家的对外援助不是慈善活动，而是理性的广义的国家利益拓展的需要。</li><li>审慎性道德准则：用人的标准来要求而不是神的标准来要求人，不通过损害他人以自利。</li><li>审慎道德标准低调可行可持续。</li><li>中国援助行为的特点：心理上平等，事理上互利。</li><li>中国人明白：对于落后者而言，尊严往往比五斗米更值得珍惜。</li></ul><p>在符合审慎道德原则下，<strong>国际援助的必要性</strong>：</p><ol><li>增进国家人民间信任友谊和认同，利于体系持久和平。</li><li>有殖民原罪的国家，有义务提供援助：假如先辈犯罪而获得好处至今仍为当代人享用，那么赎罪是援助不单是消除负罪感，更是一种政治和道德的必须。</li><li>全球市场中心的大国，发达国家从风险收益不对称获利巨大，代价由外围国家承担，补贴外围国家是平衡体系内生的不公平。</li><li>贫困和混乱会溢出到其他国家和地区，影响富国的长期利益。</li></ol><p>干涉与良治：援助中的主权问题：</p><ul><li>用财力逼他人就范，实际也是一种专制</li><li>任何人手中都不拥有绝对真理</li><li>在一国经济技术水平和社会结构非常落后情况下，强求发展民主可能是拔苗助长的做法。</li><li>援助者不应随意对他国家庭内部事务发表见解。</li></ul><h3 id="改进中国的援外政策"><a href="#改进中国的援外政策" class="headerlink" title="改进中国的援外政策"></a>改进中国的援外政策</h3><ol><li>重视人的作用<ul><li>争取当地民心，不能只惠政府</li><li>重视人员交流，服务民生</li></ul></li><li>改革援外决策和管理机制<ul><li>缺乏协调统一的高于各部委的决策部门</li><li>随意性较大缺乏论证</li><li>权利竞争，责任推诿</li><li>未纳入法制化轨道</li><li>企业和非政府组织的高效对外援助还有很大空间</li><li>应该争取本国民众理解</li></ul></li><li>集中援助树“典型”<ul><li>“撒胡椒面”难以产生强大的初始动能</li><li>评估上来说如果该国更依赖中国市场而不是中国政府，则援助成功</li><li>对其他国家对华政策产生诱导作用</li><li>安哥拉模式就是很好的例子</li></ul></li><li>援外和资本输出结合<ul><li>形成合力，良性循环</li><li>滚动发展，使对外援助在中国内部具有经济效益上的可持续</li><li>这种援助某种意义是一种投资</li><li>在和美元脱钩后，我们需要使对外援助在中国对外经济关系中具有不可替代性，要让其真实成本降低。</li><li>援助形成的友好氛围，基础设施可以为投资创造条件和抬高收益率</li><li>土地矿权股权有获得资本增值机会</li><li>金融危机救援，救急不救穷，别人做不了的事情往往最有利可图</li></ul></li><li>改进对援外事物的宣传<ul><li>拿出少量美元储备以贷款方式援助是出于对国家利益的整体长远考虑</li><li>民众认为政府拿着本来属于自己的财富白送给别人，这反映出：<ol><li>货币知识的缺失：美元不能用在国内，不用掉只能躺在美元债券，不能支付国内贫困学生的学费或者为苦难群众造房子。</li><li>民生问题关注度高</li><li>宣传技巧有进一步提升空间</li></ol></li></ul></li></ol><h2 id="第十二章：结论：中国对外经济关系的潜能和风险"><a href="#第十二章：结论：中国对外经济关系的潜能和风险" class="headerlink" title="第十二章：结论：中国对外经济关系的潜能和风险"></a>第十二章：结论：中国对外经济关系的潜能和风险</h2><h3 id="关于两组关系的探讨"><a href="#关于两组关系的探讨" class="headerlink" title="关于两组关系的探讨"></a>关于两组关系的探讨</h3><ol><li>国家与市场间的关系<ul><li>国家很重要，但是如果光靠国家控制，没有市场来配置资源，那么经济必然缺乏活力，最终国家力量也会衰竭。市场的确很高效，但是离开了国家力量的规范和约束，市场秩序和市场结构难以自我维持。</li><li>为了在全球市场获取超额利润，内部非市场化往往是一种必须，有选择有分寸的搞些政府管制，尽管会不可避免的导致资源配置效率损失，但是由于这种管制获得了外部博弈的优势，那么超额利润可能足够弥补内部损失。</li></ul></li><li>中国与体系间的关系<ul><li>哪个国家越能够全面彻底有效地把人类整合到全球性的交易分工和要素流动中来，就越能得到“天命”的资助。（世界市场体系对各地区各文明的吞噬消化和整合。）</li><li>我们将用什么办法来实现比美国时代更加全面深入有效的整合全球的经济要素？</li><li>我们如何在主导权更替的过程中尽可能实现和平禅让而不是物理决斗？</li></ul></li></ol><h3 id="“三外路线”是否可以向外围国家推广"><a href="#“三外路线”是否可以向外围国家推广" class="headerlink" title="“三外路线”是否可以向外围国家推广"></a>“三外路线”是否可以向外围国家推广</h3><ol><li>“三外路线”的<strong>普适性</strong>：<ul><li>体系外围国家：资本缺乏，工业技术能力落后，层次较低，人才匮乏，制度落后，国内治理混乱。互为因果互相牵制。</li><li>三外路线使中国一下子摆脱了资本匮乏，也让其他方面逐步改善。同时快虚积累外汇储备，增强了抵御系统性风险的能力。</li><li>三位路线可以看成一种融资模式，向他国（产业资本）融资，向未来融资，从而在特定地域和时间点上集中足够密集的资本规模，实现发展的突破，开启发展的正循环。</li></ul></li><li>“三外路线”的<strong>推广</strong>：<ul><li>向一部分发展中国家推荐，对中国有以下好处：加速产业升级和对外转移趋势，减少美欧贸易顺差但是不会损减整体福利，出口数量损失换来的是质量提升，在国家间形成不对称依赖，符合人民币国际化内在需求。</li><li>美欧应该不会反对此路线</li><li>适用性前提：<ol><li>资源富集劳动力匮乏就不适用</li><li>要求政府对社会有很强的渗透控制能力</li><li>出口加工工业的地理要求</li><li>民族文化对勤劳节俭的鼓励（较容易改变，例如70年代被认为懒惰，90年代勤奋。）</li><li>竟然制度变迁可以大幅度改造中国民众的生活方式，为什么对非洲或者其他地区人民持悲观态度呢？</li><li>时机问题，目前中国资源密集型产业向外转移</li></ol></li></ul></li></ol><h3 id="中国对外经济关系战略潜能"><a href="#中国对外经济关系战略潜能" class="headerlink" title="中国对外经济关系战略潜能"></a>中国对外经济关系战略潜能</h3><blockquote><p>中国已积累了罕见的经济实力，但是执政者还不善于用这种实力寻求国际抱负。</p></blockquote><p><strong>对各章探讨的对外经济关系各个方面潜能加以总结</strong>：</p><ol><li>参与国际经济分工时，可以使用自身各方面优势塑造周边中小国对中国的不对称依赖。</li><li>集中了世界最大的外汇官方储备可以通过耐心大胆巧妙的长期投资把手中外汇变成世界主要跨国企业的控制权，形成网络化的非正式权力。</li><li>推动人民币国际化，修正货币格局，让东亚在世界经济体系获得更有利的位置，并对美国国际权势基础形成瓦解作用。</li><li>中国企业走出去创建品牌的时候，中国的外宣系统应当加以支持和利用，获得世界各地主流媒体的影响力。</li><li>借助自身资金和市场规模，应该有选择的调控全球基础原材料的价格，拥有部分定价权。</li><li>对外援助和资本输出结合起来，在体系外围国家扮演金融和货币危机救援者的角色，形成中国援助品牌。</li></ol><p><strong>这些构想的实现需要中国的决策和执行体系做必要的改革，尤其是将对外经济事务同涉外政治事务之间的制度性藩篱消除掉。</strong>比较现实的政策建议，通过边际性改革促进对外战略和对外经济政策之间实现若干功能性的结合。</p><h3 id="对外经济关系的风险"><a href="#对外经济关系的风险" class="headerlink" title="对外经济关系的风险"></a>对外经济关系的<strong>风险</strong></h3><p><strong>2010-2020:</strong></p><ol><li>货币政策与泡沫化风险：<ul><li>这里不是说价格高得让人难以理解就是泡沫，而是符合某种特点的价格运动过程。（自我增长自我毁灭的循环。）</li><li>外资的投资行为，造成了人民币升值的事实，又使外资“理性决策”，继续投资。</li></ul></li><li>全球化退潮风险</li><li>对外投资效率风险<ul><li>国有企业体制缺陷，对人激励约束不充分</li><li>民营企业规模小，资本有限</li></ul></li></ol><p><strong>2020-2030:</strong></p><ol><li>逆全球化纵深发展，中美经济持续脱钩，并各自组团将全球市场再次变成相互平行而竞争的两个体系。</li><li>美国国内的债务周期将迎来巨幅调整阶段。<ul><li>2021年前后巨额的债券到期，借新还旧不可持续成本提高，除非大幅降息。</li></ul></li><li>一带一路面临的挑战，没有很好的回答以下问题：<ul><li>发展中国家缺什么发展不起来？<ul><li>可能并不是钱，而是现代主权国家治理能力和治理体系。</li></ul></li><li>我们通过一带一路究竟在追求什么要素？<ul><li>不是能源资源，甚至也不是劳动力，而是<strong>巨量年轻消费者</strong>。</li></ul></li><li>当发展中国家还不起债的时候，我们如何追求回报？</li></ul></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;《中国为什么有前途》 翟东升老师&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Note" scheme="https://superuier.github.io/categories/reading-note/"/>
    
    
    <category term="读书" scheme="https://superuier.github.io/tags/%E8%AF%BB%E4%B9%A6/"/>
    
    <category term="翟东升" scheme="https://superuier.github.io/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>代理模型辅助的演化计算</title>
    <link href="https://superuier.github.io/paper-reading/surrogate/"/>
    <id>https://superuier.github.io/paper-reading/surrogate/</id>
    <published>2021-08-19T12:00:00.000Z</published>
    <updated>2021-08-19T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对 Surrogate-assisted evolutionary computation: Recent advances and future challenges 这篇综述的阅读笔记。这是一篇发表于2011年的关于在演化计算中如何应用辅助模型的综述。</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>绝大部分的演化计算都假设存在一个可以为每一个个体提供 fitness value 的手段，或是模拟，或是实验，或是一个显式的 fitness function。但是有的时候，这个 fitness 的评估是非平凡的，例如当模拟或实验需要消耗大量成本。此时通过使用代理模型的演化计算方法来减少昂贵问题上使用演化计算时间成本。</p><p>代理模型往往和真实的 fitness function 一起使用，以防演化计算被误引入代理模型提供的错误最优。当问题越高维度，代理模型的构建难度就越大。</p><h2 id="代理模型的策略"><a href="#代理模型的策略" class="headerlink" title="代理模型的策略"></a>代理模型的策略</h2><blockquote><p>No analytical fitness function exists for accurately evaluating the fitness of a candidate solution. Instead, there are only more accurate and less accurate fitness estimation methods, which often trade off accuracy with computational costs.</p></blockquote><p>使用代理模型也需要权衡模型的效率和保真度。最初，一部分工作完全依赖代理模型进行演化搜索，但是代理模型引入的可能并不存在的最优会带来严重的问题。代理模型几乎可以用在所有的演化计算步骤中来剔除差的结果，并且减少随机性：population initialization, cross-over, mutation, local search and fitness evaluations。</p><p>根据代理模型的使用对象进行不同，可以将代理模型方法分类可以分为以下三类：</p><ul><li>Generalization based:<ul><li>surrogates are used for fitness evaluations in some of the generations, while in the rest of the generations, the real fitness function is used</li></ul></li><li>Individual based:<ul><li>the real-fitness function is used for fitness evaluations for some of the individuals in a generation</li></ul></li><li>Population based:<ul><li>more than one subpopulation co-evolves, each using its own surrogate for fitness evaluations. Migration of individuals from one sub-population to another is allowed.</li></ul></li></ul><hr><h2 id="单代理模型"><a href="#单代理模型" class="headerlink" title="单代理模型"></a>单代理模型</h2><p>我们假设与真实 fitness 函数交互费时，希望尽可能减少与真实函数交互。那么关键的问题就在于如何确定哪个个体是应该被重新评估的。我们需要考虑到以下三个方面。</p><h3 id="1-选取重评估样本的标准"><a href="#1-选取重评估样本的标准" class="headerlink" title="1. 选取重评估样本的标准"></a>1. 选取重评估样本的标准</h3><p>不得不说这些选取的方式和<strong>主动学习</strong>极度相似。选取具有以下特征的样本评估:</p><ul><li>potentially have a good fitness value</li><li>representative</li><li>large degree of uncertainty in approximation<ul><li>fitness landscape around these solutions has not been well explored</li><li>improve the approximation accuracy of the surrogate,</li></ul></li></ul><p>如何描述或者估计这种不确定性或者错误呢？</p><ul><li>uncertainty is roughly set to be inversely proportional to the average distance to the closest data samples</li><li>estimating the variance of the individual estimates given by an ensemble of surrogates</li></ul><h3 id="2-如何评估代理模型的好坏"><a href="#2-如何评估代理模型的好坏" class="headerlink" title="2. 如何评估代理模型的好坏"></a>2. 如何评估代理模型的好坏</h3><p>首先代理模型并不是需要严格和 fitness function 相同才可以发挥作用，在存在较大的预测错误时同样可以起到作用，如下图所示。</p><div style="width:90%;margin:auto"><img src="/paper-reading/surrogate/surrogate-error.png" class=""></div><p>一些常用的度量：</p><ul><li>mean squared error between the individual’s real fitness value and the predicted fitness</li><li>the number of individuals that have been selected correctly using the surrogate</li><li>the rank of the selected individuals, calculated based on the real fitness function.</li><li>rank correlation: measure for the monotonic relation between the ranks of two variables</li><li>continuous correlation between the surrogate and the original fitness function.</li></ul><h3 id="3-提升预测的准确性"><a href="#3-提升预测的准确性" class="headerlink" title="3. 提升预测的准确性"></a>3. 提升预测的准确性</h3><ul><li>神经网络的正则化</li><li>随着搜索更新模型</li><li>建立一个地位的搜索空间</li><li>评估时利用生成的中间数据</li></ul><hr><h2 id="多代理模型"><a href="#多代理模型" class="headerlink" title="多代理模型"></a>多代理模型</h2><p>模型类别可能不同，模型保真度（fidelity）可能不同。此处根据对 fidelity 的掌控把多代理模型分为两类，同质（homogeneous）和异质（heterogeneous）多代理模型。</p><blockquote><p>By homogeneous multiple surrogates, the fidelity of the surrogates are not explicitly controlled, even if different types of surrogates are used. </p><p>On the contrary, heterogeneous surrogates vary in their fidelity due to an explicit control in model complexity or training data.</p></blockquote><ul><li>同质（homogeneous）多代理模型<ul><li>多个模型可以提升预测质量，也可以帮助识别较大的预测错误。</li><li>其经验有效性在多篇工作中得到证实。</li></ul></li><li>异质（heterogeneous）多代理模型<ul><li>其实是组合了一些列不同粒度的代理模型。</li><li>这类工作提出的背景也是训练不同粒度的代理模型会有不同的成本，粒度越低成本越低。</li></ul></li></ul><hr><h2 id="在昂贵问题之外更多的考虑"><a href="#在昂贵问题之外更多的考虑" class="headerlink" title="在昂贵问题之外更多的考虑"></a>在昂贵问题之外更多的考虑</h2><ol><li>Surrogates in interactive evolutionary computation</li><li>Surrogated-assisted evolution for solving dynamic optimization</li><li>Surrogates for robust optimization</li><li>Surrogates for constrained optimization</li></ol><h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><p>代理模型的方法更多的是应用驱动。</p><blockquote><p>One intensively researched area is surrogate-assisted design optimization, such as turbine blades, airfoils, forging, vehicle crash tests, multi-processor systems-on-chip design and injection systems. Other applications include drug design, protein design, hydroinformatics and evolutionary robotics.</p></blockquote><h2 id="未来挑战"><a href="#未来挑战" class="headerlink" title="未来挑战"></a>未来挑战</h2><ol><li>Theoretic work</li><li>Multi-level, multi-fidelity heterogeneous surrogates</li><li>Surrogate-assisted combinatorial optimization</li><li>Surrogate-assisted dynamic optimization</li><li>Rigorous benchmarking and test problems</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文是对 Surrogate-assisted evolutionary computation: Recent advances and future challenges 这篇综述的阅读笔记。
这是一篇发表于2011年的关于在演化计算中如何应用辅助模型的综述。&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Reading" scheme="https://superuier.github.io/categories/paper-reading/"/>
    
    
    <category term="EA" scheme="https://superuier.github.io/tags/EA/"/>
    
  </entry>
  
  <entry>
    <title>Vim 常用功能记录</title>
    <link href="https://superuier.github.io/programming/vim/"/>
    <id>https://superuier.github.io/programming/vim/</id>
    <published>2021-08-18T07:05:14.000Z</published>
    <updated>2021-08-18T07:05:14.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>Vim 是一款文本编辑器。说来惭愧，自己在日常使用中并不熟练，于是此处记录一些有需求的功能，便于查阅。</p><a id="more"></a><h2 id="四种模式"><a href="#四种模式" class="headerlink" title="四种模式"></a>四种模式</h2><ul><li>正常模式：<code>&lt;ESC&gt;</code> </li><li>命令模式：<code>:</code> or <code>/</code></li><li>插入模式：<code>i</code> or <code>a</code> or <code>o</code>（new line）</li><li>可视模式：<code>v, V, &lt;Ctrl&gt;+v</code></li></ul><h2 id="正常模式下常用命令"><a href="#正常模式下常用命令" class="headerlink" title="正常模式下常用命令"></a>正常模式下常用命令</h2><p>基本：</p><ul><li>保存退出：<code>:wq</code> or <code>ZZ</code></li><li>不保存退出：<code>:q!</code> or <code>:qa!</code></li><li>光标位置和文件信息：<code>&lt;Ctrl&gt;+g</code></li><li>显示及取消显示行号：<code>:set nu</code> and <code>:set nonu</code></li><li>定位到 n 行：<code>:n</code></li><li>翻页：<code>ctrl+f</code>（下一页） <code>ctrl+b</code>（上一页）</li></ul><p>搜索：</p><ul><li>搜索：<code>/+&lt;content&gt;</code></li><li>继续搜索：<code>n</code>（向下） or <code>N</code>（向上）</li><li>跳转至从哪里来：<code>&lt;Ctrl&gt;+o</code>（向后） or <code>&lt;Ctrl&gt;+i</code>（向前）</li><li>对应符号的跳转（例如括号）：<code>%</code></li></ul><h2 id="正常模式下编辑"><a href="#正常模式下编辑" class="headerlink" title="正常模式下编辑"></a>正常模式下编辑</h2><p>插入或更改：</p><ul><li>插入模式：<code>i</code> or <code>a</code> or <code>o</code>（新一行）</li><li>替换字符：<code>r+&lt;char&gt;</code> or <code>R+&lt;char&gt;</code>（多个字符）</li></ul><p>删除：</p><ul><li>删除当前字符：<code>x</code></li><li>删除当前单词：<code>dw</code></li><li>删除2个单词：<code>d2w</code></li><li>删除当前行：<code>dd</code></li><li>删除2行：<code>2dd</code> </li><li>删除到当前行尾：<code>d$</code></li></ul><p>撤销删除</p><ul><li>撤销：<code>u</code>（单次） or <code>U</code>（整行）</li><li>整行重做：<code>&lt;Ctrl&gt;+R</code></li></ul><p>复制粘贴：</p><ul><li>复制：<code>y</code>（在可视模式下选中）</li><li>粘贴内容：<code>p</code>（）</li></ul><p>替换文本：</p><ul><li>To substitute new for the first old in a line type    <code>:s/old/new</code></li><li>To substitute new for all ‘old’s on a line type       <code>:s/old/new/g</code></li><li>To substitute phrases between two line #’s type       <code>:#,#s/old/new/g</code></li><li>To substitute all occurrences in the file type        <code>:%s/old/new/g</code></li><li>To ask for confirmation each time add ‘c’             <code>:%s/old/new/gc</code></li></ul><h2 id="移动光标"><a href="#移动光标" class="headerlink" title="移动光标"></a>移动光标</h2><p>行内移动光标：</p><ul><li>向前移动两个单词至词首：<code>2w</code></li><li>向前移动两个单词至词尾：<code>2e</code></li><li>移动到行首：<code>0</code></li><li>移动到行尾：<code>$</code></li></ul><p>跨行移动图标（显示什么内容）：</p><ul><li>光标定位到第 n 行的行首 <code>nG</code></li><li>光标定位到第一行的行首 <code>gg</code></li><li>光标定位到最后一行的行首 <code>G</code></li><li>光标定位到当前屏幕的第一行行首 <code>H</code></li><li>光标移动到当前屏幕的中间 <code>M</code></li><li>光标移动到当前屏幕的尾部 <code>L</code></li><li>把当前行移动到当前屏幕的最上方，也就是第一行 <code>zt</code></li><li>把当前行移动到当前屏幕的中间 <code>zz</code></li><li>把当前行移动到当前屏幕的尾部 <code>zb</code></li></ul><h2 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h2><p>大小写转换</p><ul><li>将光标下的字母改变大小写 <code>~</code></li><li>将光标位置开始的3个字母改变其大小写 <code>3~</code></li><li>改变当前行字母的大小写 <code>g~~</code></li><li>将当前行的字母改成大写 <code>gUU</code></li><li>将当前行的字母全改成小写 <code>guu</code></li><li>将从光标开始到下面3行字母改成大写 <code>3gUU</code></li><li>将光标下的单词改成大写。 <code>gUw</code></li><li>将光标下的单词改成小写 <code>guw</code></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;Vim 是一款文本编辑器。
说来惭愧，自己在日常使用中并不熟练，于是此处记录一些有需求的功能，便于查阅。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="https://superuier.github.io/categories/programming/"/>
    
    
    <category term="Linux" scheme="https://superuier.github.io/tags/Linux/"/>
    
    <category term="Vim" scheme="https://superuier.github.io/tags/Vim/"/>
    
  </entry>
  
  <entry>
    <title>深度主动学习批判文章阅读</title>
    <link href="https://superuier.github.io/paper-reading/deep-AL-criticism/"/>
    <id>https://superuier.github.io/paper-reading/deep-AL-criticism/</id>
    <published>2021-08-12T06:51:10.000Z</published>
    <updated>2021-08-12T06:51:10.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>目前出现一些对深度主动学习批判的文章，结合自己的实践，深以为然，此处将其整理一下。同时这些文章也收录进了本人 <code>awesome-active-learning</code> 的仓库，详见<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/subfields/deep_AL.md">此链接</a>。在本文末尾，本人也提出了一些自己的看法。</p><a id="more"></a><p>文章列表：</p><ul><li>Parting with Illusions about Deep Active Learning [2019, Arxiv]</li><li>Towards Robust and Reproducible Active Learning Using Neural Networks [2020, Arxiv]</li><li>Effective Evaluation of Deep Active Learning on Image Classification Tasks [2021, Open Review]</li></ul><hr><h1 id="文献概览"><a href="#文献概览" class="headerlink" title="文献概览"></a>文献概览</h1><h2 id="1-Parting-with-Illusions-about-Deep-Active-Learning-2019-Arxiv"><a href="#1-Parting-with-Illusions-about-Deep-Active-Learning-2019-Arxiv" class="headerlink" title="1. Parting with Illusions about Deep Active Learning [2019, Arxiv]"></a>1. Parting with Illusions about Deep Active Learning <a href="https://arxiv.org/abs/1912.05361">[2019, Arxiv]</a></h2><p>这篇文章指出当前主动学习没有考虑到半监督学习及数据增强等平行设定，于是他们在图像分类和语义分割上做了一个对比实验。实验中对比到的内容包括：多种 SOTA 主动学习策略、加入数据增强模块的主动学习策略、加入半监督学习方法的主动学习策略、半监督学习策略。</p><p>分类任务的结果:</p><blockquote><ul><li>主动学习加入数据增强可以带来提升，但是这会模糊不同主动学习策略间的区别，他们表现都大致相同。</li><li>主动学习与半监督学习结合可以带来比单独使用主动学习和半监督学习都要好的表现。</li><li>不同主动学习策略的优劣排序在不同数据集上不同。</li><li>在样本数量极少时，主动选取的样本表现差于随机选取，包括在半监督学习上的随机选取。</li></ul></blockquote><p>语义分割的结果：</p><blockquote><ul><li>半监督学习加随机选取表现最好。</li></ul></blockquote><p>总结:</p><ul><li>当前用于评估主动学习的模式并不好，会带来错误的结论。</li><li>半监督学习的加入会大幅提升主动学习表现。</li><li>很多 SOTA 的主动学习方法会比随机选取要差，尤其是当标记样本数很小时。</li></ul><h2 id="2-Towards-Robust-and-Reproducible-Active-Learning-Using-Neural-Networks-2020-Arxiv"><a href="#2-Towards-Robust-and-Reproducible-Active-Learning-Using-Neural-Networks-2020-Arxiv" class="headerlink" title="2. Towards Robust and Reproducible Active Learning Using Neural Networks [2020, Arxiv]"></a>2. Towards Robust and Reproducible Active Learning Using Neural Networks <a href="https://arxiv.org/abs/2002.09564">[2020, Arxiv]</a></h2><p>这篇文章指出在不同的主动学习文章中，作为基准的随机选取策略表现飘忽不定。为了提高主动学习工作的可复现度和鲁棒性，这里对当前方法做一个公平的对比。</p><p>同时本文指出，当前主动学习方法大多忽视了正则化对减小泛化误差的作用。所以作者也将不同的正则化项 (parameter norm penalty, random augmentation (RA), stochastic weighted averaging (SWA), and shake-shake (SS)) 加入了对比。</p><p>图像分类任务的结果:</p><blockquote><ul><li>相比各作者在原文中提到的结果，这里随机选取的表现都要比他们宣称的更好。同时没有策略可以明显超过随机选取。</li><li>使用不同的主动学习批选取数目，得到的表现不一致。</li><li>主动学习方法没有超越随机选取，且在类别不平衡设定上表现不鲁棒。</li><li>加入了 RA 和 SWA 的正则化，主动学习表现明显提升，同时不同策略间表现差异减小。</li><li>把选取的样本迁移到不同的模型结构时，不同策略表现不同，但是随机选取表现依然占优。</li></ul></blockquote><p>讨论：</p><blockquote><ul><li>基于这种相同 baseline 表现不一致的情况，强调主动学习的对比应当在一系列限定条件下施行。</li><li>不同于 <code>Parting with Illusions about Deep Active Learning</code> 这篇文章，作者认为<ul><li>主动学习的表现提升仅在有限的的实验条件下才会出现</li><li>这种基于随机选取的提升不具有统计学意义</li><li>在加入正则化之后，这些对于随机选取策略的提升消失。</li></ul></li><li>正则化在小样本情况下带来的提升可观</li><li>对于一些在模型中使用到未标记样本训练的主动学习策略，例如 <code>VAAL</code> 更应该使用半监督学习来作为基线方法。</li><li>相信当前主动学习的工作都是基于未正则化的模型，其表现提升不能说是由于样本选取的好。</li></ul></blockquote><p>提出了一个评估的标准：</p><blockquote><ul><li>策略要在不同优化器、模型结构、批选取大小等上保证鲁棒。</li><li>模型训练时应当加入 RA 或 SWA 这类的正则化。</li><li>迁移测试必须进行，用来保证选取的样本的确是高质量的。</li><li>实验应该使用统一的评估平台</li><li>实验过程的快照应该留存发布</li><li>训练、测试、标记、未标记、选取样本的编码应该被分享。</li></ul></blockquote><h2 id="3-Effective-Evaluation-of-Deep-Active-Learning-on-Image-Classification-Tasks-2021-Open-Review"><a href="#3-Effective-Evaluation-of-Deep-Active-Learning-on-Image-Classification-Tasks-2021-Open-Review" class="headerlink" title="3. Effective Evaluation of Deep Active Learning on Image Classification Tasks [2021, Open Review]"></a>3. Effective Evaluation of Deep Active Learning on Image Classification Tasks <a href="https://arxiv.org/abs/2106.15324">[2021, Open Review]</a></h2><p><strong>个人认为这篇文章十分全面且实验到位。</strong>本文指出了当前 AL 工作的一些问题：</p><blockquote><ol><li>不同 AL 策略在不同的工作中往往存在矛盾的表现</li><li>非故意的排除一些用于深度学习的重要一般化步骤，例如数据增强和 SGD 优化。</li><li>对于标记效率等评估方式缺乏认知</li><li>对 AL 在什么情形下能超过随机选取没有清晰的认知</li></ol></blockquote><p>作者展示了一个统一的对于 SOTA 主动学习策略在图像分类下的复现，且在几个不同方面做出了分析。他们指出了一些重要但是目前不清楚的细节：</p><blockquote><ol><li>模型在每个轮循环之后需要从头训练还是可以 fine-tuning？</li><li>使用精心选取的初始集对 AL 有何影响。</li><li>有没有一个完美的 AL batch size？或者这个 AL batch size 重要吗？</li><li>什么情形下 AL 可以超越随机选取？什么因素对其产生影响？</li><li>AL 的 scalability 如何？具体的，模型的训练和 AL 的选取各需要多少时间？</li></ol></blockquote><p>以下是他们的重要结论和实用的经验：</p><blockquote><ol><li>数据增强对测试集表现以及标记效率能带来提升。</li><li>SGD 表现要比 Adam 表现好。</li><li>在使用数据增强和 SGD 优化器时，Diversity 选取策略难以比简单的 Uncertainty 选取表现好。</li><li>在加入人工制造的数据冗余时，BADGE 开始表现好于 Uncertainty 选取。</li><li>每个类别中未标记样本的数量对于表现有很大影响：每个类别中样本数越少，对于 AL 的提升空间越小。</li><li>初始标记数据的选取在几轮循环后对 AL 表现将几乎没有影响。</li><li>AL batch size 同样对表现几乎没有影响。</li><li>在每轮循环中，重训练模型或者 fine-tune 模型，只影响最开始几轮选取的表现。</li><li>最费时的步骤是每轮循环中模型的重训练。</li></ol></blockquote><hr><h1 id="总结、讨论与个人看法"><a href="#总结、讨论与个人看法" class="headerlink" title="总结、讨论与个人看法"></a>总结、讨论与个人看法</h1><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这三篇文章都是对当前深度主动学习的批判与调研文，个人很钦佩这种刨根问底的态度。首先这三篇文章有一些共性的结论：</p><ol><li>数据增强可以带来性能提升 [1,3]</li><li>半监督学习，正则化可以带来性能提升 [1,2]（个人看法，某些类的半监督学习方法可以看作正则化项，于是这里放在一起）</li><li>在加入适用于深度学习的提升方法后，不同 AL 策略间的优劣程度变得模糊 [1,2,3]</li><li>[1,2] 认为应当将半监督学习作为基线方法。</li></ol><p>当然也有一些互相排斥的结论：</p><ol><li>[2] 认为加入正则化之后，主动学习相对于随机选取的提升消失，不具有统计意义，但是 [1,3] 中数据增强后仍相对随机选取有提升。</li></ol><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><p>就这三篇文章而言，背景是当前一大部分的深度主动学习仅考虑了<strong>主动学习的范畴</strong>而没有更多考虑<strong>深度学习的问题</strong>。</p><p>仅从主动学习范畴而言，这二十多年来，Pool-Based AL 的架构，评估方式都没有发生过太大变化：</p><ul><li>全监督式学习</li><li>循环架构并每次从头训练</li><li>通过学习曲线评估不同策略</li><li>以随机选取样本的监督式学习模型作为最基础的基线</li></ul><p>如果从传统模型来考虑，这个主动学习的范畴其实没有太大问题。但是近十年来，深度学习兴起，其实为主动学习带来了新的实现环境。之前的有关深度主动学习的调研（见<a href="/paper-reading/deep-AL-survey/" title="这篇笔记">这篇笔记</a>），其实已经指出了很多在深度模型中使用主动学习面临的挑战。其中第一条就是主动学习期望选取少量重要标记样本，而深度学习期望大量训练样本，两者之间有着矛盾。所以在深度学习的框架下，不能仅仅考虑主动学习的范畴，也要结合深度学习的情况。</p><p>深度学习在这十年的发展中，其实也苦于标记样本数目稀少，但是在深度学习的社区中，采用了一些其他的方式来解决此问题，并取得了十分不错的效果：</p><ul><li>数据增强</li><li>利用未标记的样本<ul><li>半监督学习</li><li>自监督学习</li></ul></li><li>预训练</li></ul><p>所以目前来看，主动学习的范畴致力于用少量的标记样本达到与随机选取相同的表现，深度学习的这些方法致力于用已有的标记数据达到更好的表现。这两种角度其实是一件事情，放在主动学习评估的学习曲线中，就是横向比较和纵向比较。其实在评估时，绝大部分的主动学习工作，都是宣称前者但是采纳后者。换言之就是更侧重于纵向的比较（当然横向好就会带来纵向好毋庸置疑）。</p><p>在这种情况下，<strong>许多深度主动学习仍然使用传统主动学习范畴就很不公平了</strong>。根本原因在于比较的基线方法是一个明明能获取大量未标记样本却只在少量标记样本上训练的模型。换句话说，当前的很多深度主动学习方法还是在虐菜，虐那些没有使用先进的深度学习方法且仅在少量标记样本上训练的神经网络的菜。再打个比方说，主动学习可以看作一种样本维度的提升方式，当前的很大一部分深度主动学习是在对像刀剑一样的武器上进行磨刀抛光提升，表明我磨的比你好。殊不知现在神经网络经过多年社区的贡献已经变成了诸葛神弩或者是火枪。所以说现在仍基于对刀剑提升的作为主动学习的评估已经过时了，磨好的刀是比不过未经提升的火枪的。只有在火枪上进行提升，才可能是当前深度主动学习需要考虑的方向，才是能带来实用价值的方向。正式的说，就是<strong>如何在当前深度学习这些已经验证好用的通用方法下，进一步使用主动学习减少标记成本</strong>。</p><p>目前来看，在策略设计之外，我们需要对主动学习的框架来进行调整，这些调整和主动学习策略的设计可以是正交的，并不一定互相影响：</p><ol><li>首先比较的基线需要是随机选取样本训练的，纳入很多先进成熟深度学习方法的神经网络，包括但不限于：半监督，自监督，正则化，数据增强等方法。</li><li>模型的训练可能需要重训练和增强训练交替进行，而不是一味的重训练（考虑到相较于经典方法来说，神经网络训练时间较长。）</li><li>评估的方式不能单纯以学习曲线论，labeled efficiency 也是一个更直观的角度。</li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;目前出现一些对深度主动学习批判的文章，结合自己的实践，深以为然，此处将其整理一下。
同时这些文章也收录进了本人 &lt;code&gt;awesome-active-learning&lt;/code&gt; 的仓库，详见&lt;a href=&quot;https://github.com/SupeRuier/awesome-active-learning/blob/master/subfields/deep_AL.md&quot;&gt;此链接&lt;/a&gt;。
在本文末尾，本人也提出了一些自己的看法。&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Reading" scheme="https://superuier.github.io/categories/paper-reading/"/>
    
    
    <category term="active-learning" scheme="https://superuier.github.io/tags/active-learning/"/>
    
  </entry>
  
  <entry>
    <title>Prompt 学习记录</title>
    <link href="https://superuier.github.io/machine-learning/prompt/"/>
    <id>https://superuier.github.io/machine-learning/prompt/</id>
    <published>2021-08-11T09:02:00.000Z</published>
    <updated>2021-08-11T09:02:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>在自然语言处理中有一个叫做 prompt 的新范式最近较火，其背景是在少标记的场景下学习。本文主要内容都是从 <a href="https://arxiv.org/pdf/2107.13586.pdf">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</a> 这篇综述中提取。仅涵盖本人认为最需要被科普的内容。</p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当前在自然语言处理中主要存在以下范式，其中由 a 到 d 基本按照时间顺序出现。总的来说，目前为止经历了两个 sea changes（重大变化）。</p><blockquote><div style="width:100%;margin:auto"><img src="/machine-learning/prompt/paradigm.png" class=""></div></blockquote><p>在2017年以前，主要以完全监督学习为主（a和b范式）。研究的主要内容在于特征提取（传统模型），结构构建（深度模型）。但是在2017年之后，经历了第一个重大变化，完全监督的旧范式的使用不断在缩小，预训练及微调（c范式）开始流行。在当前时间节点，2021年，正在经历第二个重大变化。当前对于下游任务学习并不是通过预训练及微调中的 objective engineering，而是通过 prompt（提示）来实现。</p><p>这里举一个 prompt 的例子。</p><blockquote><p>When recognizing the emotion of a social media post, “I missed the bus today.”, we may continue with a prompt “I felt so __”, and ask the LM to ﬁll the blank with an emotion-bearing word. </p><p>Or if we choose the prompt “English: I missed the bus today. French: __”), an LM may be able to ﬁll in the blank with a French translation.</p></blockquote><p>通过这种选取合适的 prompt 的方法，预训练的 language model（LM）可以用来预测合适的输出，有时甚至不需要 task-specific 的训练。</p><h1 id="Prompt-的正式表述"><a href="#Prompt-的正式表述" class="headerlink" title="Prompt 的正式表述"></a>Prompt 的正式表述</h1><p>基于 prompt 的方法尝试规避无法获得大规模数据的问题，直接对样本 $\boldsymbol{x}$ 的概率 $P(\boldsymbol{x};\theta)$ 进行建模，之后再用这个概率来预测$\boldsymbol{y}$。以下是一些基于 prompt 的方法中的术语。</p><blockquote><div style="width:100%;margin:auto"><img src="/machine-learning/prompt/terminology.png" class=""></div></blockquote><p>通常来说，prompt 的方法预测高质量的输出 $\hat{\boldsymbol{y}}$ 有三步。</p><ol><li>Prompt Addition：通过模版，将原始语句转化为 Prompt，含有空白等待填入。</li><li>Answer Search：在候选集$\mathcal{Z}$中，选取 answer prompt $\hat{\boldsymbol{z}}=\operatorname{search}_{\boldsymbol{z} \in \mathcal{Z}} P\left(f_{\mathrm{fill}}\left(\boldsymbol{x}^{\prime}, \boldsymbol{z}\right) ; \theta\right)$。</li><li>Answer Mapping：将高分的回答 $\boldsymbol{z}$ 和高分的输出 $\hat{\boldsymbol{y}}$ 对应起来。</li></ol><h2 id="设计-Prompt-时需要考虑的具体问题"><a href="#设计-Prompt-时需要考虑的具体问题" class="headerlink" title="设计 Prompt 时需要考虑的具体问题"></a>设计 Prompt 时需要考虑的具体问题</h2><p>这里一般来说存在以下5个需要具体考虑的问题：</p><ol><li>如何选择预训练模型</li><li>选择何种 Prompt 来作为 Prompting funtion（模版）。</li><li>设计候选集$\mathcal{Z}$，可能同时还需要考虑与输出的映射。</li><li>对简单框架的扩展以提高表现和适用性。</li><li>训练参数的策略</li></ol><p>此处不一一展开，可以到综述中寻找具体的部分。</p><h2 id="Prompt-的应用和挑战"><a href="#Prompt-的应用和挑战" class="headerlink" title="Prompt 的应用和挑战"></a>Prompt 的应用和挑战</h2><p>这篇综述也详尽的展开了当前 Prompt 的应用和挑战。这里只简单记录不做展开。</p><p>应用方面，几乎涉及了 NLP 的方方面面，集中于以下几大类：Knowledge Probing、Classiﬁcation-based Tasks、Information Extraction、“Reasoning” in NLP、Question Answering、Text Generation、Automatic Evaluation of Text Generation、Multi-modal Learning、Meta-Applications。</p><p>挑战方面，主要集中于以下几个大类：Prompt Design、Answer Engineering、Selection of Tuning Strategy、Multiple Prompt Learning、Selection of Pre-trained Models、Theoretical and Empirical Analysis of Prompting、Transferability of Prompts、Combination of Different Paradigms、Calibration of Prompting Methods。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://pretrain.nlpedia.ai">Pretrain, Prompt, Predict: A New Paradigm for NLP</a></li><li><a href="https://arxiv.org/pdf/2107.13586.pdf">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</a> </li><li><a href="https://github.com/thunlp/PromptPapers">PromptPapers</a></li></ul><h1 id="对这个范式的看法"><a href="#对这个范式的看法" class="headerlink" title="对这个范式的看法"></a>对这个范式的看法</h1><p>Prompt 方法归根结底还是面向标记数据缺乏这一老生常谈的问题。</p><p>从二十多年前的经典方法开始，大家就在对这一问题展开研究。从模型角度入手似乎还是比较少见，主要还是在学习范式的角度上进行研究。从最开始的监督学习，到半监督学习，还有迁移学习，都是致力于使用有限的标记来最大化任务表现。近几年这种半监督，或者说自（无）监督的方法已经极大程度上融进了目前机器学习的框架中。有时作为一种特征提取器而存在，有时作为一种正则化而存在。从这一角度来看，当前的几种范式，都是在探讨如何最大化利用未标记样本，Prompt 也不例外。</p><h2 id="对于-Prompt-而言"><a href="#对于-Prompt-而言" class="headerlink" title="对于 Prompt 而言"></a>对于 Prompt 而言</h2><p>在我来看 Prompt 的定位应该是一种较为成熟的广泛适用于文本的自监督学习方法。自监督学习关键在于定义一种可以自己知道正确答案的任务，用此任务来训练，以得到对该任务的较好表现，同时也可以获取质量相对较好的特征以适用于下游任务。</p><p>当前的预训练模型大多都是由 mask 这类操作来自监督训练。所以在预训练模型上学习的填空能力是可以很好的用于 Prompt 定义的填空题。由于这种填词题在训练的时候已经见过，不像很多下游任务还需要知道之前没见过的标签，所以预训练模型在寻找 answered prompt 时可以 zero-shot 或者 few-shot。</p><p>总的来说，这种范式设计了一种能“引诱”模型输出之前在大量样本中学到的统计（/逻辑/推断）数据。个人觉得还是蛮有意思，或许可以用来对模型进行解释。</p><h2 id="对于自己主动学习的研究而言"><a href="#对于自己主动学习的研究而言" class="headerlink" title="对于自己主动学习的研究而言"></a>对于自己主动学习的研究而言</h2><p>主动学习和这些范式其实不太相同，上述半监督自监督学习主要考虑如何利用未标记样本，而主动学习是在探讨如何最大化利用有限的标记成本来选取最有价值的样本。其已假设更重要的样本能学出来相对随机选取的样本更好的模型。</p><p>在当前无监督自监督学习表现如此之好的情况下，单纯使用主动学习得到的标记样本意义似乎不大。因为单纯选取少量重要的标记样本可能仍旧难以与大量未标记样本上的自监督匹敌。这就是那两篇主动学习劝退文里面指出的问题。所以说个人认为主动学习中，尤其是模型的训练部分，为了最大化效用，应该是一定是要使用未标记样本的。</p><p>主动学习中存在标记，那么必然是一个下游任务。那么具体如何结合少量标记样本和大量未标记样本来训练，就是其他那几种范式。在其他范式上学到的特征提取器上对于下游进行微调，可能才是主动学习最好的实施方法。具体如何微调，又是一个研究了很久的问题。</p><p>所以这种无机的结合可能才是主动学习的实际场景。</p>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;在自然语言处理中有一个叫做 prompt 的新范式最近较火，其背景是在少标记的场景下学习。
本文主要内容都是从 &lt;a href=&quot;https://arxiv.org/pdf/2107.13586.pdf&quot;&gt;Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing&lt;/a&gt; 这篇综述中提取。
仅涵盖本人认为最需要被科普的内容。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://superuier.github.io/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://superuier.github.io/tags/machine-learning/"/>
    
    <category term="nlp" scheme="https://superuier.github.io/tags/nlp/"/>
    
    <category term="few-shot-learning" scheme="https://superuier.github.io/tags/few-shot-learning/"/>
    
  </entry>
  
  <entry>
    <title>Numpy 相关</title>
    <link href="https://superuier.github.io/programming/numpy/"/>
    <id>https://superuier.github.io/programming/numpy/</id>
    <published>2021-08-11T06:07:55.000Z</published>
    <updated>2021-08-11T06:07:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>一些在使用 Numpy 时需要注意的东西</p><a id="more"></a><h2 id="随机数生成"><a href="#随机数生成" class="headerlink" title="随机数生成"></a>随机数生成</h2><p>为保证实验结果可复现，一般我们使用 <code>np.random.seed(number)</code> 来固定随机种子，之后可保证调用随机数生成器产生的结果相同。</p><p>但是在项目规模较大，且需要导入其他包时，这种固定随机种子的办法可能会出现一定问题。原因在于其他的包中，可能同样会设定其他的全局随机种子 <code>np.random.seed(other_number)</code>。导致之后生成的样本不是按照自己设定的随机种子来生成。</p><blockquote><p>“The preferred best practice for getting reproducible pseudorandom numbers is to instantiate a generator object with a seed and pass it around” — Robert Kern, <a href="https://numpy.org/neps/nep-0019-rng-policy.html">NEP19</a>.</p></blockquote><p>解决方法是定义一个随机数生成器，并将其传送到需要使用随机数的地方。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rng = np.random.default_rng(<span class="number">2021</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rng.random(<span class="number">4</span>)</span><br><span class="line">array([<span class="number">0.75694783</span>, <span class="number">0.94138187</span>, <span class="number">0.59246304</span>, <span class="number">0.31884171</span>])</span><br></pre></td></tr></table></figure><p>Reference:</p><ul><li><a href="https://towardsdatascience.com/stop-using-numpy-random-seed-581a9972805f">Stop using numpy.random.seed()</a></li><li><a href="https://numpy.org/neps/nep-0019-rng-policy.html">NEP 19 — Random Number Generator Policy</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些在使用 Numpy 时需要注意的东西&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="https://superuier.github.io/categories/programming/"/>
    
    
    <category term="Python" scheme="https://superuier.github.io/tags/Python/"/>
    
    <category term="numpy" scheme="https://superuier.github.io/tags/numpy/"/>
    
  </entry>
  
</feed>
