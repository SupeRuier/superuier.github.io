<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Superui&#39;s Blog</title>
  
  
  <link href="https://blog.superui.cc/atom.xml" rel="self"/>
  
  <link href="https://blog.superui.cc/"/>
  <updated>2022-11-07T10:00:00.000Z</updated>
  <id>https://blog.superui.cc/</id>
  
  <author>
    <name>Superui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习中的 Lipschitz Continuity</title>
    <link href="https://blog.superui.cc/machine-learning/lipschitz-in-ml/"/>
    <id>https://blog.superui.cc/machine-learning/lipschitz-in-ml/</id>
    <published>2022-11-07T10:00:00.000Z</published>
    <updated>2022-11-07T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>在 discriminator 的学习使用中，经常会见到这个 Lipschitz Condition，在此处做一个学习。</p><span id="more"></span><h2 id="Lipschitz-Continuity"><a href="#Lipschitz-Continuity" class="headerlink" title="Lipschitz Continuity"></a>Lipschitz Continuity</h2><p>Lipschitz Continuous 是比可微分更严格的条件，这个性质限制了函数的微分值必须有上下限。换句话说，目标函数会被一个一次函数上下夹逼，如下图所示。</p><div style="width:50%;margin:auto"><img src="/machine-learning/lipschitz-in-ml/Lipschitz_Visualisierung.gif" class=""></div><p>以公式的形式展开，函数需要满足以下条件：</p><script type="math/tex; mode=display">\|f(x)-f(y)\| \leqslant L\|x-y\|</script><h2 id="为什么会在机器学习中使用？"><a href="#为什么会在机器学习中使用？" class="headerlink" title="为什么会在机器学习中使用？"></a>为什么会在机器学习中使用？</h2><p>本人目前见到过的使用地点多在 discriminator 相关工作中。Discriminator 在 GAN 相关模型中是一个必要的结构，在域迁移的模型中也多有使用。其作用是将真实样本与虚假样本分开，之后在将其固定来训练生成器使得判别器无法将虚假样本分开。</p><p>当下 GAN 可以生成足以骗过人类的高质量图像，但是其训练过程的不稳定仍然是一个具有挑战性的问题。因此，一系列的研究工作都着眼于解决不稳定训练的问题。WGAN 中使用 wasserstein distance 来代替原始 GAN 中的分类损失，效果良好。</p><script type="math/tex; mode=display">\left(P_r, P_g\right)=\inf _{\gamma \in \prod\left(P_r, P_g\right)} \mathbb{E}_{(x, y) \sim \gamma}[\|x-y\|]</script><p>但是由于这个形式十分难以求解，所以将该优化问题转换为以下形式。</p><script type="math/tex; mode=display">W\left(P_r, P_\theta\right)=\sup _{\|f\|_L \leq K} \mathbb{E}_{x \sim P_r}[f(x)]-\mathbb{E}_{x \sim P_\theta}[f(x)]</script><p>这个转化通过对判别器应用正则化或归一化，将判别器形式化定义为一个利普希茨连续的函数（Lipschitz continuous function），其利普希茨常数为 K。这样，在不大幅度牺牲判别器性能的条件下，判别器的梯度空间会变得更平滑，可以更加稳定的训练。在此技术上，有谱归一化和梯度归一化等工作。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://mp.weixin.qq.com/s/V7DzjtidOI6ohocRgAgUEA?">舍弃谱归一化，这篇ICCV’21论文用梯度归一化训练GAN，效果极好</a></li><li><a href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/83112332">深度学习中的Lipschitz约束：泛化与生成模型</a></li><li><a href="https://ai.stackexchange.com/questions/29904/what-is-lipschitz-constraint-and-why-it-is-enforced-on-discriminator">What is Lipschitz constraint and why it is enforced on discriminator?</a></li><li><a href="https://www.cnblogs.com/wonderlust/p/15767225.html">Spectral Normalization 谱归一化-原理及实现</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;在 discriminator 的学习使用中，经常会见到这个 Lipschitz Condition，在此处做一个学习。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="neural-network" scheme="https://blog.superui.cc/tags/neural-network/"/>
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="theory" scheme="https://blog.superui.cc/tags/theory/"/>
    
  </entry>
  
  <entry>
    <title>LSTM</title>
    <link href="https://blog.superui.cc/machine-learning/lstm/"/>
    <id>https://blog.superui.cc/machine-learning/lstm/</id>
    <published>2022-10-27T13:00:00.000Z</published>
    <updated>2022-10-27T13:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>最近用到的 ASP-MTL 模型中使用 LSTM 作为特征提取器。自己对于 RNN 的认知很不成体系，在此进行一个梳理。对 LSTM 来做一个学习，主要针对结构和预测两方面。</p><span id="more"></span><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p>Recurrent Neural Networks（RNN）指循环神经网络，用来处理序列数据。每一个时刻的输出或中间信息会被传递到下一个时刻作为一部分输入，以保留时序信息。具体模式如下图所示。</p><div style="width:80%;margin:auto"><img src="/machine-learning/lstm/RNN-unrolled.png" class="" title="一个 RNN 示例"></div><p>其中处理以往和当前信息的结构十分简单，以一个 tanh 来合并。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/simpleRNN.png" class="" title="简单 RNN 内部结构示例"></div><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>经典的 RNN 存在难以解决长距离依赖（long-term dependency）的问题，即时序上距离过远的相关信息难以被学到。于是 LSTM 模型被提出，其包含了一个记录长效信息的模块。LSTM 的结构如下图所示。最主要的核心观点是维护一个 cell state（细胞状态），以使得信息跨时序传输。当然这里个人认为翻译成“牢房”更为贴切。不同于简单的 RNN 中只有一个神经网络，LSTM 中含有四个主要的神经网络（门结构）。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/lstm.png" class="" title="LSTM 内部结构示例"></div><p>遗忘门决定要从细胞状态中舍弃什么信息。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/LSTM3-focus-f.png" class="" title="遗忘门"></div><p>输入门决定保存哪些新信息进入细胞状态。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/LSTM3-focus-i.png" class="" title="输入门"></div><p>旧的状态 $C_{t-1}$ 先 forget 再 input 得到新的状态 $C_t$。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/LSTM3-focus-C.png" class="" title="细胞状态更新"></div><p>输出一个“过滤”后的细胞状态。</p><div style="width:60%;margin:auto"><img src="/machine-learning/lstm/LSTM3-focus-o.png" class="" title="输出门"></div><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>先由正向传播，算出最终的损失 $J$，再反向计算梯度即可。详细的正向过程可见【2】。反向过程可见【3】。值得注意的是，反向过程的梯度更新需要考虑每一个时间步的输出。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li><li><a href="https://zhuanlan.zhihu.com/p/83496936">人人都能看懂的LSTM介绍及反向传播算法推导 - 陈楠的文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/54775438">RNN之随时间反向传播BPTT推导细节，从公式中理解RNN梯度消失与梯度爆炸原因 - 塞巴斯万隆的文章</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;最近用到的 ASP-MTL 模型中使用 LSTM 作为特征提取器。
自己对于 RNN 的认知很不成体系，在此进行一个梳理。
对 LSTM 来做一个学习，主要针对结构和预测两方面。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="neural-network" scheme="https://blog.superui.cc/tags/neural-network/"/>
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="rnn" scheme="https://blog.superui.cc/tags/rnn/"/>
    
    <category term="lstm" scheme="https://blog.superui.cc/tags/lstm/"/>
    
  </entry>
  
  <entry>
    <title>深度神经网络模型复杂度</title>
    <link href="https://blog.superui.cc/machine-learning/computational-complexity/"/>
    <id>https://blog.superui.cc/machine-learning/computational-complexity/</id>
    <published>2022-10-20T05:00:00.000Z</published>
    <updated>2022-10-20T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>深度学习计算量/复杂度相关知识。个人在此方面的知识较少，导致上周高性能计算的讲座好多都没有听懂，在此做一个学习。</p><span id="more"></span><h2 id="一些基础概念"><a href="#一些基础概念" class="headerlink" title="一些基础概念"></a>一些基础概念</h2><p>首先介绍一些概念：</p><ul><li>FLOPS：floating point operations per second 的缩写，意指每秒浮点运算次数，理解为计算速度，是衡量硬件性能的指标。（常与 FLOPs 混淆）</li><li>FLOPs：floating point operations 的缩写，意指浮点运算数，理解为计算量，可以用来衡量算法/模型的复杂度。</li><li>MACs：multiply–accumulate operations，意为乘加计算数，通常与 FLOPs 存在一个两倍的关系。</li></ul><p>关于什么是浮点数可以看这篇文章【2】，个人觉得深入浅出写的比较清晰。</p><h2 id="如何计算"><a href="#如何计算" class="headerlink" title="如何计算"></a>如何计算</h2><p>其实就是计算有多少次运算，对于不同的模型结构计算数目不同。此处不涉及具体公式，仅介绍 FLOPs 计算思路，MACs（又乘又加）的话通常为 FLOPs 的两倍左右。</p><ol><li>卷积层：在卷积层参数数目的基础上乘以输出的 feature map 大小（输出的每一个 feature 都是通过一次卷积层得到的）。</li><li>全联接层：即为全联接层参数数目。</li><li>激活层：不同激活函数的计算量不同。通常来说不重点计算。</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.zhihu.com/question/65305385/answer/451060549">CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？ - 泓宇的回答</a></li><li><a href="https://www.zhihu.com/question/425741425/answer/2584045783">浮点数浮点型到底是什么，能说的简单一点吗，就是用高中生能理解的语言。它们的作用是什么？ - 木木的回答</a></li><li><a href="https://blog.csdn.net/weixin_39833897/article/details/105807172">CNN的参数量、计算量（FLOPs、MACs）与运行速度</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;深度学习计算量/复杂度相关知识。
个人在此方面的知识较少，导致上周高性能计算的讲座好多都没有听懂，在此做一个学习。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="deep-learning" scheme="https://blog.superui.cc/tags/deep-learning/"/>
    
    <category term="high-performance-computing" scheme="https://blog.superui.cc/tags/high-performance-computing/"/>
    
  </entry>
  
  <entry>
    <title>再次学习强化学习的笔记</title>
    <link href="https://blog.superui.cc/machine-learning/re-learn-RL/"/>
    <id>https://blog.superui.cc/machine-learning/re-learn-RL/</id>
    <published>2022-10-14T06:00:00.000Z</published>
    <updated>2022-10-14T06:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>距离上一次学习强化学习已经很久了。最近由于 learning to optimize 用到了很多强化学习的知识，猛的一看发现又不太懂，于是这里进行对于强化学习的再学习。上一次对强化学习的学习见<a href="/machine-learning/reinforcement-learning/" title="这一篇帖子">这一篇帖子</a>。</p><span id="more"></span><p>总的来说，上次对于强化学习的理解过于浅薄，而且并没有从一个系统性和直观的角度进行理解，导致抄了一堆公式也是白抄。本文主要以一个直观的角度来对一个重要算法在整个体系中存在的位置做一个定位，不会过多陷入数学计算。</p><h2 id="什么是强化学习？（一些基础知识）"><a href="#什么是强化学习？（一些基础知识）" class="headerlink" title="什么是强化学习？（一些基础知识）"></a>什么是强化学习？（一些基础知识）</h2><p>强化学习目标是学到一个对于目标任务的策略 policy ($\pi$)，给定一个当前的状态 state ($s$)，策略可以给出当前应该执行的策略 action ($a$) 以获得最大收益。</p><p>此外还有以下一些概念：</p><ul><li>Value 价值：一般单独提到时指的是当前状态的价值。</li><li>Q-value 动作价值：指在某一个状态 $s$ 下实施动作 $a$ 所能收获的收益。</li><li>Model 模型：指状态转移的模式，即环境对于特定的动作如何反应。</li><li>Return 回报：指在整个交互结束之后能收到的总奖励。</li></ul><h2 id="最初的方法：-Q-Leaning-amp-Policy-Gradient"><a href="#最初的方法：-Q-Leaning-amp-Policy-Gradient" class="headerlink" title="最初的方法： Q-Leaning &amp; Policy Gradient"></a>最初的方法： Q-Leaning &amp; Policy Gradient</h2><p>我们这里还是更多的介绍一下 model-free 的场景。具体来说，我们对环境提供的状态转移无知，并且我们不对其进行建模。在这种情况下，我们想要学习一个策略，$\pi(s)\rightarrow a$，可以有两种方式：</p><ol><li>学习不同状态下的 Q-value，并对其进行建模。建模成功之后即可选取在当前 state 下 Q-value 最大的 action 实施。</li><li>直接学习策略 $\pi$，则可直接输入 state，得到 action。</li></ol><p>那么两者各有什么特点呢？</p><ol><li>Q-learning 以值为基础，可以使用时序差分（temporal-difference）的思路，使效用估计朝着理想均衡方向调整，可以进行单步更新。但是由于其离散化的特点，如果在连续空间中进行选择，则会瘫痪。</li><li>Policy gradient 可以在毫不费力地在连续空间中进行选择，但是因为其是基于 Monte-Carlo 采样得到的评估，必须等一个回合结束后才可以更新，学习效率低。</li></ol><div style="width:90%;margin:auto"><img src="/machine-learning/re-learn-RL/TD_MC_backups.png" class=""></div><h2 id="结合两者的优点-Actor-Critic"><a href="#结合两者的优点-Actor-Critic" class="headerlink" title="结合两者的优点 Actor-Critic"></a>结合两者的优点 Actor-Critic</h2><p>Policy gradient 使用现实中的奖惩来更新 actor。此时的梯度可以写作：</p><script type="math/tex; mode=display">\nabla \bar{R}_\theta=E_{\tau \sim p_\theta(\tau)}\left[R(\tau) \nabla \log p_\theta(\tau)\right]</script><p>这个 reward 奖惩信息 $R$ 可以被学出来，作为一个 critic 来来指导 actor 训练。Critic 可以看到当前所处状态动作的潜在奖励，所以可以使得 actor 每一步都在更新，而不是到回合结束才能更新。AC 中的梯度可以写作：</p><script type="math/tex; mode=display">\nabla \bar{R}_\theta=\frac{1}{N} \sum_{n-1}^N \sum_{t=1}^{T_n} Q^{\pi_\theta}\left(s_t^n, a_t^n\right) \nabla \log p_\theta\left(a_t^n \mid s_t^n\right)</script><h2 id="A2C-和-A3C"><a href="#A2C-和-A3C" class="headerlink" title="A2C 和 A3C"></a>A2C 和 A3C</h2><h3 id="Advantage-Actor-Critic-A2C"><a href="#Advantage-Actor-Critic-A2C" class="headerlink" title="Advantage Actor-Critic (A2C)"></a>Advantage Actor-Critic (A2C)</h3><p>AC 中使用 Q-value，方差大，梯度差异较大训练不稳定。PG 中同样有这种问题，它的解决方式是引入一个 baseline，用累计奖励 Gain 减去 baseline，可以使梯度减小，训练平缓。</p><script type="math/tex; mode=display">\nabla \bar{R}_\theta=\frac{1}{N} \sum_{n=1}^N \sum_{t=1}^{T_n}\left(Gain_t - baseline(s_t)\right) \nabla \log p_\theta\left(a_t^n \mid s_t^n\right)</script><p>A2C 中，认为对于 Q-value $Q^{\pi_\theta}\left(s_t^n, a_t^n\right) $ 一个自然的 baseline 选择是 $V^{\pi_\theta}\left(s_t^n\right)$。于是可以构造优势函数 advantage function $A(s_t,a_t) = Q(s_t,a_t)-V(s_t)$。其可以通过近似计算得到 $A(s_t,a_t) = r_t^n+V^\pi\left(s_{t+1}^n\right)-V^\pi\left(s_t^n\right)$。所以可以仅用一个网络来估计 $V$ 值而不用评估 Q-value。可以说 A2C 解决的是梯度方差大，训练不稳定的问题。</p><p>A2C 中的梯度可以写作：</p><script type="math/tex; mode=display">\nabla \bar{R}_\theta=\frac{1}{N} \sum_{n=1}^N \sum_{t=1}^{T_n} A^{\pi_\theta}\left(s_t^n, a_t^n\right) \nabla \log p_\theta\left(a_t^n \mid s_t^n\right)</script><p>除了方差大，AC 还存在的问题：两个网络交替训练，critic 和 action 强相关，有着很强的时序关联，只能探索到有限的状态和动作空间。为了打破经验耦合，需要采用 experience replay，使得 agent 在后续训练可以访问到以前知识（例如 DQN 和 DDPG（DQN+AC）这类基于值的方法）。但是策略类的方法，经验都是以 episode 形式获得，用完即弃。</p><p>在此情况下使用并行架构，不同的 worker 与环境进行交互，得到独立的采样经验。即每轮训练中，Global network 都会等待每个 worker 各自完成当前的 episode，然后把这些 worker 上传的梯度进行汇总并求平均，得到一个统一的梯度并用其更新主网络的参数，最后用这个参数同时更新所有的 worker。可以说 A2C 也解决了经验耦合的问题。</p><h3 id="Asynchronous-Advantage-Actor-Critic-A3C"><a href="#Asynchronous-Advantage-Actor-Critic-A3C" class="headerlink" title="Asynchronous Advantage Actor-Critic (A3C)"></a>Asynchronous Advantage Actor-Critic (A3C)</h3><p>A3C 相对于 A2C 使用了异步经验更新。没有等待所有 worker 完成当前 episode 并汇总的过程。</p><blockquote><p><strong>各个 worker 都分别使用着一套不同的策略</strong>，独立的跟自己的环境交互。而主网络保持着最新的策略，各 worker 跟主网络同步的时间也是不一样的，只要有一个 worker 完成当前episode，主网络就会根据它的梯度进行更新，并不影响其它仍旧在使用旧策略的 worker。这就是异步并行的核心思想。</p></blockquote><p>但是研究者们逐渐发现A3C主要优势在于采用了“并行训练”的思想，而不一定要“异步地并行训练”。异步更新并没有使训练效率和性能取得显著提高【3】，A2C 表现更好（A2C 是在 A3C 后面出现的）。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>本文并没有深入技术细节，而是从强化学习（在这几个方法上）的演变角度，简单的记录了不同方法的 intuition。比之前的学习笔记或许在问题定义上清晰了一些。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/25831658">什么是 Actor-Critic (强化学习) - 莫烦的文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/478709774">深入理解强化学习（七）- Actor-Critic - 莫冉的文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/148492887">深度强化学习 — 进击的 Actor-Critic（A2C 和A3C） - Quantum cheese的文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/51645768">强化学习AC、A2C、A3C算法原理与实现！ - 梁勇的文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/161839383">Actor-Critic的变体 - heaven的文章</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;距离上一次学习强化学习已经很久了。
最近由于 learning to optimize 用到了很多强化学习的知识，猛的一看发现又不太懂，于是这里进行对于强化学习的再学习。
上一次对强化学习的学习见&lt;a href=&quot;/machine-learning/reinforcement-learning/&quot; title=&quot;这一篇帖子&quot;&gt;这一篇帖子&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="reinforcement-learning" scheme="https://blog.superui.cc/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>Attention 和 Transformer</title>
    <link href="https://blog.superui.cc/machine-learning/attention/"/>
    <id>https://blog.superui.cc/machine-learning/attention/</id>
    <published>2022-09-30T08:00:00.000Z</published>
    <updated>2022-09-30T08:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>注意力机制和 Transformer 在神经网络中已经取得了良好的表现，此处做一个简要的学习。因为在自己的工作中并不会用到，所以此处可能更注重一些逻辑上的思路，以加强直观上的理解，具体细节有需要的时候再进行补充。</p><span id="more"></span><h2 id="Attention-机制是什么？"><a href="#Attention-机制是什么？" class="headerlink" title="Attention 机制是什么？"></a>Attention 机制是什么？</h2><p>Attention 最初面对的是长程梯度消失以及中间隐变量信息含量有限的问题。其通过将输入中的样本信息指导输出过程，来解决这一问题。其有着参数少速度快效果好的优点。</p><p>Attention 做的事情简单来说就是“加权求和”：</p><ul><li>对什么加权？对 feature 或者一系列输入信息加权。</li><li>权重是多少？权重为一个函数，而不是固定值。（若为固定值的话则可视为全连接层了。）一般来说这个权重即为 attention 分布，基于输入位置和输出位置的关联性。</li><li>求和得到什么？所需的输出。</li></ul><div style="width:80%;margin:auto"><img src="/machine-learning/attention/knowledge_is_power.gif" class="" title="一个翻译任务的例子"></div><h2 id="Attention-定义"><a href="#Attention-定义" class="headerlink" title="Attention 定义"></a>Attention 定义</h2><p>以下是 “Attention Is All You Need”【4】这篇重磅论文中给出的定义。这个定义虽说是针对于他们的 scaled dot-product attention，但是整体来说整个 attention 都是一个思路，所以可以拿来作为定义。</p><script type="math/tex; mode=display">\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V</script><p>即通过关系矩阵 $Q K^T$ 归一化得到的概率分布 $\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right)$ 对 $V$ 进行重采样。当然这个 $QKV$ 在不同场景下可能有着不同的具体含义。</p><h2 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h2><p>如下图所示。简单来说就是将多个 scaled dot-product attention 的值拼接，再通过线形结合输出。</p><div style="width:80%;margin:auto"><img src="/machine-learning/attention/multi-head-attention.png" class="" title="multi-head attention"></div><p>具体的，</p><script type="math/tex; mode=display">\operatorname{MultiHead}(Q, K, V)=\operatorname{Concat}\left(\operatorname{head}_1, \ldots\right., head \left._{\mathrm{h}}\right) W^O \\where \quad \text{head}_i=\operatorname{Attention}\left(Q W_i^Q, K W_i^K, V W_i^V\right)</script><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>其模型结构如下图所示。Multi-head attention 是其主要组成部分。在 attention 之外，样本的位置（顺序）信息使用 positional encoding 嵌入（因为不像 RNN 有顺序结构）。</p><div style="width:50%;margin:auto"><img src="/machine-learning/attention/transformer.png" class="" title="transformer"></div><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.zhihu.com/question/320174043/answer/651998472">深度学习中Attention与全连接层的区别何在？ - SleepyBag的回答 - 知乎</a></li><li><a href="https://zhuanlan.zhihu.com/p/47063917">Attention机制详解（一）——Seq2Seq中的Attention</a></li><li><a href="https://www.zhihu.com/question/68482809/answer/1876764572">目前主流的attention方法都有哪些？ - 电光幻影炼金术的回答 - 知乎</a></li><li>Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017).</li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;注意力机制和 Transformer 在神经网络中已经取得了良好的表现，此处做一个简要的学习。
因为在自己的工作中并不会用到，所以此处可能更注重一些逻辑上的思路，以加强直观上的理解，具体细节有需要的时候再进行补充。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="neural-network" scheme="https://blog.superui.cc/tags/neural-network/"/>
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="attention" scheme="https://blog.superui.cc/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>Focal Loss</title>
    <link href="https://blog.superui.cc/machine-learning/focal-loss/"/>
    <id>https://blog.superui.cc/machine-learning/focal-loss/</id>
    <published>2022-09-21T07:00:00.000Z</published>
    <updated>2022-09-21T07:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>前几天听到一个关于元学习的报告，里面提到了一下 Focal Loss，意识到总是听人讲起却没有好好看过它到底是什么，于是这里做一个简短的学习。</p><span id="more"></span><h2 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h2><p>Focal loss 是何恺明大神提出的，面向类别不平衡性能损失问题的一个思路。</p><p>通常情况下，面对类别不平衡，如果不加干预，模型则更倾向于对优势类有着更好表现。通常大家的解决思路是对不同类别的样本损失函数加权，降低优势类损失的权重，增强劣势类损失的权重，比例约为不同类别（正负样本）的数量比。</p><p>此处 focal loss 本质上也是一个对于 CEloss 的加权，但是它入手的角度是学习样本的难易程度。</p><h2 id="Focal-loss-具体形式"><a href="#Focal-loss-具体形式" class="headerlink" title="Focal loss 具体形式"></a>Focal loss 具体形式</h2><p>首先我们给出 focal loss 的表达式：</p><script type="math/tex; mode=display">L_{f l} =-\left(1-p_t\right)^\gamma \log \left(p_t\right)\\p_t = \begin{cases}\hat{p} & \text { if } \mathrm{y}=1 \\ 1-\hat{p} & \text { otherwise }\end{cases}</script><p>同理也有交叉墒损失函数的表达式:</p><script type="math/tex; mode=display">L_{ce}=- \log \left(p_t\right)\\</script><p>两者的主要区别在于 $log$ 项之前的权重。直观上理解，$p$ 反应了分类的难易程度，分类的置信度越高，代表样本越易分；分类的置信度越低，代表样本越难分。因此focal loss相当于增加了难分样本在损失函数的权重，使得损失函数倾向于难分的样本，有助于提高难分样本的准确度。而通常情况下，样本较少的类别天然会难分一些。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/32423092">何恺明大神的「Focal Loss」，如何更好地理解？</a></li><li><a href="https://zhuanlan.zhihu.com/p/266023273">focal loss 通俗讲解</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;前几天听到一个关于元学习的报告，里面提到了一下 Focal Loss，意识到总是听人讲起却没有好好看过它到底是什么，于是这里做一个简短的学习。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="neural-network" scheme="https://blog.superui.cc/tags/neural-network/"/>
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="loss-function" scheme="https://blog.superui.cc/tags/loss-function/"/>
    
  </entry>
  
  <entry>
    <title>《世界简史》读书笔记</title>
    <link href="https://blog.superui.cc/reading-note/brief-world-history/"/>
    <id>https://blog.superui.cc/reading-note/brief-world-history/</id>
    <published>2022-07-24T08:30:00.000Z</published>
    <updated>2022-07-24T08:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>通俗历史的高度概括，从空间时间的起源到世界政治与社会的重建。</p><span id="more"></span><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>H•G·韦尔斯（1866-1946），英国著名作家。早年在一家布店当过学徒，后毕业于英国皇家学院。曾尝试以教书为生，却以新闻和文学创作闻名于世。其所著《时间机器》、《隐身人》为现代科幻小说开山之作。一生涉猎甚广，虽不是历史学家，却以《世界史纲》跻身于史学大家之列。（摘自豆瓣）</p><h2 id="内容简介"><a href="#内容简介" class="headerlink" title="内容简介"></a>内容简介</h2><p>《世界史纲》乃鸿篇巨制，煌煌近百万字，非一般读者所能吸纳。韦尔斯于1923年出版的这本包含着“崭新立意和写法”的《韦尔斯世界简史》，作为前者的普及版。作者以无比开阔的视界、轻快简洁的笔调将自生物起源以来的生物及人类历史，有条不紊地展现在读者面前，作者的目的不拘泥于考据，而在于给读者提供一个宏伟、宽广的大视野。（摘自豆瓣）</p><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>惊讶于二十世纪初作者对世界历史的了解。史实之外，作者还加入了很多对事件发展变迁的认识。帝国的此起彼伏、潮起潮落，在作者的笔下以平实的语言叙述出来，并且能直接地指出变迁的关键事件（原因），对于帮助认识历史有着极大的好处。本书跨度极大，从宇宙地球讲起，直到一战前的世界格局，从原始的部落社会，到后来的资本主义和社会主义，可以说是一本极好的科普书籍。</p><h3 id="感想看法"><a href="#感想看法" class="headerlink" title="感想看法"></a>感想看法</h3><ul><li>这本书讲了很多生命起源，原始人什么的。对我而言很无趣且冗长。</li><li>讲了很多公元前的埃及巴比伦那边的人种，包含大量的地名人名，没有配合图片难以阅读。</li><li>发现对熟悉领域的扩展阅读似乎总是比不熟悉的领域要看得舒服一些。大量的欧洲史个人就觉得有点晦涩难懂。</li><li>有点感叹，在写成这本书的无互联网的年代，搜集到如此多的历史信息并成文是一件很不容易的事情。</li><li>一个国家的灭亡根本的原因会是什么呢？不得人心吗？还是经济无力支撑？</li><li>教皇原来曾经有这么大的影响力。十字军东征原来是教会扫除异教徒的行为。</li><li>蒙古人的西进并非人多势众野蛮暴烈，他们的行军很有战略规划和情报刺探。而基督教诸国却对自己的敌人一无所知。这对自己原来对蒙古领土横跨亚欧大陆的认识相差甚远，以前只是觉得可能蒙古人太骁勇了。</li><li>元朝看起来只是蒙古统治的一个分支。</li><li>教会压制了人们对自由科学的追求，教会发达的时候自然科学完完全全被压制。就让人想到中国的这些儒家文化道家文化，从来都是三纲五常，可能有着对人探索精神的压制，或许这也是中国自然科学没发展起来的原因之一。</li><li>原来是蒙古人把枪炮和火药带到的西方。</li><li>工业革命开始的这段科技发展的时间在历史长河中实在是过于的短暂，或许可以说这个是需求推动的科技发展？</li><li>其实对中华文明的概念越来越模糊，元朝算吗？清朝算吗？如果算的话，如果日本占领了全中国建立了满洲国，那满洲国算吗？感觉值得思考。</li><li>交通真的对稳定统治起到了极其重要的作用。</li><li>历史上撕毁协议的事情真的是屡见不鲜。</li></ul><h1 id="内容摘录"><a href="#内容摘录" class="headerlink" title="内容摘录"></a>内容摘录</h1><p>本就是简史，此处不会详细记录，仅仅记录自己认为有趣的描述和事实。</p><ul><li>这本被后世基督徒称为《旧约》的，正是希伯来《圣经》，他大约成书于公元前400年或公元前500年。</li><li>《奥德赛》，这是一部历险记，主要内容说的是，希腊人英明的首领奥德赛从特洛伊返回自己的国家时，在漫长旅途中的冒险故事。</li><li>公元前六世纪，在人类历史上具有非同凡响的意义。当时，在希腊，哲学家们开始探讨人类在宇宙中的地位，在印度，释迦摩尼开始布道解惑，在中国，孔子和老子的学说广为流传。</li><li>一种盛行于雅典的高尚死法是苏格拉底的最终选择：在众目睽睽之下，喝下用有毒草类炮制而成的毒酒。</li><li>柏拉图是第一个向我们描绘“乌托邦”的人，那是一种不同于现有社会、比任何时代的社会更加美好的社会蓝图。《理想国》这本柏拉图早起的著作，讲述了一个共和主义贵族的梦想。</li><li>罗马和汉朝这两个处于同一时代的庞然大国，却对彼此一无所知。</li><li>罗马帝国之所以能崛起，主要是依仗着早期民权的意识团结了人民。罗马帝国之所以灭亡就在于他失去了意志。</li><li>公元751年中国人曾袭击撒马尔罕的阿拉伯人，然后被击败被俘获的中国人中有一批熟练的造纸行家，于是造纸的技术就这样传过来。</li><li>蒙古人对欧洲征服活动，极大的刺激了欧洲人的地理想象力。</li><li>等欧洲步入16世纪以后历史的兴趣，已经从王朝的更迭，转到了<strong>政治和社会组织实验的广泛性与多样性</strong>上。</li><li>枪炮和火药打破了住在城堡中的贵族和有城墙防护的城市的安全感，也彻彻底底地埋葬了封建制度。</li><li>一种对抗力量出现了，他避免了联邦的分裂，并在世界各地发挥着重要作用。这就是蒸汽轮船的发明以及铁路和电报的相继出现。他们拯救了美国，把分散的居民结合起来，使美国成为第一个现代化的国家。</li><li>从本质上来说，<strong>世界上任何政治协议都是暂时性的</strong>。</li><li>到了，19世纪的后半期德国科学领域的进展已经遥遥领先，每一位科研人员要是不想落伍，就一定得掌握德语，以便去进行学习。</li><li>到了19世纪以后，那些有头脑的人越来越清楚地意识到比起劳役苦工，一般平民更加可贵，必须要让他们接受教育，因为他们起码要知道自己在干什么，这样才能确保工作效率。</li><li>现在我们所说的社会主义实际上等同于一种集体主义，他允许私人占有相当数量的财产，但是教育运输矿山土地所有权重要物质的生产，则主张控制在具有高度组织性的国家手中。</li><li>为促进世界范围的繁荣十分有必要在全世界进行通畅的自由贸易，个人主义者对国家的敌意实际上就是对关税和国界设定的不满，就是对法定关税和国界限制了国际自由行为和运动的不满。</li><li>个人主义和社会主义这两个理论虽然立场完全相反，但他们共同探索着同一个问题，即为人们如何才能共同劳动这一问题找出建立在更广泛的社会和政治基础上的解决方案。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;通俗历史的高度概括，从空间时间的起源到世界政治与社会的重建。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Note" scheme="https://blog.superui.cc/categories/reading-note/"/>
    
    
    <category term="读书" scheme="https://blog.superui.cc/tags/%E8%AF%BB%E4%B9%A6/"/>
    
    <category term="历史" scheme="https://blog.superui.cc/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
  <entry>
    <title>Awesome Active Learning</title>
    <link href="https://blog.superui.cc/machine-learning/awesome-active-learning/"/>
    <id>https://blog.superui.cc/machine-learning/awesome-active-learning/</id>
    <published>2022-07-19T05:45:00.000Z</published>
    <updated>2022-07-19T05:45:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>This is the introduction for the <a href="https://github.com/SupeRuier/awesome-active-learning">Awesome-Active-Learning</a> project.<strong>Hope you can find everything you need about active learning (AL) in this repository.</strong></p><p>这篇博文同样有一份<strong>中文版本</strong>: <strong><a href="/machine-learning/al-all-in-one/" title="主动学习，看这一篇就够了">主动学习，看这一篇就够了</a></strong>。</p><span id="more"></span><p>This is not only a curated list, but also a well-structured library for active learning.The whole repository is constructed in a <strong>problem-orientated</strong> approach, which is easy for users to locate and track the problem.At the mean time, the techniques are discussed under the corresponding problem settings.</p><p>Specifically, this repository includes:</p><ul><li><a href="#1-what-is-active-learning">1. What is Active Learning?</a> </li><li><a href="#2-reviewssurveysbenchmarks">2. Reviews/Surveys/Benchmarks</a></li><li><a href="#3-problem-settings">3. Problem Settings</a><ul><li><a href="#31-basic-problem-settings-three-basic-scenarios">3.1. Basic Problem Settings (Three basic scenarios)</a></li><li><a href="#32-advanced-problem-settings">3.2. Advanced Problem Settings</a></li><li><a href="#33-tasks-in-other-ai-research-fields">3.3. Tasks in other AI Research Fields</a></li></ul></li><li><a href="#4-theoretical-support-for-active-learning">4. Theoretical Support for Active Learning</a></li><li><a href="#5-practical-considerations-to-apply-al">5. Practical Considerations to Apply AL</a></li><li><a href="#6-real-world-applications-of-al">6. Real-World Applications of AL</a></li><li><a href="#7-resources">7. Resources</a></li><li><a href="#8-groupsscholars">8. Groups/Scholars</a></li></ul><p>The hierarchical structure of this repository is shown in the following figure, and <strong>you can find the paper-list in the corresponding sub-pages</strong>:</p><p><img src="repo-structure.png" alt="Repo Structure"></p><h3 id="Shortcuts"><a href="#Shortcuts" class="headerlink" title="Shortcuts"></a><strong>Shortcuts</strong></h3><p>These shortcuts could quickly lead you to the information you want.</p><div class="table-container"><table><thead><tr><th>Link</th><th>Note</th></tr></thead><tbody><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/pb_classification.md">Taxonomy of Strategies</a></td><td>The types of AL strategies, in general pool-based scenario.</td></tr><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_combinations.md">AL Aids AI</a></td><td>Use AL under other AI research problems.</td></tr><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_applications.md">AL Applications</a></td><td>The scientific and industrial applications of AL.</td></tr><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/practical_considerations.md">Practical Considerations</a></td><td>The practical issues in applying AL when the assumptions change.</td></tr><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/intrinsic_issues.md">Intrinsic Issues in AL</a></td><td>The intrinsic issues of AL.</td></tr><tr><td><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/deep_AL.md">Deep AL</a></td><td>AL with deep neural networks.</td></tr></tbody></table></div><h3 id="Contributing"><a href="#Contributing" class="headerlink" title="Contributing"></a><strong>Contributing</strong></h3><p>If you find any valuable researches, please feel free to <a href="https://github.com/SupeRuier/awesome-active-learning/pulls">pull request</a> or contact <a href="ruihe.cs@gmail.com">ruihe.cs@gmail.com</a> to update this repository.Comments and suggestions are also very welcome!</p><h1 id="1-What-is-AL"><a href="#1-What-is-AL" class="headerlink" title="1. What is AL?"></a>1. What is AL?</h1><p>High labeling cost is common in machine learning community.Acquiring a heavy number of annotations hindering the application of machine learning methods.Active learning is one approach to relief this annotation burden.The intuition is that not all the instances are equally important to the desired task, so only labeling the more important instances might bring cost reduction.</p><p>It is very hard to find a formal definition of general AL within a single optimization function.It would be better to define specific AL under specific problem settings.Hence, we only point out the essences of AL in this section.<strong>When we talk about active learning, we talk about</strong>:</p><ul><li>an approach to reduce the annotation cost in machine learning.</li><li>the ways to select the most important instances for the corresponding tasks.</li><li>(in most cases) an interactive labeling manner between algorithms and oracles.</li><li>a machine learning setting where human experts could be involved.</li></ul><h1 id="2-Reviews-Surveys-Benchmarks"><a href="#2-Reviews-Surveys-Benchmarks" class="headerlink" title="2. Reviews/Surveys/Benchmarks"></a>2. Reviews/Surveys/Benchmarks</h1><p>There have been several reviews/surveys/benchmarks for this topic.They provided a good overview for the field.</p><p><strong>Reviews/Surveys</strong>:</p><ul><li>Active learning: theory and applications <a href="https://ai.stanford.edu/~koller/Papers/Tong:2001.pdf.gz">[2001]</a></li><li>Active Learning Literature Survey <strong>(Recommend to read)</strong><a href="https://minds.wisconsin.edu/handle/1793/60660">[2009]</a></li><li>A survey on instance selection for active learning <a href="https://link.springer.com/article/10.1007/s10115-012-0507-8">[2012]</a></li><li>Active Learning: A Survey <a href="https://www.taylorfrancis.com/books/e/9780429102639/chapters/10.1201/b17320-27">[2014]</a></li><li>Active Learning Query Strategies for Classification, Regression, and Clustering: A Survey <a href="https://link.springer.com/article/10.1007/s11390-020-9487-4">[2020]</a>[Journal of Computer Science and Technology]</li><li>A Survey of Active Learning for Text Classification using Deep Neural Networks <a href="https://arxiv.org/pdf/2008.07267.pdf">[2020]</a></li><li>A Survey of Deep Active Learning <a href="https://arxiv.org/pdf/2009.00236.pdf">[2020]</a></li><li>Active Learning: Problem Settings and Recent Developments <a href="https://arxiv.org/pdf/2012.04225.pdf">[2020]</a></li><li>From Model-driven to Data-driven: A Survey on Active Deep Learning <a href="https://arxiv.org/pdf/2101.09933.pdf">[2021]</a></li><li>Understanding the Relationship between Interactions and Outcomes in Human-in-the-Loop Machine Learning <a href="http://harp.ri.cmu.edu/assets/pubs/hil_ml_survey_ijcai_2021.pdf">[2021]</a>: HIL, a wider framework.</li><li>A Survey on Cost Types, Interaction Schemes, and Annotator Performance Models in Selection Algorithms for Active Learning in Classification <a href="https://arxiv.org/pdf/2109.11301.pdf">[2021]</a></li><li>A Comparative Survey of Deep Active Learning <a href="https://arxiv.org/pdf/2203.13450.pdf">[2022]</a></li></ul><p><strong>Benchmarks</strong>:</p><ul><li>A Comparative Survey: Benchmarking for Pool-based Active Learning <a href="https://www.ijcai.org/proceedings/2021/0634.pdf">[2021]</a>[IJCAI]</li><li>A Framework and Benchmark for Deep Batch Active Learning for Regression <a href="https://arxiv.org/pdf/2203.09410.pdf">[2022]</a></li></ul><h1 id="3-Problem-Settings"><a href="#3-Problem-Settings" class="headerlink" title="3. Problem Settings"></a>3. Problem Settings</h1><p>In this section, <strong>the specific problems which active learning is trying to solve are described</strong>.The previous works are organized in a problem-oriented order.The methods are categorized for the corresponding settings in the subpage.</p><p><strong>Three levels of problem settings</strong>:</p><ol><li>Basic Problem Settings<ul><li>Under the basic scenarios: Pool-based/Stream-based/Query synthesis</li><li>Under the basic tasks: Classification/Regression</li></ul></li><li>Advanced Problem Settings<ul><li>Under many variants of machine learning problem settings</li></ul></li><li>Tasks from other Research Fields<ul><li>With more complex tasks from other research fields</li></ul></li></ol><h2 id="3-1-Basic-Problem-Settings-Three-basic-scenarios"><a href="#3-1-Basic-Problem-Settings-Three-basic-scenarios" class="headerlink" title="3.1. Basic Problem Settings (Three basic scenarios)"></a>3.1. Basic Problem Settings (Three basic scenarios)</h2><p>There are three basic types of scenarios, almost all the AL works are build on these scenarios.The scenarios are different in where the queried instances are from:</p><ul><li><strong>pool-based</strong>: select from a pre-collected data pool</li><li><strong>stream-based</strong>: select from a steam of incoming data</li><li><strong>query synthesis</strong>: generate query instead of selecting data</li></ul><p>For the most basic AL researches, they usually study on two basic tasks:</p><ul><li>classification</li><li>regression</li></ul><p>The details and the list of works could see <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_problem.md"><strong>here</strong></a>.</p><h2 id="3-2-Advanced-Problem-Settings"><a href="#3-2-Advanced-Problem-Settings" class="headerlink" title="3.2. Advanced Problem Settings"></a>3.2. Advanced Problem Settings</h2><p>There are many variants of machine learning problem settings with <strong>more complex assumptions</strong>.Under these problem settings, AL could be further applied.</p><ul><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MCAL.md">Multi-class active learning</a>: In a classification task, each instance has one label from multiple classes (more than 2).</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MLAL.md">Multi-label active learning</a>: In a classification task, each instance has multiple labels.</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MTAL.md">Multi-task active learning</a>: The model or set of models handles multiple different tasks simultaneously. For instance, handle two classification tasks at the same time, or one classification and one regression. </li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MDAL.md">Multi-domain active learning</a>: Similar to multi-task, but the data are from different datasets(domains). The model or set of models handles multiple datasets simultaneously.</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MVAL.md">Multi-view/modal active learning</a>: The instances might have different views (different sets of features). The model or set of models handles different views simultaneously.</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MIAL.md">Multi-instance active learning</a>: The instances are organized into bags and training labels are assigned at the bag level.</li></ul><h2 id="3-3-Tasks-in-other-AI-Research-Fields"><a href="#3-3-Tasks-in-other-AI-Research-Fields" class="headerlink" title="3.3. Tasks in other AI Research Fields"></a>3.3. Tasks in other AI Research Fields</h2><p>In many AI research fields, the tasks can’t be simply marked as classification or regression.They either acquire different types of outputs or assume a unusual learning process.So AL algorithms should be revised/developed for these problem settings.Here we summarized the works which <strong>use AL to reduce the cost of annotation in many other AI research fields</strong>.</p><ul><li>Computer Vision (CV)</li><li>Natural Language Processing (NLP)</li><li>Transfer learning/Domain adaptation</li><li>Metric learning/Pairwise comparison/Similarity learning</li><li>One/Few/Zero-shot learning</li><li>Graph Processing</li><li>etc.(The full list of fields could see <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_combinations.md"><strong>here</strong></a>)</li></ul><h1 id="4-Theoretical-Support-for-Active-Learning"><a href="#4-Theoretical-Support-for-Active-Learning" class="headerlink" title="4. Theoretical Support for Active Learning"></a>4. Theoretical Support for Active Learning</h1><p>There have been many theoretical supports for AL.Most of them are focus on finding a performance guarantee or the weakness of AL selection.(This section has not finished yet.)</p><h1 id="5-Practical-Considerations-to-Apply-AL"><a href="#5-Practical-Considerations-to-Apply-AL" class="headerlink" title="5. Practical Considerations to Apply AL"></a>5. Practical Considerations to Apply AL</h1><p>Many researches of AL are built on very idealized experimental setting.When AL is used to real life scenarios, the practical situations usually do not perfectly match the assumptions in the experiments.These <strong>changes of assumptions</strong> lead issues which hinders the application of AL.In this section, the practical considerations are reviewed under different assumptions.The details and the list of works could see <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/practical_considerations.md"><strong>here</strong></a>.</p><div class="table-container"><table><thead><tr><th>Assumption Type</th><th>Practical Considerations</th></tr></thead><tbody><tr><td>Data</td><td>Imbalanced data</td></tr><tr><td></td><td>Cost-sensitive case</td></tr><tr><td></td><td>Logged data</td></tr><tr><td></td><td>Feature missing data</td></tr><tr><td></td><td>Multiple Correct Outputs</td></tr><tr><td></td><td>Unknown input classes</td></tr><tr><td></td><td>Different data types</td></tr><tr><td></td><td>Data with Perturbation</td></tr><tr><td>Oracle</td><td>The assumption change on single oracle (Noise/Special behaviors)</td></tr><tr><td></td><td>Multiple/Diverse labeler (ability/price)</td></tr><tr><td>Workflow</td><td>Cold start</td></tr><tr><td></td><td>Stop criteria</td></tr><tr><td>Scale</td><td>Large-scale</td></tr><tr><td>Training cost</td><td>Take into account the training cost</td></tr><tr><td></td><td>Incrementally Train</td></tr><tr><td>Query types</td><td>Provide other feedbacks other than just labels</td></tr><tr><td>Performance metric</td><td>Other than the learning curves</td></tr></tbody></table></div><h1 id="6-Real-World-Applications-of-AL"><a href="#6-Real-World-Applications-of-AL" class="headerlink" title="6. Real-World Applications of AL"></a>6. Real-World Applications of AL</h1><p>We have introduced that AL could be used in many <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_combinations.md">other AI research fields</a>.In addition, AL has already been used in many real-world applications.For some reasons, the implementations in many companies are confidential.But we can still find many applications from several published papers and websites.</p><p>Basically, there are two types of applications: <strong>scientific applications</strong> &amp; <strong>industrial applications</strong>.We summarized a list of works <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_applications.md"><strong>here</strong></a>.</p><h1 id="7-Resources"><a href="#7-Resources" class="headerlink" title="7. Resources"></a>7. Resources</h1><h2 id="7-1-Software-Packages-Libraries"><a href="#7-1-Software-Packages-Libraries" class="headerlink" title="7.1. Software Packages/Libraries"></a>7.1. Software Packages/Libraries</h2><div class="table-container"><table><thead><tr><th>Name</th><th>Languages</th><th>Author</th><th>Notes</th></tr></thead><tbody><tr><td><a href="https://github.com/google/active-learning">AL playground</a></td><td>Python(scikit-learn, keras)</td><td>Google</td><td>Abandoned</td></tr><tr><td><a href="https://github.com/modAL-python/modAL">modAL</a></td><td>Python(scikit-learn)</td><td>Tivadar Danka</td><td>Keep updating</td></tr><tr><td><a href="https://github.com/ntucllab/libact">libact</a></td><td>Python(scikit-learn)</td><td>NTU(Hsuan-Tien Lin group)</td><td></td></tr><tr><td><a href="https://github.com/NUAA-AL/ALiPy">ALiPy</a></td><td>Python(scikit-learn)</td><td>NUAA(Shengjun Huang)</td><td>Include MLAL</td></tr><tr><td><a href="https://github.com/rmunro/pytorch_active_learning">pytorch_active_learning</a></td><td>Python(pytorch)</td><td>Robert Monarch</td><td>Keep updating &amp; include active transfer learning</td></tr><tr><td><a href="https://github.com/ej0cl6/deep-active-learning">DeepAL</a></td><td>Python(scikit-learn, pytorch)</td><td>Kuan-Hao Huang</td><td>Keep updating &amp; deep neural networks</td></tr><tr><td><a href="https://github.com/ElementAI/baal/">BaaL</a></td><td>Python(scikit-learn, pytorch)</td><td>ElementAI</td><td>Keep updating &amp; bayesian active learning</td></tr><tr><td><a href="https://github.com/IBM/low-resource-text-classification-framework">lrtc</a></td><td>Python(scikit-learn, tensorflow)</td><td>IBM</td><td>Text classification</td></tr><tr><td><a href="https://github.com/webis-de/small-text">Small-text</a></td><td>Python(scikit-learn, pytorch)</td><td>Christopher Schröder</td><td>Text classification</td></tr><tr><td><a href="https://github.com/PatrickZH/DeepCore">DeepCore</a></td><td>Python(scikit-learn, pytorch)</td><td>Guo et al.</td><td>In the coreset selection formulation</td></tr><tr><td><a href="https://github.com/RelationRx/pyrelational">PyRelationAL: A Library for Active Learning Research and Development</a></td><td>Python(scikit-learn, pytorch)</td><td>Scherer et al.</td><td></td></tr><tr><td><a href="https://github.com/SineZHAN/deepALplus/"> DeepAL+</a></td><td>Python(scikit-learn, pytorch)</td><td>Zhan</td><td>An extension for DeepAL</td></tr></tbody></table></div><h2 id="7-2-Tutorials"><a href="#7-2-Tutorials" class="headerlink" title="7.2. Tutorials"></a>7.2. Tutorials</h2><div class="table-container"><table><thead><tr><th>Title</th><th>Year</th><th style="text-align:center">Lecturer</th><th>Occasion</th><th>Notes</th></tr></thead><tbody><tr><td><a href="https://github.com/Azure/active-learning-workshop">Active learning and transfer learning at scale with R and Python</a></td><td>2018</td><td style="text-align:center">-</td><td>KDD</td><td></td></tr><tr><td><a href="https://www.youtube.com/watch?v=_Ql5vfOPxZU">Active Learning from Theory to Practice</a></td><td>2019</td><td style="text-align:center">Robert Nowak &amp; Steve Hanneke</td><td>ICML</td><td></td></tr><tr><td><a href="https://jacobgil.github.io/deeplearning/activelearning">Overview of Active Learning for Deep Learning</a></td><td>2021</td><td style="text-align:center">Jacob Gildenblat</td><td>Personal Blog</td></tr></tbody></table></div><h1 id="8-Groups-Scholars"><a href="#8-Groups-Scholars" class="headerlink" title="8. Groups/Scholars"></a>8. Groups/Scholars</h1><p>We also list several scholars who are currently heavily contributing to this research direction.</p><ol><li><a href="https://www.csie.ntu.edu.tw/~htlin/">Hsuan-Tien Lin</a></li><li><a href="http://parnec.nuaa.edu.cn/huangsj/">Shengjun Huang</a> (NUAA)</li><li><a href="https://sites.google.com/site/drwuHUST/publications/completepubs">Dongrui Wu</a> (Active Learning for Regression)</li><li>Raymond Mooney</li><li><a href="http://ise.thss.tsinghua.edu.cn/MIG/gyc.html">Yuchen Guo</a></li><li><a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=fEhNO7YAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Steve Hanneke</a></li></ol><p>Several young researchers who provides valuable insights for AL:</p><ul><li>Jamshid Sourati [University of Chicago]: Deep neural networks.</li><li>Stefano Teso [University of Trento]: Interactive learning &amp; Human-in-the-loops.</li><li>Xueyin Zhan [City University of Hong Kong]: Provide several invaluable comparative surveys.</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;This is the introduction for the &lt;a href=&quot;https://github.com/SupeRuier/awesome-active-learning&quot;&gt;Awesome-Active-Learning&lt;/a&gt; project.
&lt;strong&gt;Hope you can find everything you need about active learning (AL) in this repository.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这篇博文同样有一份&lt;strong&gt;中文版本&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;/machine-learning/al-all-in-one/&quot; title=&quot;主动学习，看这一篇就够了&quot;&gt;主动学习，看这一篇就够了&lt;/a&gt;&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="active-learning" scheme="https://blog.superui.cc/tags/active-learning/"/>
    
  </entry>
  
  <entry>
    <title>主动学习(Active Learning)，看这一篇就够了</title>
    <link href="https://blog.superui.cc/machine-learning/al-all-in-one/"/>
    <id>https://blog.superui.cc/machine-learning/al-all-in-one/</id>
    <published>2022-07-19T04:00:00.000Z</published>
    <updated>2022-07-19T04:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>本文是对自己 <a href="https://github.com/SupeRuier/awesome-active-learning">Awesome-Active-Learning</a> 项目的一个宣传及简要介绍，不定期更新。</p><p>An <strong>English Version</strong> Of This Post: <strong><a href="/machine-learning/awesome-active-learning/" title="Awesome Active Learning">Awesome Active Learning</a></strong>.</p><span id="more"></span><h2 id="0-写在最前"><a href="#0-写在最前" class="headerlink" title="0. 写在最前"></a>0. 写在最前</h2><p>在自己对主动学习（Active Learning）的学习和研究过程中，一直断断续续收集整理了很多不同方向的文章和研究进展，日积月累，整理的内容开始完善和系统化，于是将其开源成 <a href="https://github.com/SupeRuier/awesome-active-learning">awesome active learning</a> 项目。</p><p>对于该项目，我的初衷是：维护一个<strong>包含主动学习方方面面的知识库</strong>，这样研究者和工程师可以较快锁定相关工作并展开科研。 同时，也由于个人的力量有限，希望大家可以一起对主动学习的相关进展进行追踪梳理和总结。如发现遗漏或错误，或想要增补一些新的内容，欢迎大家在该项目下 pull request 或者通过邮件 ruihe.cs@gmail.com 联系我。知识库的整体结构如下图所示，希望大家能在这个知识库项目中找到你需要的关于主动学习的一切信息。</p><div style="width:100%;margin:auto"><img src="/machine-learning/al-all-in-one/repo-structure.png" class=""></div><p>​</p><h3 id="0-1-关于本文"><a href="#0-1-关于本文" class="headerlink" title="0.1. 关于本文"></a>0.1. 关于本文</h3><p>本文旨在对主动学习（AL）领域从一个<strong>以问题为导向</strong>的角度，展开阐述当前主动学习的研究和应用。 此处的以问题为导向包含两个方面，一是指主动学习期望解决的实际问题，二是指主动学习应用中的技术问题。 本文的重点是对这些问题进行基本的描述和文献总结，从而让大家对主动学习的适用场景有一定的认识。 一些关于理论和技术上的分类也会有所提及，但是详细内容不会在本文中展开。此外，本文不涉及列举具体场景下具体算法的文献，若阁下对所描述的问题场景有兴趣，可以移步 github 项目并查阅相关文献列表。</p><h3 id="0-2-推荐阅读的-Survey-Review"><a href="#0-2-推荐阅读的-Survey-Review" class="headerlink" title="0.2. 推荐阅读的 Survey/Review"></a>0.2. 推荐阅读的 Survey/Review</h3><p>作为一个相对成熟的领域，目前已有不少相关的文献综述和领域调研。 此处推荐以下两篇，其余的可以去我们的项目中查看完整的列表： </p><ul><li>Active Learning Literature Survey [<a href="https://minds.wisconsin.edu/handle/1793/60660">2012</a>]：作者为 Burr Settles。这是最著名也是相对较早的一篇调研，至今已有数千次引用，初步了解可以看这一篇。 </li><li>A Survey on Active Deep Learning: From Model-Driven to Data-Driven [<a href="https://arxiv.org/pdf/2101.09933.pdf">2020</a>]：较新的一篇文章，主要是在技术角度对主动学习的方法进行分类，个人认为这篇文章需要在对具体问题有足够清晰地了解之后再看，否则过早陷入对技术的纠结其实不利于对领域的认知。</li></ul><h3 id="0-3-项目关键章节传送门"><a href="#0-3-项目关键章节传送门" class="headerlink" title="0.3. 项目关键章节传送门"></a>0.3. 项目关键章节传送门</h3><p>对于一些 <strong>AL 的关键方向</strong>，我们在此设立传送门，可以直达我们项目中的相关章节（英文版）。</p><ul><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/pb_classification.md">主动学习策略分类</a>：在 Pool-based 场景下的主要方法分类。</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_combinations.md">AI 中的 AL</a>：用主动学习来尝试解决 AI 各问题下的标注/查询成本昂贵问题。</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_applications.md">AL 的应用方向</a>：<strong>科学研究应用</strong>和<strong>工业界应用</strong>两个方面。</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/practical_considerations.md">AL 使用中的实际考虑</a>：当 AL 假设不完全成立时，或者遇到新的问题场景时如何解决。</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/intrinsic_issues.md">AL 内在的问题</a>：AL 这种选取模式带来的不可避免的问题。</li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/deep_AL.md">深度主动学习</a>：如何在深度神经网络上使用主动学习。</li></ul><h2 id="1-什么是主动学习？（若已有背景知识可跳过）"><a href="#1-什么是主动学习？（若已有背景知识可跳过）" class="headerlink" title="1. 什么是主动学习？（若已有背景知识可跳过）"></a>1. 什么是主动学习？（若已有背景知识可跳过）</h2><p>监督学习问题中，存在标记成本较为昂贵且标记难以大量获取的问题。 针对一些特定任务，只有行业专家才能为样本做上准确标记。在此问题背景下，主动学习（Active Learning, AL）尝试通过选择性的标记较少数据而训练出表现较好的模型。下面是从 Burr 的 Survey 中选取的一个简单的例子，图(c)中使用主动学习策略仅选取30个样本作为训练集训练出的逻辑回归模型即可达到90%的准确率，而图(b)中随机选取的30个样本训练出的模型却相对表现较差。</p><div style="width:100%;margin:auto"><img src="/machine-learning/al-all-in-one/toy_example.jpg" class="" title="在一个人造数据集上主动学习策略与随机选取的对比"></div><p>从整个学习过程来看，在相同数目的标记样本下，主动学习选取的表现要好于随机选取的表现。这种可以描绘出整个学习过程的曲线也一般用于对主动学习方法进行评估。​</p><div style="width:80%;margin:auto"><img src="/machine-learning/al-all-in-one/learning_curve.jpg" class="" title="主动学习的学习曲线"></div><p>主动学习最重要的假设是不同样本对于特定任务的重要程度不同，所以带来的表现提升也不全相同。选取较为重要的样本可以使当前模型以较少的标记样本数得到较好的表现。在这一过程中，主动学习的本质是对样本的重要性（/信息度/期望带来的表现等）等进行评估。绝大多数的工作都是围绕如何评估样本来展开。</p><p>但是随着领域的发展，相关文献的增多，主动学习一词可能在强调不同的东西。<strong>总的来说，当我们谈起主动学习的时候，我们指的是</strong>：</p><ul><li>从<strong>问题</strong>的角度：通过以某种主动策略构建较小训练集来<strong>减少标记成本</strong>的机器学习方式。</li><li>从<strong>策略</strong>的角度：以某种方式对未标记<strong>样本重要性的评估</strong>。</li><li>从<strong>训练</strong>的角度：一种<strong>交互式</strong>的标记、训练、评估流程。</li></ul><h2 id="2-主动学习的问题-任务场景"><a href="#2-主动学习的问题-任务场景" class="headerlink" title="2. 主动学习的问题/任务场景"></a>2. 主动学习的问题/任务场景</h2><p>标记成本高昂的情况在很多任务下都存在，所以主动学习的潜在应用问题还是比较广泛的。本节，我们会对大部分主动学习涉及到的问题和任务场景进行简要介绍。</p><h3 id="2-1-基础问题场景"><a href="#2-1-基础问题场景" class="headerlink" title="2.1 基础问题场景"></a>2.1 基础问题场景</h3><p>这里我们只讨论最基础的分类和回归问题。在这两类问题下，有着三种不同的主动学习场景： </p><ul><li>Pool-based scenario：此类场景通常提供一个未标记的数据池，主动学习策略在数据池中选取相应样本进行标记。 </li><li>Stream-based scenario：此类场景中，数据以数据流的形式输入，主动学习策略需要确定对当前数据进行标记还是直接用现有模型预测。 </li><li>Query synthesis scenario：此类场景较为少见，一个未标记的数据池通常也被提供，但是主动学习策略并不是在数据池中挑选样本进行查询，而是自行生成新样本进行查询。</li></ul><p>所以我们就有了如下几个子问题：</p><div class="table-container"><table><thead><tr><th></th><th>Pool-based</th><th>Stream-based</th><th>Query synthesis</th></tr></thead><tbody><tr><td>Classification</td><td>PB-classification (most works)</td><td>SB-classification</td><td>(rare)</td></tr><tr><td>Regression</td><td>PB-regression</td><td>SB-regression (rare)</td><td>(rare)</td></tr></tbody></table></div><p>其中目前据大多数的基础研究都是基于 pool-based classification，目前大多数的文献分类也是基于此问题而分类的。 此处我们以介绍清楚问题场景为主，具体对于每一个问题的具体方法，请参考：<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_problem.md">Basic AL Problem Settings</a></p><h3 id="2-2-复杂问题场景"><a href="#2-2-复杂问题场景" class="headerlink" title="2.2 复杂问题场景"></a>2.2 复杂问题场景</h3><p>此处的复杂主要是指任务相较于简单的分类回归任务复杂。在机器学习的领域中，有不少衍生问题，包括但不限于多分类问题，多标签问题，多任务问题。作为监督学习问题，这些问题同样可以使用主动学习来缓解标记压力： </p><ul><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MCAL.md">Multi-class active learning</a>: 在分类任务中，每个样本的标签取值可以从多种取值里选取（不小于两种）。 </li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MLAL.md">Multi-label active learning</a>: 在分类任务中，每个样本可以同时存在多个标签。 </li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MTAL.md">Multi-task active learning</a>: 多个任务需要被同时处理，比如同时进行两个分类任务，或同时进行一个分类和一个回归任务。 </li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MDAL.md">Multi-domain active learning</a>: 与多任务学习较为相似，多领域学习则是在不同的领域（数据分布/数据集）上学习相同的任务。 </li><li><a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/MVAL.md">Multi-view/modal active learning</a>: 多视角或多模态学习中的样本可能会有不同形式的表征。比如不同角度拍摄的同一个物品，来源于同一视频的音轨和视轨等。</li></ul><p>针对这些问题，主动学习方法一般都会有特定的适配和修改，仅仅使用简单场景上的方法可能不会有较好的表现。</p><h3 id="2-3-与其他-AI-领域结合的问题场景"><a href="#2-3-与其他-AI-领域结合的问题场景" class="headerlink" title="2.3 与其他 AI 领域结合的问题场景"></a>2.3 与其他 AI 领域结合的问题场景</h3><p>由于篇幅限制，主动学习与 AI 结合的领域和工作可以参见以下链接：<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_combinations.md">AL Aids AI</a>。</p><p>相较于之前提到的场景，AI 领域其实有不少更加复杂的问题。这些问题可能不能简单的用分类回归来表述，更多的时候是多种问题的结合。此类问题一般较为细致，定义也相对狭隘。针对这些具体问题，主动学习也有很多结合。 这些问题包括但不限于： </p><ul><li>Computer Vision (CV)   <ul><li>Image Segmentation   </li><li>Object Detection </li></ul></li><li>Natural Language Processing (NLP)   <ul><li>Sentence Classification   </li><li>Named Entity Recognition </li></ul></li><li>Domain adaptation/Transfer learning </li><li>Metric learning/Pairwise comparison/Similarity learning </li><li>One/Few/Zero-shot learning - Graph Processing </li><li>etc.</li></ul><h2 id="3-主动学习的技术角度的分类"><a href="#3-主动学习的技术角度的分类" class="headerlink" title="3. 主动学习的技术角度的分类"></a>3. 主动学习的技术角度的分类</h2><p>在上一节中我们以问题为导向介绍了绝大多数可以使用主动学习来解决的问题，可以说涵盖了大部分最重要的主动学习的相关工作。这一节的介绍并不是以问题为导向，而是从技术角度对现有方法进行分类。我们选用了两个角度： </p><ul><li>设计原理角度：希望读者对不同种策略有一定的认识。 </li><li>适用模型角度：希望读者可以直接找到适用于自己模型的策略。</li></ul><h3 id="3-1-从设计原理上分类"><a href="#3-1-从设计原理上分类" class="headerlink" title="3.1 从设计原理上分类"></a>3.1 从设计原理上分类</h3><p>这个角度是目前大部分 review/survey 的分类角度。由于很多小问题中的相关文献较少，在我们的项目中，我们在对应的问题介绍下直接对相应方法作了简要分类。本文中，我们的分类主要作用于最常见和最广泛的 Pool-based Classification 场景。绝大多数著名的主动学习工作都是在此场景下进行的。同样的，这里我们只简述设计原理，具体的文献列表参见我们项目中的<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/pb_classification.md">这一章节</a>。在这里，我们把主动学习的设计原理（i.e.主动学习对样本的评估方法）分为五大类：</p><div class="table-container"><table><thead><tr><th style="text-align:left">评估方法</th><th style="text-align:left">简述</th><th style="text-align:left">评论</th></tr></thead><tbody><tr><td style="text-align:left">Informativeness</td><td style="text-align:left">一般来说指模型对选取样本取值的不确信程度</td><td style="text-align:left">忽略了数据分布的影响</td></tr><tr><td style="text-align:left">Representativeness-impart</td><td style="text-align:left">考虑了选取样本是否可以对数据分布起到代表作用</td><td style="text-align:left">通常来说和informativeness一起使用，此类方法和批选取方法可能会有重叠</td></tr><tr><td style="text-align:left">Expected Improvements</td><td style="text-align:left">考虑选取样本能为当前模型带来多少性能提升</td><td style="text-align:left">此类评估通常较为耗时</td></tr><tr><td style="text-align:left">Learn to score</td><td style="text-align:left">不人为启发式地设计选取策略，而是学习一个选取策略</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">Others</td><td style="text-align:left">有一些工作较难分类到上述的类别中</td></tr></tbody></table></div><p>此处我们也列出这几类方法之下的小类： </p><ul><li>Informativeness   <ul><li>Uncertainty-based sampling   </li><li>Disagreement-based sampling </li></ul></li><li>Expected Improvements </li><li>Representativeness-impart sampling  <ul><li>Cluster-based sampling  </li><li>Density-based sampling   </li><li>Alignment-based sampling   </li><li>Expected loss on unlabeled data </li></ul></li><li>Learn to Score</li><li>Others</li></ul><p>此外，批选取的方法（batch active learning）也有众多研究，其与 representativeness-impart sampling 有一定的交叉，具体可以参阅以下链接：<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/batch_mode.md">Batch mode</a></p><h3 id="3-2-从适用模型上分类"><a href="#3-2-从适用模型上分类" class="headerlink" title="3.2 从适用模型上分类"></a>3.2 从适用模型上分类</h3><p>很多种主动学习选取策略都标榜自己是全模型通用（model-free）的，但是实际使用中，他们可能仅仅适用于一个或一类模型（model-dependent）。 此处我们总结了一些 model-dependent 的策略在特定模型上的工作。 由于业界的模型实在是过于多样，此处我们仅归纳了几类常用模型，且工作并不一定很全，之后这个章节也会更新。 具体的文献列表请查阅我们项目中的<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_technique_models.md">这一章节</a>。</p><p>这里我们仅列出一些我们总结到的模型： </p><ul><li>SVM/LR </li><li>Bayesian/Probabilistic Models </li><li>Gaussian Progress </li><li>Decision Trees </li><li>Neural Network</li></ul><p>此外，如何设计适用于神经网络的主动学习策略和框架也是一个比较重要的问题。我们也对相关的深度主动学习进行了调研，详情请查阅以下链接：<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/deep_AL.md">AL with Models</a></p><h2 id="4-将-AL-应用时的实际考虑"><a href="#4-将-AL-应用时的实际考虑" class="headerlink" title="4. 将 AL 应用时的实际考虑"></a>4. 将 AL 应用时的实际考虑</h2><p>我们之前讨论的是主动学习可以应用于什么问题场景，本节我们讨论的是实际应用主动学习的时候可能会遇到什么技术问题。 具体的内容列表请查阅我们项目中的这一章节：<a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/practical_considerations.md">Practical Considerations</a></p><p>简要来说，大部分的主动学习工作对数据，标注专家，问题规模等都是有着一般性的假设。比如“在一个几千样本上的平衡分类问题中，可以通过询问一个准确率百分之百的标注专家来获得标注数据”。但是这些假设在实际运用中可能并不总能保真，所以本节我们纳入了很多对实际问题的考虑。</p><p>具体的考虑如下：</p><ul><li>Data (imbalanced, biased, feature missing, etc.</li><li>Oracles (multiple labeler, diverse labeler, etc.)</li><li>Scale (large-scale)</li><li>Workflow (cold start problem, stop criteria, etc.)</li><li>Model training cost</li><li>Query/feedback types</li><li>Performance metric</li><li>Robustness</li><li>More assumptions</li></ul><p>可以说在这些问题上的研究拉近了主动学习到实际运用的距离。</p><h2 id="5-AL-的实际应用"><a href="#5-AL-的实际应用" class="headerlink" title="5. AL 的实际应用"></a>5. AL 的实际应用</h2><p>主动学习已经是一个较为成熟的技术，已经有很多研究工作将其应用于不同学科和领域。 这里我们将其分为两部分：科学研究应用和工业界应用。 具体的文献列表请查阅以下链接： <a href="https://github.com/SupeRuier/awesome-active-learning/blob/master/contents/AL_applications.md">AL Applications</a></p><h3 id="5-1-科学研究应用"><a href="#5-1-科学研究应用" class="headerlink" title="5.1 科学研究应用"></a>5.1 科学研究应用</h3><p>目前的工作主要聚焦于以下几个学科： </p><ul><li>Biology </li><li>Materials </li><li>Astronomy </li><li>Chemistry</li><li>Math and Statistics </li><li>Geology </li><li>Experiment Design / Experimental Condition Selection</li></ul><h3 id="5-2-工业界应用"><a href="#5-2-工业界应用" class="headerlink" title="5.2 工业界应用"></a>5.2 工业界应用</h3><p>工业界应用相对较广泛，此处列举几个较为常用的领域，其他内容请参阅我们的项目。 </p><ul><li>Remote Sensing</li><li>Medical Research  </li><li>Drug Discovery </li><li>Labeling System </li><li>Spam Detection </li><li>etc.</li></ul><h2 id="6-相关资料"><a href="#6-相关资料" class="headerlink" title="6. 相关资料"></a>6. 相关资料</h2><h3 id="6-1-软件包"><a href="#6-1-软件包" class="headerlink" title="6.1 软件包"></a>6.1 软件包</h3><p>在github上已经有不少基于Python的主动学习软件包： </p><div class="table-container"><table><thead><tr><th>Name</th><th>Languages</th><th>Author</th><th>Notes</th></tr></thead><tbody><tr><td><a href="https://github.com/google/active-learning">AL playground</a></td><td>Python(scikit-learn, keras)</td><td>Google</td><td>Abandoned</td></tr><tr><td><a href="https://github.com/modAL-python/modAL">modAL</a></td><td>Python(scikit-learn)</td><td>Tivadar Danka</td><td>Keep updating</td></tr><tr><td><a href="https://github.com/ntucllab/libact">libact</a></td><td>Python(scikit-learn)</td><td>NTU(Hsuan-Tien Lin group)</td><td></td></tr><tr><td><a href="https://github.com/NUAA-AL/ALiPy">ALiPy</a></td><td>Python(scikit-learn)</td><td>NUAA(Shengjun Huang)</td><td>Include MLAL</td></tr><tr><td><a href="https://github.com/rmunro/pytorch_active_learning">pytorch_active_learning</a></td><td>Python(pytorch)</td><td>Robert Monarch</td><td>Keep updating &amp; include active transfer learning</td></tr><tr><td><a href="https://github.com/ej0cl6/deep-active-learning">DeepAL</a></td><td>Python(scikit-learn, pytorch)</td><td>Kuan-Hao Huang</td><td>Keep updating &amp; deep neural networks</td></tr><tr><td><a href="https://github.com/ElementAI/baal/">BaaL</a></td><td>Python(scikit-learn, pytorch)</td><td>ElementAI</td><td>Keep updating &amp; bayesian active learning</td></tr><tr><td><a href="https://github.com/IBM/low-resource-text-classification-framework">lrtc</a></td><td>Python(scikit-learn, tensorflow)</td><td>IBM</td><td>Text classification</td></tr><tr><td><a href="https://github.com/webis-de/small-text">Small-text</a></td><td>Python(scikit-learn, pytorch)</td><td>Christopher Schröder</td><td>Text classification</td></tr><tr><td><a href="https://github.com/PatrickZH/DeepCore">DeepCore</a></td><td>Python(scikit-learn, pytorch)</td><td>Guo et al.</td><td>In the coreset selection formulation</td></tr><tr><td><a href="https://github.com/RelationRx/pyrelational">PyRelationAL: A Library for Active Learning Research and Development</a></td><td>Python(scikit-learn, pytorch)</td><td>Scherer et al.</td><td></td></tr><tr><td><a href="https://github.com/SineZHAN/deepALplus/"> DeepAL+</a></td><td>Python(scikit-learn, pytorch)</td><td>Zhan</td><td>An extension for DeepAL</td></tr></tbody></table></div><h3 id="6-2-Tutorials"><a href="#6-2-Tutorials" class="headerlink" title="6.2 Tutorials"></a>6.2 Tutorials</h3><p>之前也有一些关于主动学习的研讨班内容： </p><ul><li><a href="https://github.com/Azure/active-learning-workshop">active-learning-workshop</a>: KDD 2018 Hands-on Tutorial: Active learning and transfer learning at scale with R and Python </li><li><a href="https://www.youtube.com/watch?v=_Ql5vfOPxZU">Active Learning from Theory to Practice</a>: ICML 2019 Tutorial. </li><li><a href="https://jacobgil.github.io/deeplearning/activelearning">Overview of Active Learning for Deep Learning</a>: Jacob Gildenblat.</li></ul><h3 id="6-3-领域内研究学者"><a href="#6-3-领域内研究学者" class="headerlink" title="6.3 领域内研究学者"></a>6.3 领域内研究学者</h3><p>参见我们的<a href="https://github.com/SupeRuier/awesome-active-learning#8-groupsscholars">项目</a>，排名不分先后（有待补充） </p>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;本文是对自己 &lt;a href=&quot;https://github.com/SupeRuier/awesome-active-learning&quot;&gt;Awesome-Active-Learning&lt;/a&gt; 项目的一个宣传及简要介绍，不定期更新。&lt;/p&gt;
&lt;p&gt;An &lt;strong&gt;English Version&lt;/strong&gt; Of This Post: &lt;strong&gt;&lt;a href=&quot;/machine-learning/awesome-active-learning/&quot; title=&quot;Awesome Active Learning&quot;&gt;Awesome Active Learning&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="active-learning" scheme="https://blog.superui.cc/tags/active-learning/"/>
    
  </entry>
  
  <entry>
    <title>浪潮之巅</title>
    <link href="https://blog.superui.cc/reading-note/top-of-the-wave/"/>
    <id>https://blog.superui.cc/reading-note/top-of-the-wave/</id>
    <published>2022-06-14T15:10:00.000Z</published>
    <updated>2022-06-14T15:10:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>一本介绍大型科技公司浪潮起落的书。</p><span id="more"></span><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>吴军</p><h2 id="内容简介"><a href="#内容简介" class="headerlink" title="内容简介"></a>内容简介</h2><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>一本了解世界互联网产业发展的必读书籍。以浪潮反应产业的起伏，对于个人择业或者行业研究有着一定的参考价值。</p><h3 id="感想看法"><a href="#感想看法" class="headerlink" title="感想看法"></a>感想看法</h3><ol><li>这本书还是有些过时，很多内容需要更新。比如微软和苹果公司的关系。</li><li>竟然还写了红杉资本的联系方式，有趣。</li><li>由于Google 很明智地没有在互联网泡沫高峰期疯狂地扩展，而是实实在在地、低调地做好自己的搜索引擎，因此它早期烧钱的速度非常之慢。2000 年的时候它没有急着上市，避免了绝大多数互联网公司大起大落并且最终关门的厄运，同时最早期的优秀人才没有拿了钱就走掉，因此Google 的骨干完好无损。感觉这个可以用来研究没来得及上市的蚂蚁金服的发展上。</li><li>制定规则的重要性一次次体现。</li><li>让人思考商业模式和技术的权衡，或许商业模式更加重要。</li><li>一个巨大的公司拓展新生代业务看起来还是比较难的。</li><li>与大学的合作研发看起来性价比极高，远高于自建独立实验室。</li><li>对于商业来说，技术并不是最重要的。</li><li>“存在即合理”，的确能不断的找到这句话的印证。</li><li>创业公司的员工或许都能以一当十？</li><li>其中有很多华为公司的部分，当时华为并不像现在一样人尽皆知，但是业内已经是名声响亮了。华为的成功有其必然性，其创办之初就剑指最先进的技术而不是二流技术。</li><li>流量并不是一切，很多中国的公司证明了这一点，无数次的烧钱没有转化为实际收入，都只是抱薪救火。所以说商业模式，预期产值或许更重要。</li><li>公司的掌舵人决策者实在是太为重要了。</li><li>技术并不是无敌的。</li><li>身体真的是创业者最大的本钱。今日孙剑博士去世，不由得重新感慨这一点。R.I.P.</li><li>业绩下滑时，裁员是很明智的决策。</li><li>革命是创业的重要部分，而不紧紧是“进化”。风投，或者说创业者（创业其实是在风投自己），要能准确的评估技术及其前景。</li><li>当公司已经足够大的时候，其市场占有率（增长前景）就难以翻番了。</li><li>斯坦福的校友组织的确比较有趣。</li><li>投资人对于公司的影响极大，公司总是要对股东负责。</li><li>2B 产品受经济大环境的影响太大，收入相对不如 2C 产品来得稳定。这个可能在经济周期中有一定的指导意义。</li><li>资金利用率&amp;自动化程度对企业的经济效益影响极大。</li><li>近期吹嘘了很多 web3.0 的概念，个人并不太知道这是什么。目测是一种元宇宙+数字货币+vr的一种缝合怪结合体？我们回顾 web2.0（打造通用平台，再由社会上的开发力量和广大用户补充内容），web3.0 的口号目前仍是以技术为导向还不是以问题和需求为导向，似乎就有一点像 web2.0 真正意义出现之前的那一波噱头了。那到底什么是 web3.0 呢？</li><li>个人一向推崇经济和金融的意义，因为他们对于实体经济起到了不可替代的资源调度作用。虽然还有很多逐利的资金追求泡沫和杀猪盘，但是仍然不能因此忽略它的绝大多数的积极意义。</li><li>当总有什么新词新指标来为新东西背书的时候，可能要留心这是不是一个泡沫了。</li><li>危机之下，求生或许是所有公司的本能，成功断臂求生可能才有未来的发展。</li><li>很多看似无关的技术都或许会因为一个产业结合在一起，整体还是要看产业对社会的效率有多大的提升。</li><li>有一些东西对用户而言的沉没成本极高，即使有更好用的新东西，也不会轻易转换。</li><li>有意思的是，作者指出“阿里巴巴只要它不犯大的错误，现在找不出一家公司可以挑战它的商业地位”。然后我们都知道，他犯了大的错误。然而这个错误真的是错误吗？见仁见智，只能说他过于自大却忘记了国内的监管环境，所以才有了后来的制裁。</li><li>“因果倒置”这种事情有时候还真的不一定能分辨出。所以马云的电子商务是因还是果呢？或许互为因果，但是很多时候要追究事物发生的原因。</li><li>不靠泡沫挣钱的时候，经济体才能繁荣发展。</li></ol><h1 id="内容摘录"><a href="#内容摘录" class="headerlink" title="内容摘录"></a>内容摘录</h1><h2 id="ATT"><a href="#ATT" class="headerlink" title="ATT"></a>ATT</h2><ul><li>ATT 不紧不慢地向上走过了百年，才爬到顶点，走下坡路却只要十年时间。（注：今天的 ATT 是由当年小贝尔公司之一的西南贝尔公司几次以小吃大合并出的类似于水电公司的设施服务公司，这类公司在美国统统称为 utility 公司，毫无技术可言。）</li><li>在很长的时间里，美国国际长途电话的价钱不是由市场决定的，而是由 ATT 和美国联邦通信委员会（FCC）谈判决定的</li><li>ATT 的总裁们并不真正拥有公司。他们之中不乏有远见者，但是根本左右不了董事会。</li><li>一般来讲，一个公司当前的股价，已经反映了当前和几年后的盈利能力。如果想让股价快速增长，公司的盈利就必须高于大家的预期</li><li>在工业史上，一种新技术代替旧的技术是不以人的意志为转移的。人生最幸运之事就是发现和顺应这个潮流。</li></ul><h2 id="IBM"><a href="#IBM" class="headerlink" title="IBM"></a>IBM</h2><ul><li>IBM 公司可能是世界上为数不多的成功地逃过历次经济危机，并且在历次技术革命中成功转型的公司。</li><li>IBM 能成为科技界的常青树，要归功于它的二字秘诀——保守。毫无疑问，保守使得 IBM 失去了无数发展机会，但是也让它能专注于最重要的事，并因此而立于不败之地。</li><li>我们可以将第二次世界大战作为机械时代和电子时代的分水岭。</li><li>社会的需求对科技进步的作用要超过十所大学。计算机就是在这个背景下被发明的。美国研制计算机的直接目的是在第二次世界大战时为军方计算弹道的轨迹。在流体力学中，计算量常常大到手工的计算尺无法计算的地步，因此，对通用计算机的需求就产生了。</li><li>在我个人看来，小华生对世界最大的贡献不是将 IBM 变成一个非常成功的公司，而是将计算机从政府部门和军方推广到民间，将它的功能由科学计算变成商用。</li><li>IBM PC 第一年的营业额大约是两亿美元，只相当于 IBM 当时营业额的 1% 左右，而利润还不如谈下一个大合同。要知道，卖掉十万台 PC 可比谈一个大型机合同费劲儿多了。因此，IBM 不可能把 PC 事业上升到公司的战略高度来考虑。</li><li>因为 IBM PC 的主要部件，如处理器芯片、磁盘驱动器、显示器和键盘等等，或者本身是第三家公司提供的、或者很容易制造，而它的操作系统 DOS 又是微软的。因此，IBM PC 很容易仿制。IBM PC 唯一一个操作系统的内核 BIOS 是自己的，但是很容易地就被破解了。在短短地几年间， IBM PC 的兼容机入雨后春笋般地冒了出来。</li><li>盖茨可不是一般的人，他的心志非常高远，他不会允许别人动微机软件这块大蛋糕，虽然此时的微软的规模远没法和 IBM 相比。盖茨明修栈道，暗渡陈仓，一方面和 IBM 合作开发 OS/2 ，挣了一点短期的钱，另一方面下大力气开发视窗操作系统（Windows）</li><li>到八十年代末，由于微机性能每十八个月就翻一番，微机慢慢开始胜任以前一些必须要大型机才能做的工作。这样，微机开始危及到大型机的市场。 IBM 出现了严重的亏损，有史以来第一次开始大规模裁员。</li><li>1993 年，从未在 IBM 工作过的郭士纳受命危难，出任 IBM 的首席执行官。他成功地完成了 IBM 从一个计算机硬件制造公司到一个以服务和软件为核心的服务性公司的转变，复兴了这个百年老店，并开创了 IBM 的十年持续发展。他的第一招用他自己的话讲是将 IBM 溶解掉，通俗地讲，就是开源节流。他首先裁掉了一些冗余的部门和一些毫无前途的项目。</li><li>对比几乎同时代 ATT 将公司拆分的做法，郭士纳完全是反其道而行之。他的目的是打造一只 IT 服务业的航空母舰。在公司内部，它引入竞争机制，一个项目可能有多个组背靠背地开发。为了防止互相拆台、加强合作，郭士纳将每个人的退休金和全公司的、而不是以前的各部门的效益挂钩。</li><li>郭士纳砍掉了一些偏重于理论而没有效益的研究，并且将研究和开发结合起来。一旦一个研究项目可以实用了，他就将整个研究组从实验室挪到产品部门。到后期，他甚至要求 IBM 的所有的研究员必须从产品项目中挣一定的工资。这种做法无疑很快地将研究转化成产品。但是这样做无疑会影响 IBM 长线研究和基础研究，为了弥补这方面的损失，IBM 加强了和大学的合作，在几十所大学开展了科研合作或者是设立了奖学金。</li><li>今天，IBM 成为了世界上最大的开源操作系统 Linux 服务器的生产商。</li><li>IBM 就是这样，时不时地调整内部结构，将一些非核心的、长期效益不好的部门卖掉，同时扩大核心的利润高的生意。</li><li>今天，它仍然是世界上人数最多、营业额和利润最高的技术公司。在可以预见的未来，它会随着科技发展的浪潮顺顺当当地发展，直到下一次大的技术革命。</li></ul><h2 id="Apple"><a href="#Apple" class="headerlink" title="Apple"></a>Apple</h2><ul><li>麦金托什是世界上第一种可以买得到的、拥有交互式图形界面并且使用鼠标的个人电脑。它的硬件部分性能略优于同期的 IBM PC 机，而它的操作系统领先当时 IBM-PC 的操作系统 DOS 整整一代。</li><li>苹果的股票九十年代开始是上升的，这就是电影中的阿甘觉得持有了苹果的股票就不用为钱发愁的原因。如果那个电影晚拍几年，导演就不得不找另一家公司的股票给阿甘了。</li><li>我和硅谷很多创业者聊过，发现他们对自己的公司，哪怕再小的公司，在感情上也象对自己的孩子一样亲。</li><li>他已经认识到了苹果封闭式的软硬件，从成本上讲，无法和微软加兼容机竞争，也无法为用户提供丰富的应用软件。乔布斯做了两件事，他在苹果的微机中逐渐采用了英特尔的通用处理器，同时采用 Free BSD 作新的苹果操作系统的内核。这样相对开放的体系使得全社会大量有兴趣的开源工程师很容易地为苹果开发软件。</li><li>乔布斯看到了两点最重要的事实，第一，虽然已经有了不少播放器，但是做的都不好，尤其是当音乐数量多了以后，查找和管理都很难。要知道，从一千首歌里面顺序找到自己想听的可能要花几分钟时间。另外，要把自己以前买的几十张 CD 上的歌倒到播放器上更是麻烦；第二，广大用户已经习惯戴着耳机从播放器中听歌而不是随身带着便携的 CD 唱机和几十张光盘。因此，它不需要花钱和时间培养出一个市场。基于这两点的考虑，乔布斯决定开发被称为 iPod 的音乐和录像播放器。</li><li>虽然它六百美元的价格实在贵了点，但是根据电器十八个月降一半价钱的规律，iPhone 很有可能成为今后普及的手机，成为苹果即 iPod 以后新的成长点，它甚至会冲击传统的手机行业。</li></ul><h2 id="计算机工业的生态链"><a href="#计算机工业的生态链" class="headerlink" title="计算机工业的生态链"></a>计算机工业的生态链</h2><ul><li>现在，每十八个月，计算机等 IT 产品的性能会翻一番；或者说相同性能的计算机等 IT 产品，每十八个月价钱会降一半。虽然，这个发展速度令人难以置信，但几十年来 IT 行业的发展始终遵循着摩尔定理预测的速度。</li><li>个人电脑工业整个的生态链是这样的：以微软为首的软件开发商吃掉硬件提升带来的全部好处，迫使用户更新机器让惠普和戴尔等公司收益，而这些整机生产厂再向英特尔这样的半导体厂订货购买新的芯片、同时向 Seagate 等外设厂购买新的外设。在这中间，各家的利润先后得到相应的提升，股票也随着增长。各个硬件半导体和外设公司再将利润投入研发，按照摩尔定理制定的速度，提升硬件性能，为微软下一步更新软件、吃掉硬件性能做准备。华尔街的投资者都知道，如果微软的开发速度比预期的慢，软件的业绩不好，那么就一定不能买英特尔等公司的股票了。</li><li>反摩尔定理使得 IT 行业不可能像石油工业或者是飞机制造业那样只追求量变，而必须不断寻找革命性的创造发明。因为任何一个技术发展赶不上摩尔定理要求的公司，用不了几年就会被淘汰。</li><li>有些愿意冒风险而追求高回报的投资家将钱凑在一起，交给既懂得理财又懂得技术的专业人士打理，投给有希望的公司和个人，这就渐渐形成了美国的风险投资机制。办好一个高科技公司还需要有既志同道合又愿意承担风险的专业人才，他们对部分拥有一个公司比相对高的工资更感兴趣，因此就有了高科技公司员工的期权制度。</li></ul><h2 id="奔腾的芯：英特尔－Intel"><a href="#奔腾的芯：英特尔－Intel" class="headerlink" title="奔腾的芯：英特尔－Intel"></a>奔腾的芯：英特尔－Intel</h2><ul><li>1981 年，IBM 为了短平快地搞出 PC，也懒得自己设计处理器，拿来英特尔的 8086 就直接用上了。这一下子，英特尔一举成名。</li><li>美国历史频道（History Channel）在节目中评论了中日甲午战争。美国的历史学家认为，这是两个不同时代军队之间的战争，虽然双方武器相差不多，战争的结果不会有任何悬念，因为一个在专制的农业时代后期的军队很难打赢一个兴起的工业化国家的军队。英特尔和摩托罗拉之间的竞争也是如此。</li><li>市场的倾向说明了用户对兼容性的要求比性能更重要。因此，英特尔在精简指令上推出 80960 后，就停止了这方面的工作，而专心做”技术落后”的复杂指令系列。在整个九十年代，工业界只有英特尔一家坚持开发复杂指令集的处理器，对抗着整个处理器工业。</li><li>总的来讲，英特尔并没有想彻底把 AMD 打死。因为留着 AMD 对它利大于弊。首先，它避免了反垄断的很多麻烦。</li><li>个人认为，在个人微机以外，今后最重要的市场是游戏机市场。现在的游戏机早已不单单是为玩游戏设计的了，它们成为每个家庭的娱乐中心。IBM 等公司至少在目前在这个领域是领先的。IBM 已经垄断了任天堂、Sony 和微软三大游戏机的处理器市场。</li><li>英特尔对世界最大的贡献在于，它证明了处理器公司可以独立于计算机整机公司而存在。在英特尔以前，所有计算机公司都必须自己设计处理器，这使得计算机成本很高，而且无法普及。</li></ul><h2 id="IT业的罗马帝国：微软－Microsoft"><a href="#IT业的罗马帝国：微软－Microsoft" class="headerlink" title="IT业的罗马帝国：微软－Microsoft"></a>IT业的罗马帝国：微软－Microsoft</h2><ul><li>我在学校的老板贾里尼克院士以前在IBM当任要职，因此我们经常去IBM作报告，每次去以前贾里尼克都要确认我们报告的每一页内容是已经公开发表过的。原因很简单，IBM有世界上最好的科学家和工程师，他们可以用比你还快的速度将你没有发表的想法实现、申请专利并发表。</li><li>在这次双雄会上，乔布斯犯下的错误有两方面，首先，他自己没有意识到操作系统在今后整个微机工业中的重要性，否则他不会过早地给别人看他还没上市的设计；第二，也是更重要的，他给谁看都可以，就是不该给盖茨这个人看。</li><li>完成了在研发上的布局，盖茨要在市场上尽可能用它落后的DOS坚持到微软新一代操作系统开发出来。微软的做法概括起来是两句话，薄利多销和来者不拒。</li><li>但是，领先下的苹果犯了一个致命的错误—走封闭式道路和纯技术路线。当IBM因为反垄断的限制，不得不容忍兼容机厂家克隆自己的产品并抢走越来越多市场时，苹果正在为自己没有遇到同样的麻烦而高兴。</li><li>苹果既做硬件又做软件，很难平衡两者的速度。软件做得太快了硬件就跟不上，硬件做的太快了有没有合适的软件可用。在历史上，苹果有几款计算机一推出来时速度就已经落后了；还有几款比如早期PowerPC推出来时速度奇快但没有什么应用软件可用。</li><li>网景选择了和微软一拼，因为它觉得至少目前它还有技术和市场上的优势。后来证明这种技术上的优势根本不可靠，这也是我将技术排在形成垄断的三个条件之外的原因。</li><li>如果说乔布斯是锋芒毕露，聪明写在脸上；盖茨就是一个平衡木冠军，聪明藏在肚子里。</li><li>微软打败网景和Real Network等公司的绝招是免费提供和对手竞争的产品。但是这一招对雅虎不灵，因为雅虎的服务本身就是免费的。</li><li>公司增发期权不计入成本。因此，雅虎不断地增发期权给员工，而只需付给员工很少的现金工资。员工手中的股票期权，在华尔街的炒作下，以火箭速度往上涨</li><li>我非常喜欢黑格尔地一句话：凡是现实的都是合理的，凡是合理的都是现实的。(All that is real is rational; and all that is rational is real.)虽然这句话常常被误解成为当今不合理的现实来开脱，其实，如果我们动态地看待现实性和合理性，可以把这句话理解成，现在存在的现象，当初产生它的时候必然有产生它的原因和理由。如果这个理由将来不存在了，终究有一天它也会消亡。</li><li>进入新的世纪以来，微软的行动明显放慢，它的扩张一再受阻。但是，个人微机的这次浪潮还没有过去，处在其浪潮之巅的微软即使不做任何事，仍然是世界上最赚钱的公司。它始终是所有公司最可怕的竞争对手。它能否成功地第二次创业，很大程度上取决于客厅信息化是否能形成下一次技术革命的浪潮，而它又是否能在客厅争夺战中最终胜出。</li></ul><h2 id="互联网的金门大桥：思科"><a href="#互联网的金门大桥：思科" class="headerlink" title="互联网的金门大桥：思科"></a>互联网的金门大桥：思科</h2><ul><li>一个成功的公司的早期员工是非常宝贵的财富。他们一般是一些非常爱冒险的人，否则他们不会选择加入新开办的甚至是还没有投资的小公司，他们技术和能力非常强，常常每个人可以独挡一面，因为早期的公司要求员工什么都得能干。</li><li>但是，他们也有他们的弱点。他们虽然善于开创，但不善于或者不愿意守成，而后者对于一个大公司发展至关重要。他们做事快，但是不够精细，因为在公司很小时，抢时间比什么都重要。</li><li>如何留住早期员工，并且调动他们的积极性，便成为了每一个上市的科技公司的难题。</li><li>华为公司比思科成立晚四年，早于 Juniper 八年。华为创办时起点就很高，当时邮电部下面的一些研究所还在和 ATT 等跨国公司谈二流技术的转让和合作，任正非直接就定位当时国际上最先进的技术，并且短短几年就开发出了当时具有国际先进水平的 08 程控交换机。</li><li>一旦一项产品可以由中国制造，那么它的利润空间就会薄到让美欧公司退出市场。现在，思科和华为的竞争就是在这种阴影笼罩下。</li></ul><h2 id="英名不朽：杨致远、菲洛和雅虎公司"><a href="#英名不朽：杨致远、菲洛和雅虎公司" class="headerlink" title="英名不朽：杨致远、菲洛和雅虎公司"></a>英名不朽：杨致远、菲洛和雅虎公司</h2><ul><li>雅虎及其追随者们，不仅把互联网办成了开放、免费和盈利的，而且刺激了电子商务的诞生。</li><li>但是大多数创业者连产值都不考虑，觉得只有有了流量就有了一切，今天仍然有人持这种观点。</li><li>雅虎对网络泡沫的形成起到了推波助澜的作用。虽然它自己没有直接烧投资者的钱，但是无数小网络公司都是靠烧钱在维持，这如同抱薪救火，薪不尽火不灭。</li><li>到2000年大选后，终于没有新的投入进来了，互联网泡沫应声而灭。</li><li>一个技术公司，无论是过去的ATT，还是现在的Google，都会尽可能地采用技术而不是人工来解决问题，当然所有的技术都有自己的局限性和不足，一个崇尚技术的公司的态度是解决这些问题而不是倒退到手工操作。至今，雅虎仍然会手工地调整搜索结果，和Google完全用计算机排名不同。</li></ul><h2 id="硅谷的见证人：惠普公司"><a href="#硅谷的见证人：惠普公司" class="headerlink" title="硅谷的见证人：惠普公司"></a>硅谷的见证人：惠普公司</h2><ul><li>虽然惠普从来没有领导过哪次技术革命的浪潮，但是作为硅谷最早的公司，惠普见证了硅谷发展的全过程，从无到有，从硬件到软件，惠普的历史从某种程度上讲就是硅谷历史的缩影。</li><li>这种现象在投资大师巴菲特看来是很荒唐的，安捷伦疯涨，说明惠普卖赔了，惠普应该跌才是。</li><li>惠普的墨盒和吉列的刀片有个很大的区别。刮胡子刀片是一分价钱一分货，吉列的刀片比廉价低质量的确实好不少，而且刮胡子刀片是一种特殊的商品，对它的马虎不得，用一个劣质刀片刮破脸可不是件好玩的事。</li><li>如果一个公司不能挑选好掌舵人，以后替换掉他成本也是很高的。</li></ul><h2 id="没落的贵族：摩托罗拉"><a href="#没落的贵族：摩托罗拉" class="headerlink" title="没落的贵族：摩托罗拉"></a>没落的贵族：摩托罗拉</h2><ul><li>过分注重技术和品质使得摩托罗拉在商业上的灵活性远不如诺基亚和三星等竞争对手。</li><li>摩托罗拉对世界最大的贡献是它在八十年代初发明的民用蜂窝式移动电话，也就是早期说的大哥大，现在说的手机。</li><li>美国在标准之争上的失败间接影响的摩托罗拉手机今后的竞争力。</li><li>摩托罗拉长期以来都是一个了不起的技术公司，它长于技术，但是过分相信技术的作用。铱星计划在技术上是无与伦比的，但是，过于超前市场的技术不仅导致成本过高，而且维护费用也是巨大的。</li><li>摩托罗拉试图打造一个通用的操作系统作为它今后手机开发的统一的平台。这个想法本来不错，但是摩托罗拉选错了平台，选中了 Java 。</li></ul><h2 id="硅谷的另一面"><a href="#硅谷的另一面" class="headerlink" title="硅谷的另一面"></a>硅谷的另一面</h2><ul><li>坦率地讲，我对这些沉溺于创业梦想的人泼凉水的时候多于鼓励的时候。虽然我知道他们更需要鼓励，但是在硅谷这个环境中，他们已经得到了无数的鼓励。</li><li>创业者还必须精力过人，因为他们必须能熬得住几年每天在简陋的车库里工作 16-20 小时的苦日子。他们又必须是多面手，因为在创业初期他们必须干所有的脏活。</li><li>但是光有好的团体和技术又远远不够，他们有商业头脑而且必须找到一个能盈利的商业模型（Business Model）</li><li>硅谷几十年经验证明，那些初出茅庐能干具体事情的年轻人，可能比一个经验丰富但是已经眼高手低的权威对公司更有用。</li><li>由于 FDA 的保护，创业的小公司要打破原有制药公司的垄断是件很难的是。这就是我们很难看到小的生物公司成功的原因。</li></ul><h2 id="短暂的春秋：与机会失之交臂的公司"><a href="#短暂的春秋：与机会失之交臂的公司" class="headerlink" title="短暂的春秋：与机会失之交臂的公司"></a>短暂的春秋：与机会失之交臂的公司</h2><ul><li>太阳和微软之争，其实就是企业级的操作系统之争。对太阳来讲，取胜的关键在于是否能将它在 Unix 上的技术优势转换为市场优势。</li><li>太阳公司当时不自觉地满足于捏 SGI、DEC 和 HP 这些软柿子、并沉溺于在硬件市场上的胜利，忽视了来自微软的威胁。但当 2000 年互联网泡沫破碎时，它以服务器和工作站为主的硬件业务便急转直下。</li><li>施密特当时是太阳公司主管软件的副总裁，他从太阳失败的教训中总结出了反摩尔定理，我们已经介绍过。施密特认识到依靠硬件的利润是不断下降的，而 IT 服务业的利润则是恒定的（并随着通货膨胀而略有增加）。</li><li>当大量杰出人才离开、同时公司业绩大幅下滑时，马可尼里没有果断地大量裁员。他总给自己一个借口，我们好不容易招到这么多人（在网络泡沫时代，找工程师是很难的），如果现在裁掉冗员，万一市场好起来，我从哪里去招人。</li><li>这正应了茨威格的话，在命运降临的伟大瞬间，市民的一切美德——小心、顺从、勤勉、谨慎，都无济于事，它始终只要求天才人物，并且将他造就成不朽的形象。命运鄙视地把畏首畏尾的人拒之门外。命运——这世上的另一位神，只愿意用热烈的双臂把勇敢者高高举起，送上英雄们的天堂。</li><li>网景选择了和微软一拼，因为它觉得至少目前它还有技术和市场上的优势。后来证明这种技术上的优势根本不可靠，这也是我将技术排在形成垄断的三个条件之外的原因。在微软方面，它也正式向网景公司宣战。</li><li>网景公司在它的浏览器畅销到网络用户时，没有居安思危，它没有注意去控制互联网的内容，这样一来它失去了保护自己和反击微软的可能性。本来它最有可能成为雅虎。</li><li>即使最初网景看不到索引和组织互联网内容的重要性，但是到 1994 年底，当雅虎的流量首次达到一百万次访问时，网景也应该意识到这一点了。如果那时候网景公司走门户网站（Portal）之路，没有人能阻挡它成为后来的雅虎。</li></ul><h2 id="幕后的英雄：风险投资"><a href="#幕后的英雄：风险投资" class="headerlink" title="幕后的英雄：风险投资"></a>幕后的英雄：风险投资</h2><ul><li>高回报的投资一定伴随着高风险，但反过来高风险常常并不能带来高回报。任何一种长期赚大钱的金融投资必须有它内在的动力做保证。风险投资也是一样，它内在的推动力就是科技的不断发展进步。</li><li>风险投资的关键是能够准确评估一项技术，并预见未来科技的发展趋势。</li><li>我通常把科技进步和新的商业模式分成进化（Evolution）和革命（Revolution）两种，虽然它们的英文单词只差一个字母，意义可差远了。创业必须要有革命性的技术或者革命性的商业模式。</li><li>风投公司介入一个新兴公司后的第一个角色就是做顾问。这个顾问不仅需要在大方向比如商业上给予建议，而且还要在很多小的方面帮助创始人少走弯路。</li><li>一个风投公司要想成功，光有钱，有眼光还很不够，还要储备许多能代表自己出去管理公司的人才。这也是著名风险投资公司比小投资公司容易成功的原因之一，前者手中攥着更多更好的管理人才。</li><li>越是成功的风投公司，投资成功上市的越多，它们以后投资的公司相对越容易上市、再不济也容易被收购。因此，大多数想去小公司发财的人，选择公司很重要的一个原则就是看它幕后的风投公司的知名度。</li></ul><h2 id="信息产业的规律性"><a href="#信息产业的规律性" class="headerlink" title="信息产业的规律性"></a>信息产业的规律性</h2><ul><li>当某个领域发展成熟后（而不是群雄争霸时期），一般在全球容不下三个以上的主要竞争者。虽然每个领域的领头羊占得市场份额不尽相同，但是通常都是比其他所有公司的总和还多。</li><li>当市场上一旦诞生了一个新的猴王，它就成为了这个市场规则的制定者和解释者，这时，市场就不可逆转地向着有利于这个主导者的方向发展。其它公司即使在技术上、管理上或者其它方面有一点优势，都不足以抵消主导者在规则制定和解释方面的优势。靠着制定和解释规则，在很短的时间里这个王者就占了这个领域在全世界的大部分市场。</li><li>在通信领域，规则比技术更有利于一个公司占领市场。</li><li>为什么在信息产业的公司比传统工业的容易形成主导优势呢？这里面有两个关键的原因。首先是不同的成本在这两种工业中占得比例相差太大。传统行业研发成本低，但各种制造成本和销售成本是非常高的。研发成本可以通过规模经济来抵消，而制造成本则不能。</li><li>科技领域则大不相同，制造的成本只占营业额的很小一部分而研发成本占大多数。对微软和甲骨文来讲，制造一份软件拷贝的成本和一百万份没有什么区别。</li><li>虽然生物制药公司和信息科技公司一样有着低制造成本的特点，但是世界上没有一种万灵药能治所有的病，甚至对于同一种病也不存在一种药能医治所有的人，因此就有很多大的生物制药公司并存。它们每个公司专门研制针对不同疾病的药物。因此前面所讲的主导性的公司在生物制药领域并不存在。</li><li>一个主导者愿意强调自己是行业的领导者，这样可以给投资者和用户信心，但是永远会否认自己有垄断地位，以免给自己找麻烦。它们在提交到证监会和其它政府部门的官方文件中甚至会列举一些小的不能再小的竞争对手，表示自己在公平竞争。</li><li>诺威格定理：当一个公司的市场占有率超过 50% 后，就无法再使市场占有率翻番了。这几乎是任何人都懂的大白话，但是却道出了许多跨国公司兴衰的根源。</li><li>当它占领了大部分市场时，它的成长就受制于整个行业的发展了。而华尔街依然期望着这个新兴公司不断创造奇迹。这时候，该公司就必须寻找新的成长点，才能不断超越华尔街的预期，公司就不得不天天为营收忙碌</li><li>通用汽车失败的根源在它根深蒂固的思维方式：它一直认定自己是个汽车公司，一定就要以汽车公司为主。这好比在围棋盘上，通用汽车有一条经营了很长时间却已经没有气的大龙，和一片布局完美可扩展空间大的实空，通用汽车总是舍不得牺牲掉自己经营多年的大龙而错误地放弃前景看好的实空，最后满盘皆输。</li><li>严格地讲，苹果其实不能算是一个计算机公司，而是一个注重创新的消费电子公司。在苹果眼中，计算机不过是新的电子产品的一种，当然苹果要把它做得越新、越酷越好。</li><li>红杉风投认为一个公司的基因在创办的一个月内就定型了，这也许有些夸张，但是一个成型的公司改变基因的可能却是非常小。越是以前成功的公司越是容易相信自己固有的基因是最优秀的。</li></ul><h2 id="高科技公司的摇篮：斯坦福大学"><a href="#高科技公司的摇篮：斯坦福大学" class="headerlink" title="高科技公司的摇篮：斯坦福大学"></a>高科技公司的摇篮：斯坦福大学</h2><ul><li>从斯坦福夫人身上我们看到一位真正慈善家的美德。慈善不是在富有以后拿出自己的闲钱来沽名钓誉，更不是以此来为自己做软广告，慈善是在自己哪怕也很困难的时候都在帮助社会的一种善行。</li><li>一旦某个项目有了商业价值，并且可以由公司资助时，政府会渐渐减少并且最终停止对这些课题的资助，因为政府（纳税人的代表）认为没有必要和工业界做重复的事，更没有必要和工业界竞争。在这一点上，美国政府和中国政府与日本政府有很大的不同。</li><li>只要一个教授能完成教学任务，并且发表足够多像样的论文，斯坦福并不限制它的教授到外面的公司兼职，甚至在一段时间里全时离开学校创办公司或者在公司里担任要职。</li><li>可以想象如果佩奇和布林不是斯坦福的研究生而是什么其它学校的，他们很难有机会直接向一位工业界领袖推销自己的发明。大家可以试想一下，在中国，一位普通的清华大学或者北京大学的研究生有没有可能通过学校直接见到华为的创始人任正非，斯坦福能做到这件事是它了不起的地方。</li></ul><h2 id="科技公司的吹鼓手：投资银行"><a href="#科技公司的吹鼓手：投资银行" class="headerlink" title="科技公司的吹鼓手：投资银行"></a>科技公司的吹鼓手：投资银行</h2><ul><li>罗斯柴尔德家族十九世纪中后叶达到高峰，但是犯了几次致命的错误，又遇到几次灭顶之灾，便从此一蹶不振的。该家族犯的第一个错误就是低估了美国的发展。十九世纪后半叶，美国因为种族矛盾尖锐，后来又爆发了内战，罗斯柴尔德家族对美国不看好，撤走了在美国的大部分业务，失去了追随美国发展的大好时机。（我常常和别人讲，错过现在中国发展的快车，就像一百五十年前错过美国发展一样可惜。）</li><li>由于美国银行业的基础是私有银行，抵抗金融危机的能力就很有限，在 1907 年的金融危机中，美国的银行业几乎崩溃。这时，由著名银行家摩根发起，联合了各大银行，在总统威尔逊的支持下，美国建立了联邦储备银行系统（Federal Reserve System），简称美联储。</li><li>投资公司，虽然他们又称投资银行（Investment Bank），但是直到 2008 年 10 月，它们都不是真正意义上的银行，因为他们既不能接受存款，也不能向联邦储备银行借钱，它们是替别人买卖有价证券、期货、不动产和任何有价值的商品。</li><li>有人觉得雷曼和美林只要再坚持五天就可以逃过一劫，其实，只要它们两家公司一天不死，这个计划就不会从保尔森的口袋里拿出来。</li><li>摩根斯坦利是银行业中计算机化的先驱。早在 1962 年，它就通过计算机来分析股市并且建立了很多用于金融的数学模型（Quantitative Financial Analysis Model），并且获得了很大的成功。由于摩根斯坦利在金融界的影响力，其它金融公司也纷纷效仿，从此开创了一种用数学模型分析市场的新领域。这对八十年代后对冲基金的兴起起了先导作用。</li><li>和百度相反，中石油在香港的上市堪称败笔。首先它作为全球最大的融资行动，却选择了一家二流的承包商瑞士联合银行和不入流的中信。这两家承包商为中石油作出了天价的融资股价，以至于长期持有它的巴菲特马上套现。</li><li>融资过多和过少都是有危害的。过度的融资不仅导致原有股东的利益被压缩，而且由于在短时间里流入市场的股票太多，股价很难稳定。融资过少的危害也很明显，很多公司就是因为融资不足而在经济进入低谷时无资金摆脱困境而关门。</li><li>对于那些价值不大的科技公司，一旦它们未能达到预期，华尔街则会毫不留情的打压到底，以起到杀鸡示猴的作用。</li><li>要想不受华尔街的影响，唯一的办法就是不上市。这就是 Google 在盈利很久以后迟迟不肯上市的原因</li><li>金融业在整个经济活动中起着血液的作用。健康的金融环境和秩序可以帮助科技公司的成长。但是由于金融业和巨大的利益联系在一起，因此贪婪、投机甚至非法的欺骗行为是金融业永远也摆脱不了的阴影。</li></ul><h2 id="挑战者：Google-公司"><a href="#挑战者：Google-公司" class="headerlink" title="挑战者：Google 公司"></a>挑战者：Google 公司</h2><ul><li>我们问佩奇是如何想到Page Rank算法的。他说”当时我们觉得整个互联网就像一张大的图( Graph ) ,每个网站就像一个节点，而每个网页的链接就像一个弧。我想，互联网可以用一个图或矩阵描述， 我也许可以用这个发现做个博士论文。</li><li>虽然今天的Google 和其他搜索引擎相比当初的Google 已有了长足的进步，但是这种进步基本上属于量变。搜索引擎领域迄今为止的质变只有 Google 取代AltaVista 那一次。</li><li>佩奇知道，只有把互联网的内容送到千家万户就行了，至于互联网的内容是谁的并不重要。</li><li>巴菲特有一个最简单有效的选择股票的办法，就是到大小百货店、加油站和食品店看一看老百姓都在买什么，这比听华尔街分析师瞎掰乎要准确得多。巴菲特因此而选择了可口可乐、宝洁、强生、百威啤酒、沃尔玛和卡夫食品等公司技资，都获得了极高的回报。在巴菲特看来，广大消费者才是一切商业的衣食父母。佩奇和布林也深深体会到，广大最终的用户(网民和广告商)才是为Google 带来生意的人，因此， Google 的产品一直是针对广大用户，既非像IBM 那样针对企业，又非像苹果那样针对精英。</li><li>Google 在早期并没有刻意追求营业额和利润，而是想方设法扩大自己的用户群。除了在技术上要比对手做得好以外，还将自己的网页做得特别干净，这样在到处是铺天盖地的横幅广告和弹出式广告的互联网上，显得非常超凡脱俗，便吸引了很多用户。</li><li>由于Google 很明智地没有在互联网泡沫高峰期疯狂地扩展，而是实实在在地、低调地做好自己的搜索引擎，因此它早期烧钱的速度非常之慢。2000 年的时候它没有急着上市，避免了绝大多数互联网公司大起大落并且最终关门的厄运，同时最早期的优秀人才没有拿了钱就走掉，因此Google 的骨干完好无损。</li><li>他解释 Google 的人才战略时说，好的博士生不仅有创造力，而且有最高的自觉性。硕士生同样的聪明，但是主动性要差一些。硕士能把你领到别人到过的地方，而博士可以把你带到以前无人去过的地方。</li><li>Google 是一家思维方式与众不同的公司，它认为，杀鸡一定要用牛刀。一个本科生能完成的事，如果我能找到一个硕士生来做，那么一定比同类公司做得好! 在Google 里面实际上是贯彻一种”瑞士制造”的指导思想， Google 自己把它称为”Google 的品质” 。</li><li>随着自由派总统奥巴马的当选和任职，美国和中国的蜜月期终于过去了。自由派人士占主导的Google总部对中国的互联网管制方式一直难于接受，这中间的矛盾全压在李开复身上。终于有一天，他不堪重负，选择了离开。缺少了李开复这个润滑剂， Google 和中国的关系变得很难调和，最终导致了2010 年初Google 退出中国的事件。</li></ul><h2 id="成功的转基因：诺基亚、3M、GE"><a href="#成功的转基因：诺基亚、3M、GE" class="headerlink" title="成功的转基因：诺基亚、3M、GE"></a>成功的转基因：诺基亚、3M、GE</h2><ul><li>芬兰政府给诺基亚的支持是在人才上的支持。芬兰在欧洲近乎于一个社会主义国家，它为民众提供从小学到大学全部的免费教育。这就为诺基亚提供了人才保障。同时，作为一个小国，芬兰政府知道它不可能在世界经济的方方面面都领先，因此全国只专注几个产业，当然，移动通信是一个。而在芬兰的大学和研究所里，也就很少看到跟它产业结构不太相关的专业。</li><li>到了数字手机时代，不同手机的话音质量相差不像以前那么大，这时手机的功能就变得非常重要了，再到后来手机的外观都变得重要起来。</li><li>诺基亚由一个地区性的木工厂发展到全球最大的手机厂商，原因可以简单概括为长期探索、抓住机遇和制定规则几个字。</li><li>3M 允许员工用 15% 的时间干任何自己喜欢做的事，后来这个做法被 Google 学去了，变成了 Google 的百分之二十项目。</li><li>3M 公司在适当的时候强制淘汰一些看似还在挣钱但是前景不是很好的产品。</li><li>因为企业级的产品和服务受经济大环境的影响太大，收入相对不如消费者产品来得稳定。</li><li>了解 GE 公司历史的人都知道这个充满传奇色彩的公司是由著名发明家爱迪生创立的，是将电最早介绍和普及到世界上的公司。</li><li>3M 是靠硬性的制度维持其创新，而 GE 是靠自己不断开创新的产业。</li></ul><h2 id="印钞机：最佳的商业模式"><a href="#印钞机：最佳的商业模式" class="headerlink" title="印钞机：最佳的商业模式"></a>印钞机：最佳的商业模式</h2><ul><li>所有成功的大公司都有好的商业模式，很多大公司的兴起，不是靠技术的革新而是商业模式的转变。</li><li>在这台印钞机中，自动化程度必须到达一个阈值，它才能自动运转起来。而当它的自动化越高，成本就越低。</li><li>长城公司自己开发微机全部软硬件，自己在广东建厂，自己采购元器件，有自己的仓储，最后还发展了一大批批发和零售代理商。大家不难看到，长城公司处处走的是和戴尔公司相反的路线。当长城计算机公司很自豪地拥有了这一切时候，它的资金利用率已经比戴尔低了很多，而它的产品的价格却高了很多。</li></ul><h2 id="互联网-2-0"><a href="#互联网-2-0" class="headerlink" title="互联网 2.0"></a>互联网 2.0</h2><ul><li>到2000年世界上流量最大的网站全部是门户网站，在美国是雅虎、MSN 和Excite 等在中国则是新浪、搜狐和网易三大门户网站。</li><li>互联网2.0的公司不应该过多主导内容和服务，不应该参与和用户的竞争。以YouTube 为例，它host 的内容是用户（包括个人和专业的传媒公司）提供，它自己并不制作和拥有内容， 与其他提供内容的用户竞争。</li><li>互联网2.0公司的一个普遍特点就是专注于打造通用的平台，而由社会上的开发力量和广大用户补充成完整的服务，从Wikipedia 到Facebook 都是如此，它们相当于软件时代的甲骨文和微软。</li></ul><h2 id="金融风暴的冲击"><a href="#金融风暴的冲击" class="headerlink" title="金融风暴的冲击"></a>金融风暴的冲击</h2><ul><li>科技像是我们这个社会的大脑，而金融则是血液。没有了科技，这个社会就会是混混沌沌的，就像中世纪的欧洲；而没有了金融，这个社会就停止了运转。</li><li>金融危机的直接和表层的原因是次贷（Subprime Loan） 及与之相关的金融衍生物CDS ，而间接和深层的原因则是违反经济规律地只消费不创造，从而坐吃山空。</li><li>当人们为格林斯潘神奇的控制经济的能力叹服时， 实际上他是用一个更大的房市泡沫解决了相对小得多的互联网泡沫的问题。</li><li>金融危机首先将淘汰掉这些无法适应新环境的恐龙级的公司，因为这些长期部借新的贷款来偿还旧的贷款利息过活的跨国公司，现在已无法贷到新款，或者贷款的成本太高。</li><li>大量不健康的公司会使得整个社会的投资效率低下， 经济生活变得死气沉沉。这些公司的消失，为健康的公司腾出了宝贵的市场，健康而有活力的公司将成为未来直接的收益者。</li><li>金融危机使得以前一些不可能的兼并成为可能，并因此打造出一些竞争力更强的大型公司。</li><li>经济危机时，风险投资家们不得不主动收缩战线，弃卒保车。它们通常的做法是迅速关闭成活可能性小的公司，把资金集中投入给可以生存下去的公司中，保住一些重点投资。对于那些运营不错的公司，反而可能得到比宏观经济好的时期更多的资金，虽然它们日子也颇为艰难，却无疑是遇到了一个非常好的发展机会。</li><li>我的建议是，不求大的发展，但求生存。必须要保证12到18个月后还有资金，还活着。现在看来，能坚持一到两年的小公司，发展得都比金融危机前要好。</li><li>这些公司因为没有利润，甚至没有营业额，根本无法按照传统的市盈率（ P／E ） 比来估价，于是他们伙同华尔街发明了用股价／ 流量比来对这些网络垃圾估价。</li></ul><h2 id="云计算"><a href="#云计算" class="headerlink" title="云计算"></a>云计算</h2><ul><li>在甲骨文的Network Computer 失败后， 第一次互联网的泡沫也破灭了，大家对互联网的作用也产生了怀疑，一切基于客户端的想法又占了上风，因此很长时间这种基于Web 应用的概念没有人提了。</li><li>亚马逊发现，它不仅仅可以为商家提供网站托管服务，还可以为任何需要建立网站的公司提供。这样，任何一个想通过互联网提供服务（包括电子商务） 的公司和个人都不需要自己建网站，而只要租用亚马逊的计算资源即可。这就是亚马逊理解的云计算，它和IBM 的理解完全不同，但是没有矛盾。</li><li>云计算本身是一个非常复杂的系统工程。它的普及首先离不开巨型数据中心的建设和全球高速光纤主干网的铺设，这就好比电的普及离不开发电厂和输电网一样。在Google，这些工程称为全球基础架构，它本身也需要很多关键技术，甚至一些看上去IT无关的技术，比如制冷技术。全球基础架构设计和实施的好坏可能会导致运营成本上成倍的差别。</li><li>云计算要想得到充分的发展和全世界计算机产业的认可，不是单凭任何一家公司的力量就能做到的.</li></ul><h2 id="下一个Google"><a href="#下一个Google" class="headerlink" title="下一个Google"></a>下一个Google</h2><ul><li>很多公司靠炒作概念，而利润平平，在一段时间里，股价炒得很高，他们依靠发行新股获得了充足资金，然后盲目扩大业务。虽然风光一时，但光环迅速消失。</li><li>即使今天出现了一个比微软Windows 好一倍的操作系统，用户也没有要换操作系统的欲望，因为微软的够用了 。够用了这条很消极而枯燥的原则，让所有想通过做一个操作系统取代微软的努力都变得无效。</li><li>云计算不仅是今后最有希望的产业， 而且是上面很多产业，比如3G 移动通信的支柱。</li><li>可以毫不夸张地讲，阿里巴巴已经完全占领中同电子市场的制高点，而且只要它不犯大的错误，现在找不出一家公司可以挑战它的商业地位。</li><li>马云自己都认为是阿里巴巴开创了中同的电子商务市场。从效果上看这一点并不错，但是有些因果倒置。事实上是，中同非常糟糕的批发和零售商业环境，要求必须出现一家阿里巴巴这样让商业变得容易的公司。</li><li>腾讯的做法和Google 非常类似，通过一款产品抓住终端用户，然后通过一些服务从每一个用户身上挣钱。</li><li>美国取代英国成为世界第一强国的时候，依靠的不是任何资本泡沫，而是爱迪生和西屋（发明电和交流供电）、贝尔（发明电话）、福特（发明汽车）、怀特兄弟（发明飞机）等这样一大批在世界文明史上占有重要位置的发明家，以及洛克菲勒（石油）、卡内基（钢铁）、杜邦（ 化工）等搞实业的工业巨子。</li><li>当人们不再把房市、股市作为最快的挣钱手段时，就是中国可以诞生下一个Google 的时候了。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;一本介绍大型科技公司浪潮起落的书。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Note" scheme="https://blog.superui.cc/categories/reading-note/"/>
    
    
    <category term="读书" scheme="https://blog.superui.cc/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>富可敌国</title>
    <link href="https://blog.superui.cc/reading-note/more-money-than-god/"/>
    <id>https://blog.superui.cc/reading-note/more-money-than-god/</id>
    <published>2022-05-15T09:00:00.000Z</published>
    <updated>2022-05-15T09:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>一本介绍对冲基金发展的书。</p><span id="more"></span><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>塞巴斯蒂安-马拉比，保罗•沃尔克时期对外关系委员会国际经济高级研究员，《华盛顿邮报》的专栏作家。他在《经济学人》杂志工作了13年，在《华盛顿邮报》编委会工作了8年，主要专注于经济全球化和政治经济领域。</p><h2 id="极简简介"><a href="#极简简介" class="headerlink" title="极简简介"></a>极简简介</h2><p>一本权威的对冲基金发展史。本书作者对该行业进行了包括300个小时访谈和无数内部文件在内的深入调查，并在此基础上，讲述了关于对冲基金鲜为人知的故事。</p><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>首先作为一本纪实介绍类的书，人名太多了，对于不明所以的人来说有点难以阅读。但是讲述较为生动全面，个人认为还是比较有启发。当然全书的立意还是针对于对冲基金，说实话离大部分人都很遥远，当成故事书来说更为合适。作为一本故事书，其中的很多成功和失败案例能为自己的投资提到警示作用。</p><h3 id="感想看法"><a href="#感想看法" class="headerlink" title="感想看法"></a>感想看法</h3><ol><li>人名儿太多了，难以阅读。</li><li>量子基金做空英镑的故事的确有趣，不像是那些鸡汤文或者财经文里面介绍的那么浅显，本书将前因后果和细节交代的十分到位。给我的感想就是，了解宏观经济十分重要，了解政治也十分重要。这并不只是一场经济游戏，里面也暗含了很多政客的小心思。各种基金一起做空英镑的场景让我联想到了翟老师讲的华尔街做空雷亚尔的故事，书中也写到“亚洲和拉丁美洲的新兴经济体卡在了盯住汇率政策上，这在未来十年给对冲基金创造了巨大的机会”。</li><li>很多无风险套利的机会是要通过大规模资金才能实现。比如影子银行，借入短期资金，贷出长期资金，例如最开始的支付宝。（原来支付宝之前玩的都是美国90年代玩剩下的）。</li><li>一方面，对冲基金可能会加快金融市场的传导机制（例如长短期利率），另一方面，对冲基金可能也被政府纳入了政策制定的考虑当中。</li><li>虽然都叫对冲基金，很多是很不一样的。当然也有很多名称不一样，但做的事情本质是一样的。</li><li>原来索罗斯在做空泰铢的8亿美元收益在做多印尼盾中几乎赔了进去，interesting。</li><li>机构投资者的高仓位可能暗示着强烈的抛压，而不是暗示着还将继续上涨。记住，继续买入才会引发上涨。</li><li>其实自己在买基金和股票的时候要考虑一下流动性风险，不是自己的流动性，而是机构的流动性，他们有没有对手盘来操作。</li><li>再次重复，人名儿太多了，难以阅读，有一种看外国小说的感觉。</li><li>你可以对冲价格风险，但是你无法对冲流动性风险。</li><li>其实不认为小到可以随便倒闭就是对冲基金适合去吸收风险的理由。因为可能多个基金加总，体量也会变大，这样总风险也会变大。</li><li>”这就意味着资本价格对于脚踏实地的公司来说过高，而对于华而不实的公司来说过低。成长的概念被滥用“不敢更赞同。</li><li>过早的正确就等于错误，择时！</li><li>流动性真的太重要了，参见近期的房地产，和一些远离成交价的期权。</li></ol><h1 id="内容摘录"><a href="#内容摘录" class="headerlink" title="内容摘录"></a>内容摘录</h1><ul><li>有时CAPM模型不能解释市场异象，就是单纯考虑市场风险因素是有欠缺的。于是三因素，四因素，多因素模型提出，异象不复存在。</li><li>一方面有人认为有效市场的均衡状态永远不可能出现。另一方面，有人认为有效市场是一直存在的，只是没有找到正确的衡量风险的方法。</li><li>短期来看，市场中存在着大量的无效情况，这些无效情况可以提供无风险的套利机会。</li><li>货币会波动，利率会波动，越来越多的公司会发发行股票和债券。债务会被证券化。弄清楚什么样的金融机构能最吸收这些类型的风险将变得至关重要。这本书提供的答案是对冲基金会最好的完成这个任务。因为他们优越的激励机制，因为它们小到可以随意倒闭。因为他们可以比任何对手都更负责任的管理风险。</li><li>对冲基金并没有精确的定义，也不是所有的故事都和套期保值和杠杆效应有关。</li><li>天才并不是时刻都知道自己在干什么。</li><li>那些看上去不怎么样的价值型股票，相对于吹得天花乱坠的成长型股票来说，价值被低估。这就意味着资本价格对于脚踏实地的公司来说过高，而对于华而不实的公司来说过低。成长的概念被滥用。</li><li>他们时而被当作尽力是无效价格回归正常的稳定器而加以赞扬，时而又因其自身的不稳定性被视为威胁全球经济的因素而加以批判。</li><li>问题在于杠杆交易。杠杆效应使大额交易成为可能，因此使价格更有效，更稳定。但是杠杆效应也使得对冲基金在面对冲击时更加脆弱。</li><li>到底谁能比较好的管理风险，是那些我破产，要么靠政府埋单的商业银行和投资银行。还是一位兜售货币市场产品迫使政府支持的共同基金公司。是风险集中，使得纳税人也深陷其中的大银行，还是风险分散到从不指望政府救援的小规模对冲基金。</li><li>如果投资者是风险厌恶型，它就应该买最好的股票，但只用它继续的一部分。如果投资者是风险偏爱型，他应该购买完全一样的股票，并借钱了，卖更多。</li><li>所有新的市场首先都是低效的。这种效率，对最早顺应市场的人来说，则意味着利润。</li><li>当一种商品价格突破其一贯的价格区间，压错赌注的投资者就会出现大幅亏损，因为恐慌，他们将匆匆平仓使价格更加远离之前的价格区间。</li><li>索罗斯认识到了均衡理论无法解释实际中的货币波动，当热钱流入美国美元升值，而美元的升值又吸引了更多的投机者，使汇率更加远离均衡点。如果投机者是决定汇率水平的真正力量，那就意味着货币永远会出现先繁荣后萧条的过程。</li><li>索罗斯的投资决策往往是险中取胜，事实是，市场至少在一定程度上是有效的，所以大多数信息已经反映在价格中，投机的艺术就是看到其他人忽略的一个点，然后利用那一点小小的优势大量交易。</li><li>经验丰富的投资者也不是总能成功地纠正错误定价。</li><li>如果大交易商们已经满仓，这种消息几乎不会影响价格，但如果他们在等着进入，市场就会迅速上涨。</li><li>下跌的股票将引发投资组合保险人的抛售，而这种抛售将导致股票下跌更多。</li><li>市场可以脱离其基本价值，因为投资者缺乏挑战共识的实力，而这种趋势能持续到远远超出一个理性的点，但如果你比其他人更具备实力和勇气，你可以突然袭击，在市场毫无准备的情况下将其扰乱，因为你导致了一个新的趋势，你会是最先受益的。</li><li>进行基本面分析得知股票或债券的价值被高估了是一回事，知道什么时候市场会回归正常是另一回事，而图表则能暗示答案。</li><li>如果你了解市场上的其他玩家，你就可以找出那些非常吸引人的风险回报比的交易。</li><li>自从由于恶性通货膨胀帮助了希特勒崛起的那个时候起，德国人就十分注重货币的稳定。</li><li>当你确定自己是对的，就没有什么投注太多这样的说法，你会尽可能多的买入。</li><li>如果市场主要由追求最大利润的理性投资者控制，那么效率有可能会占上风；但如果市场由其他人驱动，那就没有理由期望有效定价。</li><li>当对冲基金通过积极购买较长期的国库券来响应美联储的低短期利率时，短期和长期利率之前的联系会更紧密。</li><li>不确定性意味着风险。</li><li>在一个券商的追加保证金就可能迫使杠杆式基金火速卖出的情况下，关键是要小心高负债的人集中的市场。</li><li>如果投机起到预警的作用而不是打击的作用的话，是让贫穷社会受益的。</li><li>当市场出现恐慌时，流动性溢价可能会增加：怯弱的投资者希望自己能迅速卖出债券，他们愿意为此付出代价。</li><li>自我纠正的趋势只是一种趋势，一个极端的事件可能会改变价格的惯常走势，这种改变可能会持续很长一段时间，甚至永远。</li><li>长期资本管理公司失败的真正教训不在于它衡量风险的方法过于简单，而是想要对风险准确衡量，这不可避免地要失败。</li><li>长期资本管理公司的失败表明没有后备资金而赌整个世界的稳定性是不理智的。</li><li>市场保持非理性的时间可能比你可持续的时间更长。过早但正确就等于错误，就像投资者多次发现的那样。</li><li>当市场价格不再具有指南作用时，你得根据一个资产所能产生的现金流量来决定购买该资产的投入。</li><li>对于一个资产以每4-5年增长一倍的基金来说，其内部专业知识的增长速度很难和拥入的资金增长同步。</li><li>在普通的具有流动性的市场，价格通常有效，预测他们是困难的。相比之下，在流动性不充分的市场会有大量便宜货，但是因为错误所付出的代价可能也会非常惨重。</li><li>对于流动性不充分资产的买家来说，最大的危险是在危机中这些资产崩溃的幅度会最大。</li><li>正是因为缺乏保密性，才使得一旦市场对他不利，它就容易成为被攻击的目标。</li><li>波动率低是因为世界上充斥着冒险资金，但充分的流动性让人误以为稳定是由金融体系的结构得到改善而带来的。</li><li>由于对冲基金习惯了自己做决定，不受监管和评级机构的干扰，他们往往表现较佳。</li><li>当交易员盲目降低负债率的时候，资本结构套利的原因就不再重要了。</li><li>政府的行动降低了“大而不倒”的机构冒险的代价，其结果就是更加冒险。</li><li>政府该如何促进能够很好的管理风险的“小到可以随意倒闭”的公司的发展呢？这是金融业未来的关键所在，而且部分答案是显而易见的：政府必须鼓励对冲基金发展。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;一本介绍对冲基金发展的书。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Note" scheme="https://blog.superui.cc/categories/reading-note/"/>
    
    
    <category term="读书" scheme="https://blog.superui.cc/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>分布间距离度量</title>
    <link href="https://blog.superui.cc/math/distribution-distance/"/>
    <id>https://blog.superui.cc/math/distribution-distance/</id>
    <published>2022-03-26T08:00:00.000Z</published>
    <updated>2022-03-26T08:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>对常用的分布间距离度量进行一个学习和复习。本文仅为初稿，日后随着理解的加深应该会进行修改和填补。</p><span id="more"></span><ul><li><a href="#kullbackleibler-divergence-kl-divergence">Kullback–Leibler Divergence (KL-Divergence)</a></li><li><a href="#jensen-shannon-divergence-jsd">Jensen-Shannon Divergence (JSD)</a></li><li><a href="#maximum-mean-discrepancy-mmd">Maximum Mean Discrepancy (MMD)</a></li><li><a href="#wasserstein-distance">Wasserstein Distance</a><ul><li><a href="#一维分布下的计算">一维分布下的计算</a></li></ul></li><li><a href="#bhattacharyya-distance">Bhattacharyya Distance</a></li><li><a href="#mahalanobis-distance">Mahalanobis Distance</a></li></ul><hr><p>正式开始之前，我想先总结一下为什么我们需要分布距离的度量。首先这里的距离并不是指我们常见的欧式距离，而是某种分布间的差异或者相似度。在我朴素的视角看来，它能为我们解答的最直观的问题是：</p><ul><li>这两个分布是不是同一个分布？</li><li>已知一个分布，另一个分布需要多少额外的信息？</li></ul><p>这些度量一般需要满足一些性质：正定（大于等于零，且可以取到0），对称，满足三角不等式。以下就是一些常见的度量。</p><hr><h2 id="Kullback–Leibler-Divergence-KL-Divergence"><a href="#Kullback–Leibler-Divergence-KL-Divergence" class="headerlink" title="Kullback–Leibler Divergence (KL-Divergence)"></a>Kullback–Leibler Divergence (KL-Divergence)</h2><p>对于分布 $P$ 和 $Q$，已知其交叉熵，可以得到 $P$ 相对于 $Q$ 的相对熵：</p><script type="math/tex; mode=display">D_{\mathrm{KL}}(p \| q) = H(p, q) - H(p) =-\sum_{x} p(x) \log \frac{q(x)}{p(x)}</script><p>相对熵又称为 KL 散度，是两个概率分布 $P$ 和 $Q$ 差别的一种非对称性度量，严格意义上不能理解为距离。其表示使用基于分布 $Q$ 的编码表来编码服从分布 $P$ 的样本（相比起用 $P$ 自己的分布来编码）所需的额外的平均比特数。在 KL 散度的基础上可以定义交叉墒，参见我们的<a href="#">Post not found: machine-learning/cross-entropy 另一条博文</a>。</p><p>KL 散度的一些特征：</p><ul><li>$p(x)$ 概率更大的匹配区域更加重要（一个更大的权重）。</li><li>不对称性。</li><li>不满足三角不等式。</li></ul><h2 id="Jensen-Shannon-Divergence-JSD"><a href="#Jensen-Shannon-Divergence-JSD" class="headerlink" title="Jensen-Shannon Divergence (JSD)"></a>Jensen-Shannon Divergence (JSD)</h2><p>JSD 解决了 KL-Divergence 非对称的问题。其形式为两个 KL-Divergence 之和。</p><script type="math/tex; mode=display">D_{\mathrm{JS}}(p \| q) = \frac{1}{2}D_{\mathrm{KL}}(p \| \frac{p+q}{2}) + \frac{1}{2}D_{\mathrm{KL}}(q \| \frac{p+q}{2})</script><p>其同样可以推广到多分布情况，在每个分布的权重为 $\pi_{i}$ 的情况下。</p><script type="math/tex; mode=display">D_{\mathrm{JS}}(P_1, P_2,...,P_n) = \sum_{i} \pi_{i} D_{\mathrm{KL}}(P_i \|M) = H(M) - \sum_{i} \pi_{i} H(P_i)\\where, M = \sum_{i} \pi_{i} P_i</script><p>JS 距离的一些特征：</p><ul><li>在以2为底的情况下，JSD的值域为 $[0, 1]$。</li></ul><h2 id="Maximum-Mean-Discrepancy-MMD"><a href="#Maximum-Mean-Discrepancy-MMD" class="headerlink" title="Maximum Mean Discrepancy (MMD)"></a>Maximum Mean Discrepancy (MMD)</h2><p>迁移学习中常用的损失函数，用来描述两个分布差别。首先通过一个连续函数 $f$ 将随机变量映射到高阶，再求其期望之差的上界，定义如下：</p><script type="math/tex; mode=display">MMD(P, Q) = \lVert E_{X \sim P}[ f(X) ] - E_{Y \sim Q}[ f(Y) ]\rVert _\mathcal{H}</script><p>又由于均值是期望的无偏估计，我们用均值替代:</p><script type="math/tex; mode=display">MMD(P, Q) = \lVert \frac{1}{n} \sum_{i=1}^{n}f(x_i) -\frac{1}{m} \sum_{j=1}^{m}f(y_j) \rVert _\mathcal{H}</script><p>当映射函数仅仅为 $f(x)=x$ 时，MMD 表示两个分布均值点的距离。而当 $f(x)$ 为无穷维时，我们无法直接计算，此时可以使用核技巧，等号两边同时平方，定义核函数来计算（常用高斯核）。</p><h2 id="Wasserstein-Distance"><a href="#Wasserstein-Distance" class="headerlink" title="Wasserstein Distance"></a>Wasserstein Distance</h2><p>又被称为推土机距离 Earth Mover’s Distance，来表述把一堆土堆成另一堆土的形状所需要的最小代价。在连续条件下可以写成如下形式：</p><script type="math/tex; mode=display">W_{p}(\mu ,\nu):=\left(\inf _{\gamma \in \Gamma (\mu ,\nu )}\int _{M\times M}d(x,y)^{p}\,\mathrm {d} \gamma (x,y)\right)^{1/p}</script><p>其中 $\gamma$ 是一个边缘分布分别为 $\mu$ 和 $\nu$ 的联合概率分布，称作 coupling。</p><p>Wasserstein Distance 具有的优点：</p><ul><li>可以衡量离散和连续分布间的距离</li><li>即使两个分布没有重叠，也可以反映他们的远近</li><li>考虑到概率分布的几何特性</li><li>可以体现如何从一个分布转换为另一个分布</li><li>这个距离是平滑的，可以提供梯度信息</li></ul><h3 id="一维分布下的计算"><a href="#一维分布下的计算" class="headerlink" title="一维分布下的计算"></a>一维分布下的计算</h3><p>对于两个分布 $\mu _{1},\mu _{2}\in P_{p}(\mathbb {R} )$ 和他们的 CDF $F_1(X), F_2(X)$，和对应的 inverse-CDF $F_1^{-1}(X), F_2^{-1}(X)$，有：</p><script type="math/tex; mode=display">W_{p}(\mu _{1},\mu _{2})=\int _{0}^{1}\left|F_{1}^{-1}(q)-F_{2}^{-1}(q)\right|^{p}\,\mathrm {d} q</script><p>这可以看作分布间差异的的横向求和，可以理解为在 x 维度上对沙土的搬运。此外，当 $p=1$ 时，可以看作分布间差异的纵向求和：</p><script type="math/tex; mode=display">W_{1}(\mu _{1},\mu _{2})=\int _{\mathbb {R} }\left|F_{1}(x)-F_{2}(x)\right|\,\mathrm {d} x</script><p>在运用 Wasserstein 距离的 WGAN中，在对 W 距离进行优化的时候，可以转化为对以下 Loss 进行优化，其中 $P_r$ 和 $P_g$ 分别是真实分布和生成分布：</p><script type="math/tex; mode=display">L = \mathbb{E}_{x \sim P_r} [f_w(x)] - \mathbb{E}_{x \sim P_g} [f_w(x)]</script><p>在这个简化的数学形式下，和 MMD 十分相似。</p><h2 id="Bhattacharyya-Distance"><a href="#Bhattacharyya-Distance" class="headerlink" title="Bhattacharyya Distance"></a>Bhattacharyya Distance</h2><p>巴式距离，很好理解，看公式一目了然。需要注意的是其并不满足三角不等式。</p><script type="math/tex; mode=display">BC(p,q)=\int {\sqrt {p(x)q(x)}}\,dx</script><h2 id="Mahalanobis-Distance"><a href="#Mahalanobis-Distance" class="headerlink" title="Mahalanobis Distance"></a>Mahalanobis Distance</h2><p>这个其实不是分布间距离的度量，而是与欧式距离曼哈顿距离同一个层级的概念。主要是每天听 dzy 说这个距离，就顺便看一眼。</p><p>首先要提到欧式距离的缺点：</p><ul><li>不同维度等同对待，哪怕单位不同</li><li>不考虑维度的相关性（非独立同分布）</li><li>举例：身高体重，量纲不同，两者相关</li></ul><p>马氏距离的主要思想在于使用主成分分析中的主成分来进行标准化。由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍即可。当个维度独立同分布，则变为欧式距离。</p><script type="math/tex; mode=display">D_{M}(x, y)=\sqrt{(x-y)^{T} \Sigma^{-1}(x-y)}</script><p>其中 $\Sigma$ 是多维随机变量的协方差矩阵。</p><hr><p>参考：</p><ol><li><a href="https://en.wikipedia.org/wiki/Statistical_distance">Statistical distance</a></li><li><a href="https://en.wikipedia.org/wiki/Jensen–Shannon_divergence">Jensen–Shannon divergence</a></li><li><a href="https://lilianweng.github.io/posts/2017-08-20-gan/">From GAN to WGAN</a></li><li><a href="https://zhuanlan.zhihu.com/p/25071913">令人拍案叫绝的Wasserstein GAN</a></li><li><a href="https://en.wikipedia.org/wiki/Wasserstein_metric">Wasserstein metric</a></li><li><a href="https://zhuanlan.zhihu.com/p/163839117">MMD Maximum Mean Discrepancy 最大均值差异</a></li><li><a href="https://zhuanlan.zhihu.com/p/46626607">马氏距离(Mahalanobis Distance)</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;对常用的分布间距离度量进行一个学习和复习。
本文仅为初稿，日后随着理解的加深应该会进行修改和填补。&lt;/p&gt;</summary>
    
    
    
    <category term="Math" scheme="https://blog.superui.cc/categories/Math/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
    <category term="distribution" scheme="https://blog.superui.cc/tags/distribution/"/>
    
    <category term="KL-divergence" scheme="https://blog.superui.cc/tags/KL-divergence/"/>
    
    <category term="JS-divergence" scheme="https://blog.superui.cc/tags/JS-divergence/"/>
    
  </entry>
  
  <entry>
    <title>Dancing With The Dragon - China - Friend or Foe?</title>
    <link href="https://blog.superui.cc/economy-finance/seminar-talks/dance-dragon/"/>
    <id>https://blog.superui.cc/economy-finance/seminar-talks/dance-dragon/</id>
    <published>2022-02-26T06:18:00.000Z</published>
    <updated>2022-02-26T06:18:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>牛津大学的辩论，关于中国是敌是友。<a href="https://youtu.be/nEchkn3unl8">原视频链接</a></p><span id="more"></span> <h1 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h1><p>其实他们的辩论还是比较逻辑清晰，相信在国外高知中具有一定的代表性，此处总结一些论据，最后加一丢丢个人的看法。</p><p>之前在抖音和B站看过一些关于这个辩论的精彩节选，当然这些节选只包含了“能给中国人看的”或者“中国人喜欢看的”部分（全部都是“友”这一方向的辩词）。本着看事情看全面的态度，特意去油管找了全视频，正反方都来看看。</p><h2 id="辩论双方"><a href="#辩论双方" class="headerlink" title="辩论双方"></a>辩论双方</h2><div class="table-container"><table><thead><tr><th>立场</th><th>姓名</th><th>简介</th></tr></thead><tbody><tr><td><strong>Friend</strong></td><td>Ser Vince Cable，文斯·凱布爾爵士</td><td>英國自由民主黨籍政治家和經濟學家</td></tr><tr><td><strong>Foe</strong></td><td>Michael Pillsbury，白邦瑞</td><td>美國國防政策顧問，前美國聯邦政府官員，中國問題作家</td></tr></tbody></table></div><h1 id="内容摘录"><a href="#内容摘录" class="headerlink" title="内容摘录"></a>内容摘录</h1><h2 id="Round-One：辩论环节"><a href="#Round-One：辩论环节" class="headerlink" title="Round One：辩论环节"></a>Round One：辩论环节</h2><h3 id="Foe"><a href="#Foe" class="headerlink" title="Foe"></a>Foe</h3><ol><li>过去大家总认为是美国打开了中国的国门，但是其实现在来看更像是中国打开了美国，并且吸纳了种种的好处。</li><li>在联合国知识产权组织的领导者竞选中，一个中国人，党员，脱颖而出而即将赢得竞选。辩手谴责了这一现象，一个著名的知识产权的盗贼国，却即将赢得竞选，这很荒谬。（当然竞选最终被一个新加坡人赢走了）</li><li>中国存有的的人权问题，审查制度，一党制，白色恐怖让中国显得像是“西方将中国拉入西方世界”这场游戏的胜者。</li><li>中国的野心不是纳粹那样，也不是日本那样的东亚共荣圈。而是重新恢复往日荣光。习需要有第三个任期来完成复兴之路。</li></ol><h3 id="Friend"><a href="#Friend" class="headerlink" title="Friend"></a>Friend</h3><ol><li>四十年前，仅通过简单的算术就可以判断中国会成为最大的经济体。四倍的美国人口，意味着中国只要达到四分之一的美国人生活水准，将会达到相同的经济总量。中国将贫困人群的生活水准提高，这是我们非常乐意看到的。（当然印度也有潜力）</li><li>英国人用了一百年习惯了 slipping down the big table 的这种落差。而美国却还没能适应这种现象（中国将进入整个世界的运转规律，而这之前是由美国主导的）。</li><li>中国模式有两个很清晰的原则：<strong>稳定和安全</strong>（在百年的混乱革命内战等等之后），<strong>提高中国的国民待遇</strong>（引入市场经济，卓有成效，虽然也存在一些问题，比如欠消费和企业负债等）</li><li>如果中国的模式没有成功，那我们不会关注他。但是问题是，如果中国的模式持续成功了，我们该如何看待和相处，对于这种社会主义市场经济和一党制。我们承认接受不同体制的存在。</li><li>香港问题，我们对看到香港很多人入狱，甚至报纸被关停十分愤怒。但是中国对香港的红线问题十分清晰。中国本可以排支军队收复香港，就像很多其他国家一样，但是它没有，它看到了一个独立的实体可能带来的好处。 你可以言论自由，但是如果暴乱，秩序被破坏，他们会阻止。那些香港人，以言论自由和民主为名，袭击警察，破坏立法会，尽自己所能杀死了香港的民主。</li><li>关于外交关系：习主席将他的施政方针在十年前就展示的很清晰。如果你想和中国保持好的关系，你需要尊重他们的原则：主权和领土完整，不干涉内政。</li><li>新疆问题，我确信那里的人权遭到了破坏，但是西方在这一问题上的立场过于强硬。明确的是，很多其他国家，包括很多重要的穆斯林国家，都站着中国那一边。你想和中国相处，要意识到他们有着不同的体系，不要干涉他们的内政。</li><li>对于英国来说，和中国合作经济上有益。比如电动车产业，路虎的利润，阿斯利康疫苗公司的利润，英国大学的学费等等。</li><li>中国实际上平衡了全球的财政制度，虽然很多人指责中国在破坏这些制度，但是其实特朗普才是破坏全球财政制度的那个人（取消对 WTO 的支持等）。</li><li>知识产权方面，日本，韩国，台湾，甚至是美国（对于最初的英国），都是在偷窃知识产权上建立起来的。这就是世界如何运行的。</li><li>国家间是需要合作的，从疫情就可以看出。以气候问题为例，我们不能寄希望于在没有中国合作的情况下解决气候问题。中国的确意识到气候问题，他们也做出了努力：碳排放交易，最大的可再生能源，新能源汽车。你不能在一个冷战背景下解决类似这样的大问题。</li><li>中国对很多拥核国有着影响力，如朝鲜，伊朗，巴基斯坦等。中国仍在扩充核武，尽管他们承诺不先使用。但是也只有和平交流才能保证安全。</li></ol><h2 id="Round-Two：主持人提问环节"><a href="#Round-Two：主持人提问环节" class="headerlink" title="Round Two：主持人提问环节"></a>Round Two：主持人提问环节</h2><h3 id="What-would-you-say-is-the-clearly-defined-role-that-china-ought-to-have-in-its-region-and-beyond-globally-Micheal"><a href="#What-would-you-say-is-the-clearly-defined-role-that-china-ought-to-have-in-its-region-and-beyond-globally-Micheal" class="headerlink" title="What would you say is the clearly defined role that china ought to have in its region and beyond globally? (Micheal)"></a>What would you say is the clearly defined role that china ought to have in its region and beyond globally? (Micheal)</h3><ul><li>用英国和当时的希特勒举例。一些英国人认为希特勒是合法的，甚至他可以做得更极端（这显然是错的，因为生灵涂炭）。</li><li>对于中国来说，我们的期望是：停止对维族人的种族灭绝，控制核武器问题。</li><li>英国当过老大，美国也当过，但是让中国当是一件危险性极大的事情。</li><li>（但是发言中，他对于这个问题并没有一个清晰的回答。）</li></ul><h3 id="Isn’t-part-of-the-problem-that-people-have-assessing-how-to-engage-with-china-Not-just-we-have-to-engage-with-china-but-actually-we-don’t-agree-with-their-vision-of-the-internet-for-instance-we-don’t-agree-with-militarization-of-the-South-China-Sea-and-these-are-matters-us-Vince"><a href="#Isn’t-part-of-the-problem-that-people-have-assessing-how-to-engage-with-china-Not-just-we-have-to-engage-with-china-but-actually-we-don’t-agree-with-their-vision-of-the-internet-for-instance-we-don’t-agree-with-militarization-of-the-South-China-Sea-and-these-are-matters-us-Vince" class="headerlink" title="Isn’t part of the problem that people have assessing how to engage with china? Not just we have to engage with china but actually we don’t agree with their vision of the internet for instance we don’t agree with militarization of the South China Sea and these  are matters us. (Vince)"></a>Isn’t part of the problem that people have assessing how to engage with china? Not just we have to engage with china but actually we don’t agree with their vision of the internet for instance we don’t agree with militarization of the South China Sea and these  are matters us. (Vince)</h3><ul><li>首先（对于 Micheal 的回答）我觉得用纳粹来类比中国是一件很 offensive 的事情，这种言语或许会毒害整个辩论并让其看起来不正确。我们讨论的起点是经济关系，但是总讨论新疆，其实解释了我们为什么总是会走到这种冷战的环境中。</li><li>（名场面）如果中国说，我们将不和美国贸易，除非你们废除宪法第二修正案（民众持枪），因为我们中国人觉得这带来的杀害侵犯了人权。如果总是以自己的角度定义人权，那将不会开始进行交流，这显然终止了讨论。中国至少是这个世界系统中的一部分，他们必须被接纳。</li><li>中国用2%的 GDP 来做军费支出，这和北约的英国一样多，他不像苏联一样致力于军事化建设。从国际扩张角度来看，美国可能有200个国际基地（表示对此没有意见），中国有2个，一个在巴基斯坦，一个在（实在是听不清）。这并不是国际军事扩张。</li><li>他们想成为国际经济的一部分，我们需要找一种方式来接纳他们。</li></ul><h3 id="Belt-and-Road-brings-infrastructures-to-the-place-where-the-west-hasn’t-provided-a-sensible-response-to-Why-doesn’t-the-west-have-a-better-answer-to-those-perfect-legitimate-questions-e-g-we-want-5G-which-Chinese-are-answering-Micheal"><a href="#Belt-and-Road-brings-infrastructures-to-the-place-where-the-west-hasn’t-provided-a-sensible-response-to-Why-doesn’t-the-west-have-a-better-answer-to-those-perfect-legitimate-questions-e-g-we-want-5G-which-Chinese-are-answering-Micheal" class="headerlink" title="Belt and Road brings infrastructures to the place where the west hasn’t provided a sensible response to. Why doesn’t the west have a better answer to those perfect legitimate questions (e.g. we want 5G) which Chinese are answering? (Micheal)"></a>Belt and Road brings infrastructures to the place where the west hasn’t provided a sensible response to. Why doesn’t the west have a better answer to those perfect legitimate questions (e.g. we want 5G) which Chinese are answering? (Micheal)</h3><ul><li>一带一路本身并不邪恶。但是一带一路可能会带来主权问题。</li><li>中国在推广他的模式，很多人喜爱中国的模式，这是我们不能接受的。</li><li>如果种族灭绝发生，你肯定不能把这个政府当成正常的政府看待。</li><li>（总体上仍然是回避了问题）</li></ul><h3 id="Essentially-the-price-of-doing-a-trade-deal-with-china-is-essentially-that-you-have-to-shut-up-about-china-if-you’re-not-gonna-say-something-nice-Vince"><a href="#Essentially-the-price-of-doing-a-trade-deal-with-china-is-essentially-that-you-have-to-shut-up-about-china-if-you’re-not-gonna-say-something-nice-Vince" class="headerlink" title="Essentially the price of doing a trade deal with china is essentially that you have to shut up about china if you’re not gonna say something nice. (Vince)"></a>Essentially the price of doing a trade deal with china is essentially that you have to shut up about china if you’re not gonna say something nice. (Vince)</h3><ul><li>如果我们想和有相同观念的国家在一起，我们会和欧洲在一起（然而我们事实上已脱欧）而不是中国。事实上，我们并没有很多选择，我们只能和这些新兴的快速成长的经济体合作。我们需要更务实（pragmatic）。</li><li>我有机会和中国总理谈论人权，你们是一个社会主义国家，但是你们的劳工都没有权利罢工。我们邪恶（wicked）的资本主义国家至少还有工会等等。我们详谈了一个半小时。</li><li>我不知道新疆确实发生了什么，我读了文献，那里可能的确有一些不合适的行为，但是我们绝对不应该用“种族灭绝”这样的词汇，这是很不合适的。当蓬佩奥开始使用这样的词汇时，他的律师与他撇清了关系，如果那里真的很邪恶，请我们使用正确的语言来描述它。</li></ul><h1 id="观后感"><a href="#观后感" class="headerlink" title="观后感"></a>观后感</h1><h2 id="对于辩论整体"><a href="#对于辩论整体" class="headerlink" title="对于辩论整体"></a>对于辩论整体</h2><ul><li>在不考虑观点论据正确性、真实性的情况下，明显能感觉到凯布尔爵士和白邦瑞两个人的语言逻辑完全不同，甚至可以说，两个人一个是在辩论，另一个更像是在做政治宣传（当然辩论也是传播思想的主要途径之一，在此不做评价）。</li><li>对于 Foe 方，在阐述过程中，白邦瑞多次使用没有论据支撑的论点，以假设语气反复强调某一论点，并且时常跑题。在提问环节中，从不正面回答问题，反而呈现的是特朗普政府那一套顾左右而言他的政客话术，个人感觉难以从他的谈吐中学到东西。</li><li>对于 Friend 方，凯布尔爵士将朋友（dance with dragon）和合作交换了概念，毕竟合作不一定需要是朋友。他的整个阐述逻辑都是围绕合作展开，个人认为这个逻辑替换还是相对可以接受。在他的小论点下（反驳目前的很多西方指责的点），他摆出了很多事实论据作为支撑，也包含他在与中国实际接触中的例子。总体的陈述方面，他先点明大原则，再在此之下展开讨论，逻辑清晰。在问答方面，个人认为他也有一些跑题，但是总体上还是围绕问题展开，也举了很多有趣的例子，我觉得还是比较不错的。</li></ul><h2 id="对于辩论内容"><a href="#对于辩论内容" class="headerlink" title="对于辩论内容"></a>对于辩论内容</h2><p>当然屁股决定脑袋，我的屁股站中国，我的脑袋也一定是站中国。其实不论他们两个人的立场（不管是个人立场还是辩论立场），我们可以从他们展现或挖掘出来的信息里看到很多东西。</p><p><strong>白邦瑞</strong>：</p><ul><li>首先最明显的一点，这个人在整个辩论过程中都充满了对自己新书的推销。甚至话说一半，剩下的“可以去我的书里找”。这或许能代表很大很大一部分美国退休政客的退休生活。</li><li>我的直观印象来看，他和特朗普在表达上有着很大的相似之处，最主要的一点在于演讲性和煽动性。对于这些性质，之前读《乌合之众》时也有一点感想，说服一群人有时候并不需要举证，举出一个观点并调动大家的情绪（威胁论，迫害论）可能就足够了。但是这是在辩论场，而且是在 Oxford Union 的辩论场，我怀疑这样是否有效，同时也觉得这样可能给他败了一波好感。</li><li>从他的发言来看，美国人最不爽的其实是“中国打开国门之后变得很好”。他们存在这么多问题但是经济还很好，所以引发了对中国体制和政党的口诛笔伐。同时也能看出来他们对于 C party 的敌意。</li><li>当他用纳粹和中国类比的时候我惊呆了，没有想到美国的高层会对中国有这样的认知，不论是否有普遍性，这种观点的产生其实足够让人思考。（当然他们很多是以新疆为论据，这个我未做调研，但是我的屁股坚定的坐在中国这一边）</li><li>个人觉得，他们是有一个中国过于强大的预期，但是他们并不满意于中国现在的一些行为方式、体制、施加影响的方式，（在不考虑“不愿意让出老大地位”的这个事实下）假设有朝一日他们愿意把老大让给中国，他们是不希望这些他们不喜欢的行为方式、体制、施加影响的方式作用在他们身上。</li></ul><p><strong>凯布尔爵士：</strong></p><ul><li>首先我认为，凯布尔爵士作为一位的确与中国有过沟通交流的政治家，经济学家，他的发言相对客观及有理有据，而且透露着一种礼貌谦逊，虽然还是有着“号召者”的那种气场（国家地位不允许），但是总体来说还是让人觉得舒服且信服的。</li><li>他说的英国已经习惯了这种从世界中心滑落的落差，而美国没有，我觉得是十分有趣的一点。这让我觉得美国当前的敌对行为是合理的，没有人愿意看到自己的相对衰落，如果真的发生，那么唯一能做的就是阻止和拖延，直到不可挽回躺平。</li><li>他能看到事情发展的两面，比如香港问题，他提到了一些对一些事件的惋惜，但是同样的，他也对香港暴徒进行了指责，我认为这是十分客观的。</li><li>他的回答很大程度上是从经济角度来看（包含 ESG），在这种情况下，他提到的合作带来的益处显而易见，这应该是无法反驳的。</li><li>从核问题角度来看，他的回答的确体现了如何从政治上进行权衡，和平的交流对中方施加善意，中方也会利用自己的影响力向其他反对西方的拥核国施加压力。而白邦瑞的态度则截然不同，他的观点更在于对抗。这就让我想起了发言人华春莹的那句话，“有没有想过把一个大国逼到绝境的后果？”</li><li>知识产权方面，的确人间清醒，这种事过去在发生，现在在发生，未来也会发生，这就是事物发展的趋势无法阻挡。我十分认同，但是我也十分支持知识产权的保护，我认为两者并不冲突。</li><li>气候问题方面，他的回答展示出很多西方高层的确看到了中国对 ESG 方向的努力，我认为这个一定程度上能体现一部分西方高层对华某些方面由衷的褒奖。</li><li>在凯布尔爵士的回答中，两次对白邦瑞的用词进行了批判。一是“纳粹”类比，二是“种族灭绝”。通过他的反驳，我对这个人肃然起敬，我觉得能为他人受到的不公发声是一件很优雅且很有勇气的事情。</li><li>对于新疆问题，他直言“我不知道新疆确实发生了什么”。我觉得其实绝大部分人，新疆人，外国人，中国人，包括我自己都不知道那里真的发生了什么，所以其实绝大部分人无证据的谈论都是毫无意义的，只能徒增吵架的材料。</li><li>在他的回答中，多次提到了接纳、融入、思考在一个有中国的体系中如何做。这是很务实且很善意的行为，我个人觉得十分欣赏。</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;牛津大学的辩论，关于中国是敌是友。
&lt;a href=&quot;https://youtu.be/nEchkn3unl8&quot;&gt;原视频链接&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Economy &amp; Finance" scheme="https://blog.superui.cc/categories/economy-finance/"/>
    
    
    <category term="辩论" scheme="https://blog.superui.cc/tags/%E8%BE%A9%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>中美关系、人民体系与未来起点收入</title>
    <link href="https://blog.superui.cc/economy-finance/seminar-talks/future-start-income/"/>
    <id>https://blog.superui.cc/economy-finance/seminar-talks/future-start-income/</id>
    <published>2022-02-20T09:30:00.000Z</published>
    <updated>2022-02-20T09:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>翟东升2021年12月中旬于财科院演讲。</p><span id="more"></span> <h2 id="1-中美关系当前态势与未来趋势"><a href="#1-中美关系当前态势与未来趋势" class="headerlink" title="1. 中美关系当前态势与未来趋势"></a>1. 中美关系当前态势与未来趋势</h2><p>当前中美关系：</p><ul><li>2021年上半年斗争为主</li><li>下半年互相让步</li><li>美方主动缓和，中方两手准备</li><li>2021年11月双方开会会谈，无人知道结果。（谈的好才保密，谈的差必然宣布“英勇斗争”）</li></ul><p>拜登政府对华特点：</p><ul><li>前倨后恭</li><li>受限于国内反华民意，力求平衡</li><li>经济困境：债务上限、高通胀</li><li>华尔街对白宫影响部分恢复</li><li>白宫对各个部门影响力有限</li><li>国内支持率低，已经弃疗，重心转向历史遗产<ul><li>众议院领先、参议院有略微优势</li><li>中期选举参议院必丢、众议院也会丢（目前领先5，平均丢27.5席位）</li></ul></li></ul><p>7.31号美国债务上限恢复，于是八月份拜登宣布在阿富汗撤军。</p><p>中美关系走向预判：</p><ul><li>中期选举之后横盘，否则会有来源于国会的压力。</li><li>三年后可能再次下跌。</li><li>特朗普在干什么？（下次竞选代表共和党可能性较大）。</li></ul><h2 id="2-如何用“人民体系”替代布雷顿森林体系及其衍生物"><a href="#2-如何用“人民体系”替代布雷顿森林体系及其衍生物" class="headerlink" title="2. 如何用“人民体系”替代布雷顿森林体系及其衍生物"></a>2. 如何用“人民体系”替代布雷顿森林体系及其衍生物</h2><p>三个强盗分金沙：</p><ul><li>两个人分：先分后挑</li><li>前一个人分，下一个人如果认为多了，减沙自取</li><li>和平的无政府博弈的关键在于：<ul><li>权力和责任要匹配：美国获得货币特权，却不愿意承担逆差的结果。</li><li>原则理念与现实手段要匹配</li></ul></li></ul><p>怀特和凯恩斯的辩论：</p><ul><li>怀特的理论有内在缺陷：例如特里芬难题（一国货币成为国际储备货币）</li><li>盖恩斯的理论更为完善</li><li>怀特计划形成布雷顿森林体系<ul><li>GATT 关税贸易总协定</li><li>世界银行</li><li>金汇兑本位制：美金可以换黄金，其他货币不能换黄金。（戴高乐发债换美元赎黄金再用黄金抵押发债）</li></ul></li></ul><p>“人民体系”：以全世界人民为中心而不是以金融资本为中心（资本相对劳动占据优势地位）</p><ul><li>原有体系受益者是资本拥有者（印钱推动资产上升）</li><li>为什么全世界绝大多数国家会乐意参与这个新体系？</li><li>分配方式：由新的全球央行通过购买各国国债来为各国提供资金</li></ul><p>布雷顿森林体系根本困境：</p><ol><li>权责不对等导致现行秩序合法性权威性缺失。</li><li>特里芬难题，美元作为国内货币主权性和作为国际货币的超主权性的矛盾。</li><li>基于英美谈判，难以反映现今国际政治经济权利格局。</li><li>自由贸易成为冲突之源。</li></ol><p>需求：</p><ul><li>一个权责匹配的，正确反映当前国际权力格局和时代挑战的国际经济新秩序</li><li>中美欧应当就21世纪货币金融贸易产业等国际规则展开谈判，寻求顶层规划，设计公平合理可持续的“人民体系”，以取代布雷顿森林体系和牙买加体系。</li></ul><p>“人民体系”（翟东升，嵇先白）：</p><ol><li>基本平衡的贸易 Balanced Trade：而不是自由贸易</li><li>超越主权的货币 World Currency：而不是主权货币<ul><li>这种国际货币需要<strong>锚定一揽子商品</strong>。</li></ul></li><li>绿色普惠的金融 Responsible Finance：ESG为主，而不是利润最大化导向</li></ol><p>如何把这套体系变成现实：</p><ol><li>中美谈判难以成功。将欧洲纳入。人民体系一定程度上是欧洲一体化经验教训的全球版。（但是非平衡贸易，商品服务不能自由流通。）</li><li>短期难以谈成，但是可以先下手为强，抢占制度变革的话语权。</li><li>有可能将世界分为两个平行的国际体制。</li></ol><h2 id="3-如何用“未来起点收入”推进共同富裕和内循环"><a href="#3-如何用“未来起点收入”推进共同富裕和内循环" class="headerlink" title="3. 如何用“未来起点收入”推进共同富裕和内循环"></a>3. 如何用“未来起点收入”推进共同富裕和内循环</h2><p>如果美方不接受2中的体系，或者我方没有下定决心进行改革，那么就需要在内部搞共同富裕。</p><p>民粹主义两大支柱：</p><ul><li>数据信息传播模式发生变化。</li><li>贫富分化。</li></ul><p>为什么必须搞共同富裕？</p><ul><li>避免民粹主义和政治动荡。（避免出现落第秀才）</li><li>共同富裕撬动消费和投资的增长，实现内循环为主的双循环</li><li>增加国民福利，让中国人投入更有意义的工作和学习，实现高质量发展</li></ul><p>合成谬误：每个人都是有道理的，但是合在一起起到了颠覆性的效果。</p><h3 id="共同富裕：北欧的例子"><a href="#共同富裕：北欧的例子" class="headerlink" title="共同富裕：北欧的例子"></a>共同富裕：北欧的例子</h3><p>黄文政：推动计划生育变革、哈佛教统计学、颠覆统计学底层逻辑、华尔街对冲基金、未加入美国国籍、致力于拯救中华民族（游说改变计划生育政策）、《新时代中国特色社会主义道路下的全民基本收入》：未来起点收入（给年轻人发钱）</p><p>北欧：</p><ul><li>税全球最高</li><li>人均GDP最高</li><li>亿万富翁密度最高</li></ul><h3 id="如何做？谁得利？谁受损？"><a href="#如何做？谁得利？谁受损？" class="headerlink" title="如何做？谁得利？谁受损？"></a>如何做？谁得利？谁受损？</h3><ul><li>中央地方的财权、事权和债务再分配</li><li>区域再分配：转移支付</li><li>代际再分配：让中老年人向年轻人让利</li><li>行业再分配：挤压原本比较肥的行业（金融、电力）</li><li>国际再分配：央行资产负债表的替代</li><li>阶层再分配：反腐、扶贫、医疗教育住房</li><li>人民币汇率水平适当高估，从长期巨额顺差变成大体平衡略有逆差。</li><li>“未来起点收入方案”：补贴年轻人，促进机会平等、提高人口素质、增强我国人口竞争力。</li></ul><h3 id="钱从哪来？"><a href="#钱从哪来？" class="headerlink" title="钱从哪来？"></a>钱从哪来？</h3><ul><li>税收：查税，警税合作，藏富于民</li><li>富人的税收是小头，大头来自于国债扩张（现代货币理论）</li></ul><h3 id="社会结构转型带来巨大内循环商机"><a href="#社会结构转型带来巨大内循环商机" class="headerlink" title="社会结构转型带来巨大内循环商机"></a>社会结构转型带来巨大内循环商机</h3><ul><li>懂得资产配置，将能从共同富裕中获利</li><li>从金字塔社会向橄榄形社会的转变将带来中产阶级和国内消费市场的快速扩大。（富人消费市场大还是中产消费市场大？）</li><li>如果共同富裕能实现，中国国内市场规模等于美欧日之和。</li><li>新增中产主要在哪里？</li></ul><p>新中产的形成与未来商机：</p><ul><li>哪些生意的市场规模扩张到十倍以上？哪些商品和服务？</li><li>汽车动力电池需求；富贵病医疗需求；高铁航空出行需求；旅游度假需求；优质教育；线下消费；养宠物情感需求；优质高端养老服务需求</li><li>这些需求扩张未必带来利润率大幅上升，因为多数供给也会随之扩张。</li><li>需求上涨而供给无法扩张的东西，价格会有明显上涨：如茅台，顶级医疗</li><li>劳动力更贵，机器人普及</li><li>旅游业</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;翟东升2021年12月中旬于财科院演讲。&lt;/p&gt;</summary>
    
    
    
    <category term="Economy &amp; Finance" scheme="https://blog.superui.cc/categories/economy-finance/"/>
    
    
    <category term="翟东升" scheme="https://blog.superui.cc/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>乌合之众</title>
    <link href="https://blog.superui.cc/reading-note/the-crowd/"/>
    <id>https://blog.superui.cc/reading-note/the-crowd/</id>
    <published>2022-02-06T07:00:00.000Z</published>
    <updated>2022-02-06T07:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>《乌合之众》古斯塔夫·庞勒（1841-1931），法国社会心理学家。</p><span id="more"></span><h2 id="极简简介"><a href="#极简简介" class="headerlink" title="极简简介"></a>极简简介</h2><p>这是一本百年前对群体心理学研究的书籍。主要介绍了三个方面：群体的心理与特征，群体意见信念及形成原因和演变，群体的分类与特点。作为参考，豆瓣上有一份个人认为比较全面且简略的<a href="https://book.douban.com/review/5204395/">内容梗概</a>。</p><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>这是一本能帮我们意识到群体具有其独特性质的书，一定程度上可以让我们对生活中一些事件有一些初步的认知，比如说：</p><ol><li>可以以此分析EDG夺冠后群体的不合理发泄的合理性（即群体的一般特征）。</li><li>1989的事件，群体的煽动性和不可控性展现的淋漓尽致。</li><li>翟老师对于之前美国通胀的表述，人民群众起义抵抗。</li><li>长津湖观影时觉得士兵慷慨赴死，体现了群体道德的一部分。</li></ol><p>但总体而言，书还是过于老旧，启发式作用远大于知识性作用，读来涨见识不错，实际运用的话还是缺少很多证据支持及实操手段，相信后人也有着更加细致的研究。</p><h3 id="缺点（喜爱挑毛病）"><a href="#缺点（喜爱挑毛病）" class="headerlink" title="缺点（喜爱挑毛病）"></a>缺点（喜爱挑毛病）</h3><ol><li>虽然结论很精彩，但论述也很薄弱（多用例证法，虽然这已经在当时是比较好的论述方式了）。的确此书指出了很多群体中出现的现象，也分析了一些原因等，但是其并没有一些指导性的建议缓解群体的这些缺点。</li><li>如今看来政治十分不正确。本书多次提到了女性和孩童容易走向极端和性格反复感情用事。同时也提到拉丁族裔的狭隘。也将种族作为一个影响群体意见的很大因素。</li></ol><h3 id="感想-看法"><a href="#感想-看法" class="headerlink" title="感想/看法"></a>感想/看法</h3><ol><li>“乌合之众”，何为“众”，其实是一个值得定义的东西。虽然书中列举了一些群体，但是我觉得还是过于宏观，或许不能一概而论。而且不同的粒度下或许群体性质会有改变。</li><li>作为管理者的话，此书或许较为重要，可以帮助理解群体的思维方式，但是具体如何管理，还是需要参考其他的著作。</li><li>“为公众留下深刻印象的不是事实，而是事情发生并引起注意的方式。”认为这句话说的很对，例如最近的一系列小作文事件。如何博眼球，如何娱乐化，如何占据道德的制高点，显得比事实更加重要。</li><li>罗伯特•墨顿的序“勒庞《乌合之众》的得与失”写得很好，他提到一点，“《乌合之众》的当代意义，在于它发现问题的功能而非解决问题的功能。”（摘自<a href="https://book.douban.com/review/5204395/">此链接</a>）。</li></ol><h1 id="按节讨论-摘录"><a href="#按节讨论-摘录" class="headerlink" title="按节讨论/摘录"></a>按节讨论/摘录</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><ul><li>文明更新过程中，仅有的重大变化就是受其影响的观念理念和信念的变化。</li><li>人们的行为从来都不是建立在纯粹理性之上的。</li></ul><h2 id="第一卷-群体心理"><a href="#第一卷-群体心理" class="headerlink" title="第一卷 群体心理"></a>第一卷 群体心理</h2><h3 id="第一章-群体的一般特征"><a href="#第一章-群体的一般特征" class="headerlink" title="第一章 群体的一般特征"></a>第一章 群体的一般特征</h3><ul><li>集体心理使他们的感受思想和行为方式与其作为独立个体时的感受思想和行为方式有着很大的不同。</li><li>不同的原因造成群体的新特征<ul><li>构成群体的个体在考虑事情是时从数量方面出发，他们会感受到一种无敌的力量，并因此形成一种本能。当他们独自一人时，则必须克制这种本能。群体是无名的，因此也无需承担责任，然后一直控制着个体的那种责任感便完全消失。</li><li>传染决定着群体特殊特征的表现。个体的受到传染后，很容易会被集体利益，而牺牲个人利益。这种能力有违个体的本性，而且除非作为群体的一部分，否则一个人很少能做到这一点。</li><li>在暗示的影响下，个体将会在不可抵抗的冲动的支配下，完成某些行为。</li></ul></li><li>群体在治理方面总是劣于其独立个体，但是从群体所引发的个体感受和行为的观点来看，根据不同的环境，群体可能会优于或劣于其个体。</li><li>群体通常都是犯罪性的，但英雄性群体是同样存在的。</li></ul><h3 id="第二章-群体的情感和道德"><a href="#第二章-群体的情感和道德" class="headerlink" title="第二章 群体的情感和道德"></a>第二章 群体的情感和道德</h3><ul><li>独立的个体具有支配其反射作用的能力，而群体则不具备这种能力。</li><li>群体的多变性使得他们难以管辖。尽管群体的愿望十分狂热，但是这些愿望仍不会长久，因为群体既没有能力，也没有意愿为任何事做长久打算。</li><li>群体并不准备承认任何事都或成为其欲望和欲望实现之间的阻碍，由于感觉到人多势众所赋予的不可抵抗的力量，所以群体没有能力理解这种阻碍。</li><li>群体会永远徘徊在无意识的边陲地带，迅速屈服于所有的暗示，游泳所有无法上溯至理性影响的生命体所特有的暴力感受，同时失去所有批判能力，而且除了过度轻信意外再无其他能力。</li><li>对于一个群体而言，不可能的事是不存在的。</li><li>通常来说，如果一件事得到了成千上万的目击者的证实，那么事情的真实情况一定与大家所说的情况存在较大差异。</li><li>不管群体展现出来的情感是好是坏，他们都展现出了双重性格，简单与夸张。<ul><li>在群体中，愚蠢、无知和有嫉妒心的人感受不到他们的毫无意义和无能为力。</li><li>群体愈加夸张的去时通常会施加于坏情绪上（作为个体对惩罚的恐惧迫使其竭力控制坏情绪这种本能），因此群里很容易会导致坏的过激行为的发生。</li><li>这并不意味着在受到巧妙的影响下不能表现出英雄主义以及成为最高美的标准的证明。</li></ul></li><li>如果一位演说家要感染一个群体，那他必须粗暴地使用激烈的言论，必须通过夸张、断言或依靠与重复，而且永远不要试图通过推理的方式来证明任何事。</li><li>群体会夸大对英雄的情绪。</li><li>个体成为群体的一部分之后，他的治理标准就会立即大幅度降低。</li><li>群体只知道简单和极端两种情绪；他们将所受到的观点想法和性能作为一个整体而接受或拒绝，而且会将他们看作绝对真理或绝对错误。</li><li>个体可能会接受矛盾并进行讨论，但是群体将永远不会这么做。</li><li>群体会对强势力量“俯首称臣”，而且很少会被善良所打动，因为善良对于他们而言不过是一种软弱的表现。他们从来不会同情随和的人，但却会同情极力压迫他们的暴君。群体所欣赏的那类英雄总是会与凯撒有相似之处，他的徽章吸引着他们，他的权利震慑着他们，他的利剑让他们对其充满恐惧而又敬畏。</li><li>群体的光荣、名誉和爱国主义情感尤其可能会对其中的个体产生影响，而且个体通常也会在这种影响的作用下献出生命。</li></ul><h3 id="第三章-群体的观念、理性思考能力和想象力"><a href="#第三章-群体的观念、理性思考能力和想象力" class="headerlink" title="第三章 群体的观念、理性思考能力和想象力"></a>第三章 群体的观念、理性思考能力和想象力</h3><ul><li>观念只能以群体所假定的简单形式才会被群体所接受，而且通常必须要经过最彻底的转变才能变得流行。</li><li>群体理性思考能力的特征就是仅在表面上相互关联的不同事物之间的结合，而且那些特定情况立即就会变的一般化。那些知道如何管理群体的人总是会向群体展示这种论证。</li><li>争取切法理性思考能力的人一样，群体的想象力是非常有利、非常积极，且容易受到强烈影响的。这就是为什么能让群体留下深刻印象的事总是那些不可思议和充满传奇色彩的事。</li><li>当我们对一种文明进行分析时，我们会看到，真正支撑文明的就是那些不可思议和充满传奇色彩的事。在历史上，表现总比现实发挥着更重要的作用，而不真实总是比真实更加有力。</li><li>每一个时代、每一个国家的伟大政治家，包括绝对专制的君主，他们都非常重视大众的想象，而且将此作为权利的基础并在对大众进行统治期间从未尝试反对他们的这些想象。（举了拿破仑天主教徒、伊斯兰教徒、教皇权力主义者的例子）</li><li>安东尼并非是利用花言巧语才成功让平民们反抗凯撒并谋杀了他；而是通过向大众宣读凯撒的遗嘱并抬出了他的尸体。</li><li>事情必须以整体的方式呈现在群体面前，而且不能告诉他们事情的起源。</li><li>为公众留下深刻印象的不是事实，而是事情发生并引起注意的方式。</li></ul><h3 id="第四章-群体信仰的宗教形态"><a href="#第四章-群体信仰的宗教形态" class="headerlink" title="第四章 群体信仰的宗教形态"></a>第四章 群体信仰的宗教形态</h3><ul><li>群体在受到适当的影响之后会准备为他们所激发出来的理想而奉献自己。</li><li>宗教情绪的特点非常简单，比如对想象中的高级生命体的崇拜、对其权力的恐惧、对其命令的盲目尊从、不具备讨论起教条的能力，以及将不接受这些教条的人看作敌人的倾向。</li><li>所有宗教或政治信条的的创始人之所以能够成功，是因为他们都通过那些狂热的情绪极大地鼓舞了民众，而这些情绪则使得人们在崇拜中找到了幸福，并且他们愿意且已准备好为他们的理想而献身。</li></ul><h2 id="第二卷-群体的观点与信念"><a href="#第二卷-群体的观点与信念" class="headerlink" title="第二卷 群体的观点与信念"></a>第二卷 群体的观点与信念</h2><h3 id="第一章-群体观点与信念的间接因素"><a href="#第一章-群体观点与信念的间接因素" class="headerlink" title="第一章 群体观点与信念的间接因素"></a>第一章 群体观点与信念的间接因素</h3><ul><li>决定群体的观点和信念有两种因素，间接因素和直接因素，间接因素中存在着一些一般属性，而这些属性就是群体所有信念和观念的基础。这些属性就是：种族、传统、时间、制度和教育。</li><li>种族的力量就在于在不经历最深刻变革的情况下，任何要素都不能在种族之间进行传播。</li><li>如果一个民族允许其风俗习惯变得根深蒂固，那么这些传统将不再发生变化，而且就像中国一样，这个民族就不再拥有改进与提高的能力。在这种情况下，暴力革命是没有任何作用的，因为其结果无非是那些被打碎的束缚再一次拼凑在一起，并且让过去的帝国原封不动地重现，接下来就是残余的历史碎片很快会破碎，然后陷入无尽的混乱。</li><li>一些重要因素的形成是依赖于时间的，比如种族，如果没有时间，种族便无法形成。</li><li>一个民族无法按照自己的意愿选择题制度，就像他们不能选择自己头发和眼睛的颜色一样，制度和政府都是种族发展的产物。他们并不是时代的造物主而是时代造就了他们。</li><li>制度并没有固有美德，就制度本身而言，他们没有好坏之分。那些良好的制度，是指在既定时间内对既定人群无害的制度，但是对于其他民族而言，这种制度可能会是另一个极端。</li><li>教育使得一个国家的年轻人可以了解这个国家的未来。</li></ul><h3 id="第二章-群体观点的直接因素"><a href="#第二章-群体观点的直接因素" class="headerlink" title="第二章 群体观点的直接因素"></a>第二章 群体观点的直接因素</h3><ul><li>词语的力量与他们所唤起的图像有密切的联系，而且不受其真正意义的支配。有时候意义最不明确的词语反而拥有最大的影响力。</li><li>语言所包含的词语在时代的发展过程中变化的非常缓慢，但是这些词语所唤起的图像或者它们的意义却在不停的变化。</li><li>政治家最基本的职能之一就是，无论如何都要经得住流行用语以及群体无法忍受其原有名称词语的考验。</li><li>在一个同样的社会中，同样的词语对于不同的社会阶层有着不同的含义，他们表面是使用同样的词语，实际上他们所说的是不同的语言。</li><li>无论是谁，只要能为他们带来幻想，这个人就会轻易成为它们的领袖；无论是谁，只要试图毁灭他们的幻想，这个人就会成为他们的受害人。</li></ul><h3 id="第三章-群体的领袖及他们的说服方法"><a href="#第三章-群体的领袖及他们的说服方法" class="headerlink" title="第三章 群体的领袖及他们的说服方法"></a>第三章 群体的领袖及他们的说服方法</h3><ul><li>领袖的行动方法：断言、重复和传染</li><li>对于一个人而言，如果模仿是十分容易的，那么模仿是必然的。</li><li>人们会把从高位跌落的英雄看成与他们平等的人，而且还会对这位不再有任何优越性的人采取报复行动。</li><li>从威望遭受质疑的那一刻起，，威望便不再有任何威力。如果要得到群众的仰慕，威望的载体就必须与他们保持距离。</li></ul><h3 id="第四章-群体观点与信念可变性的局限性"><a href="#第四章-群体观点与信念可变性的局限性" class="headerlink" title="第四章 群体观点与信念可变性的局限性"></a>第四章 群体观点与信念可变性的局限性</h3><ul><li>真正广义信念的数量是非常有限的。他们的出现和消亡都来自于历史上每一个种族历史的巅峰时刻，它们构成了文明的真正框架。</li><li>一般来说想要改变一种信念就必须要以暴力革命为代价。事实上，一场革命的开始就是一种信念的结束。</li><li>一种伟大信念开始衰败的精确时刻是很容易辨认的，就是当人们开始质疑其价值的时候。</li><li>现在一种观点在被大众普遍接受并成为一种普遍观点之后就已经消亡了。</li></ul><h2 id="第三卷-不同群体的分类和描述"><a href="#第三卷-不同群体的分类和描述" class="headerlink" title="第三卷 不同群体的分类和描述"></a>第三卷 不同群体的分类和描述</h2><h3 id="第一章-群体的分类"><a href="#第一章-群体的分类" class="headerlink" title="第一章 群体的分类"></a>第一章 群体的分类</h3><ul><li>由于种族的精神力量十分强大，因此群体的劣质特征并不占据重要比重</li></ul><h3 id="第二章-犯罪群体"><a href="#第二章-犯罪群体" class="headerlink" title="第二章 犯罪群体"></a>第二章 犯罪群体</h3><ul><li>通常群体犯罪动机是一种强烈的暗示，而且参与犯罪的个体在事后坚信他们的所作所为是遵从义务，这与普通的犯罪情况相去甚远。</li></ul><h3 id="第三章-刑事陪审团"><a href="#第三章-刑事陪审团" class="headerlink" title="第三章 刑事陪审团"></a>第三章 刑事陪审团</h3><ul><li>展示出易受暗示的特征，但是他们却几乎没有能力进行理性思考。容易受到群体领袖的影响，而且还主要收到无意识情绪的引导。</li><li>群体的力量是令人敬畏的，但是某些社会等级群体的力量是更加令人恐惧的。群体还有被说服的可能，但是那些社会等级群体则永远没有这种可能。</li></ul><h3 id="第四章-选民群体"><a href="#第四章-选民群体" class="headerlink" title="第四章 选民群体"></a>第四章 选民群体</h3><ul><li>头等重要的是，候选人必须要想有威望，而这种威望能迫使选民们没有异议地支持自己。</li><li>拥有威望还不足以确保候选人能获得成功，选民们特别重视别人对其贪婪和虚荣的恭维。</li><li>对于社会问题，由于其数量是未知的，所以人从本质上来讲都是同样无知的。</li></ul><h3 id="第五章-议会"><a href="#第五章-议会" class="headerlink" title="第五章 议会"></a>第五章 议会</h3><ul><li>在群体中最重要的特征就是他们观点的简单化。到目前为止，这种群体的不变趋势就是通过最简单的抽象原则和适用于所有情况的普通法律来解决最复杂的问题。</li><li>通常情况下，议会的投票只代表少数人的观点。</li><li>领袖应该掌握一种特殊的雄辩术，包括有力的肯定，无需证据证明，以及令人印象深刻的形象，同时伴随非常简明扼要的论证。</li><li>所谓自由的增加，必定紧随着实际自由的减少。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;《乌合之众》古斯塔夫·庞勒（1841-1931），法国社会心理学家。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Note" scheme="https://blog.superui.cc/categories/reading-note/"/>
    
    
    <category term="读书" scheme="https://blog.superui.cc/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>人工智能中的逻辑</title>
    <link href="https://blog.superui.cc/artificial-intelligence/ai-logic/"/>
    <id>https://blog.superui.cc/artificial-intelligence/ai-logic/</id>
    <published>2021-11-24T13:30:00.000Z</published>
    <updated>2021-11-24T13:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>将逻辑作为基于知识的 Agent 的一类通用表示，这样的 Agent 通过对信息的组合和再组合以适应各种用途。本文一部分参考了这位同学的<a href="https://blog.csdn.net/rectsuly/article/details/73104723">笔记</a>。</p><span id="more"></span><p>Logics: formal languages for representing knowledge to extract conclusions</p><h1 id="基于知识的-Agent"><a href="#基于知识的-Agent" class="headerlink" title="基于知识的 Agent"></a>基于知识的 Agent</h1><ul><li>知识库（KB）：基于知识的 Agent 的核心部件。是一个“语句”集合。</li><li>语句（sentence）：用知识表示语言表达，表示了关于世界的某些断言。</li><li>公理：当某语句是直接给定而不是推导得到的时候，我们将其称为公理。</li></ul><p>每次调用 Agent 程序，他做三件事：</p><ol><li>Agent TELL 知识库他所感知到的内容。</li><li>Agent ASK 知识库应该执行什么行动。<ul><li>在此过程中可能会对于世界的当前状态，可能行动队列进行大量推理。</li></ul></li><li>Agent TELL 知识库他采取的行动，并执行该行动。</li></ol><h1 id="逻辑知识与概念"><a href="#逻辑知识与概念" class="headerlink" title="逻辑知识与概念"></a>逻辑知识与概念</h1><p>逻辑：一种形式语言，可以表示能得出结论的信息 </p><ul><li>语法（Syntax）：定义了语言中的句子 </li><li>语义（Semantics）：定义了句子的意思，即语义定义了每个语句关于每个可能世界的真值 </li></ul><p>蕴涵（Entailment）</p><ul><li>蕴涵意为一个语句逻辑上跟随另一个语句而出现：$KB |= \alpha$</li><li>知识库 KB 蕴涵句子 $\alpha$ 当且仅当在 KB 为真的每个世界中，$\alpha$也为真</li><li>蕴涵是句子间的关系，其基于语义。</li><li>例如，x=0 蕴含 xy=0。</li></ul><p>逻辑推理（inference）：</p><ul><li>如果推理算法 i 可以根据 KB 导出 $\alpha$，我们表示为：$KB |-_{i} \alpha$，读为“i 从 KB 导出 $\alpha$”</li><li>KB的所有推论集合是一个干草堆，α是针，蕴含=干草堆里的针，推理=找到它 </li><li>对于推理算法 i：<ul><li>可靠性 Sound：不会虚构事实，只导出语义蕴涵句。</li><li>完备性 Completeness：可以生成任一蕴涵句。</li></ul></li></ul><h1 id="命题逻辑"><a href="#命题逻辑" class="headerlink" title="命题逻辑"></a>命题逻辑</h1><p>Syntax 语法：</p><ul><li>原子语句：命题符号P1，P2等是句子，代表一个或为真或为假的命题 </li><li>复合句： <ul><li>如果S是一个句子，则┐S也是一个句子（negation 非，否定式） </li><li>如果S1和S2是句子，则S1∧S2是句子（conjunction 与，合取式） </li><li>如果S1和S2是句子，则S1∨S2是句子（disjunction 或，析取式） </li><li>如果S1和S2是句子，则S1=&gt;S2是句子（implication 蕴涵，蕴涵式） </li><li>如果S1和S2是句子，则S1&lt;=&gt;S2是句子（biconditional 当且仅当，双向蕴涵式）</li></ul></li></ul><p>语义：</p><ul><li>定义了判定特定模型中语句真值的规则。</li><li>可以用真值表总结</li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/truth-table.png" class=""></div><p>其中=&gt;的真值表比较令人困惑。</p><ul><li>不要用如果 P 那么 Q的思路来理解。<ul><li>命题逻辑不要求 P/Q 间的相关性或因果关系。</li></ul></li><li>以“如果 P 为真，那我主张 Q 为真，否则无可奉告”来理解。<ul><li>前提为假的任意蕴含都为真。</li><li>该语句为假的唯一条件是 P 为真而 Q 为假。</li></ul></li></ul><p>算符具有一定的运算性质（逻辑等价）：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/property.png" class=""></div><p>Implication 的几形式变换，真值可能会发生变换：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/implication.png" class=""></div><h2 id="推导和证明"><a href="#推导和证明" class="headerlink" title="推导和证明"></a>推导和证明</h2><p>下列表示意为，给定任何形式的上方语句，就可以推导出下方语句：</p><ul><li>Modus Ponens: 假言推理原则 $\frac{\alpha \Rightarrow \beta, \quad \alpha}{\beta}$</li><li>Modus Tollens: 假言推理原则 $\frac{\alpha \Rightarrow \beta, \quad \neg \beta}{\neg \alpha}$</li><li>Addition: $\frac{\alpha}{\alpha \vee \beta}$</li><li>Simplification/And-Elimination: $\frac{\alpha \wedge \beta}{\beta}$</li><li>Disjunctive-syllogism: $\frac{\alpha \vee \beta, \quad \neg \alpha}{\beta}$</li><li>Hypothetical-syllogism: $\frac{\alpha \Rightarrow \beta, \quad \beta \Rightarrow \gamma}{\alpha \Rightarrow \gamma}$</li></ul><p>Search for proofs is a more efficient way than enumerating models: </p><ul><li>Truth tables have an exponential number of models.</li><li>The idea of inference is to repeat applying inference rules to the KB.</li><li>Inference is sound, but how about completeness?</li></ul><h2 id="如何来保证完备性？"><a href="#如何来保证完备性？" class="headerlink" title="如何来保证完备性？"></a>如何来保证完备性？</h2><ul><li>Proof by resolution</li><li>Forward or Backward chaining</li></ul><h3 id="归结（Resolution）"><a href="#归结（Resolution）" class="headerlink" title="归结（Resolution）"></a>归结（Resolution）</h3><p>类似于 Disjunctive-syllogism。如果两个中必存在一个，而又不是第一个，则是第二个。</p><p>单元归结（Unit resolution）</p><script type="math/tex; mode=display">\frac{\ell_{1} \vee \cdots \vee \ell_{k} \quad m}{\ell_{1} \vee \cdots \vee \ell_{i-1} \vee \ell_{i+1} \vee \cdots \vee \ell_{k}}</script><p>全归结（Full resolution）</p><script type="math/tex; mode=display">\frac{\ell_{1} \vee \cdots \vee \ell_{k} \quad m_{1} \vee \cdots \vee m_{n}}{\ell_{1} \vee \cdots \vee \ell_{i-1} \vee \ell_{i+1} \vee \cdots \vee \ell_{k} \vee m_{1} \vee \cdots \vee m_{j-1} \vee m_{j+1} \vee \cdots \vee m_{n}}</script><p>其中 $\ell_{i}$ 和 $m_{j}$ 是互补文字。</p><h3 id="合取范式（CNF）"><a href="#合取范式（CNF）" class="headerlink" title="合取范式（CNF）"></a>合取范式（CNF）</h3><p>以子句的合取式表达的语句被称为合取范式或者 CNF， 合取式不易阅读，但其将成为归结过程的输入：</p><ul><li>消去等价词</li><li>消去蕴含次</li><li>否定词只出现在文字前边（而不是括号前面）</li></ul><h3 id="归结算法"><a href="#归结算法" class="headerlink" title="归结算法"></a>归结算法</h3><p>为了证明 $KB |= \alpha$，需要证明 $(KB \wedge \neg\alpha)$是不可满足的，通过推倒矛盾来证明。</p><ul><li>先将 $(KB \wedge \neg\alpha)$ 转化为 CNF。</li><li>对子句运用归结规则，产生新子句，如果其尚未出现过，则将其加入子句集，直到：<ul><li>没有可以添加的新语句。</li><li>两个子句归结出空子句，等价于 False。（函数返回 True）</li></ul></li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/pl-resolution.png" class=""></div><blockquote><p><strong>基本归结定理</strong>：如果子句集是不可满足的，那么这些子句的归结闭包包含空子句。</p></blockquote><h3 id="Forward-or-Backward-chaining"><a href="#Forward-or-Backward-chaining" class="headerlink" title="Forward or Backward chaining"></a>Forward or Backward chaining</h3><p>前向链接 Forward Chaining：</p><ul><li>判断单个命题词是否被限定子句的知识库所蕴含。</li><li>这个算法运行的时间是线性的。</li><li>data-driven</li></ul><p>反向链接 Backward Chaining：</p><ul><li>从查询开始进行推理，如果查询为真则停止，否则，从知识库寻找以 q 为结论的蕴含式，如果前提都为真，则为真。</li><li>这个算法运行的时间也是线性的。</li><li>goal-driven</li></ul><h3 id="DPLL-Algorithm"><a href="#DPLL-Algorithm" class="headerlink" title="DPLL Algorithm"></a>DPLL Algorithm</h3><ul><li>Check the satisfiablity of a sentence in propositional logic.</li><li>类似 backtracking 但是运用了很多启发式的技术，例如早停、纯符号启发式、单元子句启发式等。</li></ul><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/DPLL.png" class=""></div><h1 id="一阶逻辑-First-Order-Logic（FOL）"><a href="#一阶逻辑-First-Order-Logic（FOL）" class="headerlink" title="一阶逻辑 First Order Logic（FOL）"></a>一阶逻辑 First Order Logic（FOL）</h1><p>可以作为 Propositional Logic 的替代。（命题逻辑表达能力很弱。）</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/FOL.png" class=""></div><h1 id="总结-Summary"><a href="#总结-Summary" class="headerlink" title="总结 Summary"></a>总结 Summary</h1><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-logic/summary.png" class=""></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;将逻辑作为基于知识的 Agent 的一类通用表示，这样的 Agent 通过对信息的组合和再组合以适应各种用途。
本文一部分参考了这位同学的&lt;a href=&quot;https://blog.csdn.net/rectsuly/article/details/73104723&quot;&gt;笔记&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://blog.superui.cc/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://blog.superui.cc/tags/AI/"/>
    
    <category term="logic" scheme="https://blog.superui.cc/tags/logic/"/>
    
  </entry>
  
  <entry>
    <title>国际经济形势与中美关系</title>
    <link href="https://blog.superui.cc/economy-finance/seminar-talks/china-us-relationship/"/>
    <id>https://blog.superui.cc/economy-finance/seminar-talks/china-us-relationship/</id>
    <published>2021-11-14T04:39:46.000Z</published>
    <updated>2021-11-14T04:39:46.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>翟东升 2021-10-28 于海南讲座。</p><span id="more"></span> <p>本次讲座涉及四个 Topic。</p><h2 id="1-疫情冲击何时结束"><a href="#1-疫情冲击何时结束" class="headerlink" title="1. 疫情冲击何时结束"></a>1. 疫情冲击何时结束</h2><ul><li>疫情传播似乎更加普及，但是疫苗的使用下，死亡率重症率下降。</li><li>11月8日开始世界大国开始放开人员往来。</li><li>中国可能在较长一段时间保持是否开门的难题。</li><li>由于疫情，东亚供应链可能重新收缩为中国供应链，一部分产能试图回中国，但是目前看来我们也不愿意接受。</li></ul><h2 id="2-美联储是否有能力加息缩表"><a href="#2-美联储是否有能力加息缩表" class="headerlink" title="2. 美联储是否有能力加息缩表"></a>2. 美联储是否有能力加息缩表</h2><ul><li>美国当前通胀率很高。</li><li>70年代中后期，婴儿潮，美国通胀率也高。美国政府主要挑战就是国内控制通胀。控制通胀的目的是来打击国内左翼激进工会势力。</li><li>长周期十年国债收益率大方向可以测，由人口结构预测。</li><li>以前08年也大量印钞票但没有使通胀大幅上升，因为钱没有进老百姓口袋。</li><li>这次疫情很多资金直接进入了老百姓口袋，零售急速上升，供给跟不上，直接导致通胀。</li><li>美国上升，其他地方也会上升，我们也会，只是暂时还没传导到下游消费。</li><li>每天嚷嚷的缩表只是象征性的，不断印钱才是常态。</li><li>主流流氓国家国债总量指数上升（尽管美国有扩有缩）。</li><li>央行独立性不能迷信。</li><li><strong>明年一月份，美联储大概率换人，鲍威尔不连任</strong><ul><li>未来两个月加息缩表会比较严重</li><li>但是明年二月开始政策会继续宽松，原因因为疫情还不是个头</li></ul></li></ul><h2 id="3-中美关系未来走向"><a href="#3-中美关系未来走向" class="headerlink" title="3. 中美关系未来走向"></a>3. 中美关系未来走向</h2><ul><li>目前是暴跌之后的小反弹，可能四年。<ul><li>高盛前总裁桑顿去新疆参观。</li><li>戴琦说不脱钩，要重新挂钩，务实坦率。</li></ul></li><li>中国应对美国策略，合作进化，tit for tat新型大国关系。</li><li>中美安全领域互信重建困难。</li><li>近期拜登对华态度软化（背景是拜登上台七个月民意死亡交叉）<ul><li>过去四年一群成人哄老小孩玩，现在一个老头带大家玩</li><li>现在拜登懂政治且固执，手段足够，且拜登中期选举必输。</li></ul></li><li>目前美国政治形式拜登参议院50+1对50，众议院民主党领先8票。<ul><li>中期选举众议院执政党一定会丢掉一些票，平均丢27.5，众议员管钱，丢掉众议院意味着大规模财政开支基建计划全部完蛋。</li><li>大概率参议院众议院全丢，所以真正有效执政只有是前两年。</li><li>拜登意识到这一点已经放弃连任幻想，按照自己的想法实施，需要立自己的历史遗产。</li></ul></li><li>三年机会之窗，新型大国关系，平等不冲突<ul><li>现在中国也硬了，现在有机会窗口</li><li>民主党2024可能出大事，共和党重来，中美关系暴跌</li></ul></li></ul><h2 id="4-海南自贸港建设的前瞻和思考"><a href="#4-海南自贸港建设的前瞻和思考" class="headerlink" title="4. 海南自贸港建设的前瞻和思考"></a>4. 海南自贸港建设的前瞻和思考</h2><ul><li>冻结的人与人交流即将放开，海南可以争取放开的优先权，外国人进入中国的缓冲通道。</li><li>争取建立多个领馆。</li><li>高端服务业来海南。</li><li>推进金融开放。</li><li>吃海外人员回流福利。</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;翟东升 2021-10-28 于海南讲座。&lt;/p&gt;</summary>
    
    
    
    <category term="Economy &amp; Finance" scheme="https://blog.superui.cc/categories/economy-finance/"/>
    
    
    <category term="翟东升" scheme="https://blog.superui.cc/tags/%E7%BF%9F%E4%B8%9C%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>距离矩阵</title>
    <link href="https://blog.superui.cc/machine-learning/distance-matrix/"/>
    <id>https://blog.superui.cc/machine-learning/distance-matrix/</id>
    <published>2021-11-05T08:48:00.000Z</published>
    <updated>2021-11-05T08:48:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>在看 k-center 的时候发现自己对其距离矩阵的计算不是很清楚，于是在此记录。</p><span id="more"></span><h2 id="距离矩阵的计算及-Python-实现"><a href="#距离矩阵的计算及-Python-实现" class="headerlink" title="距离矩阵的计算及 Python 实现"></a>距离矩阵的计算及 Python 实现</h2><p>给定 $m\times n$ 矩阵 $X$, $X = [x_1, x_2,…,x_n]$，这里第 $i$ 列向量 $x_i$ 是 $m$ 维向量，任务是计算出一个 $n\times n$ 矩阵，使得：$D_{ij}=||x_i-x_j||^2$。</p><p>具体的，$D_{ij} = (x_i - x_j)^T(x_i-x_j)=x^T_ix_i-2x^T_ix_j+x^T_jx_j$。</p><p>用 Gram Matrix 表示，$D_{ij}=G_{ii}-2G_{ij}+G_{jj}$。</p><p>放在矩阵的尺度来看，$D = H + K -2G$。其中，$H_{ij} = G_{ii}, K_{ij} = G_{jj}$。</p><p>根据最后一个式子，计算的时候可以避免循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_dist_matrix</span>(<span class="params">X</span>):</span><br><span class="line">  m,n = X.shape</span><br><span class="line">  G = np.dot(X.T, X)</span><br><span class="line">  H = np.tile(np.diag(G), (n, <span class="number">1</span>)) <span class="comment"># Construct an array by repeating the number of times.</span></span><br><span class="line">  <span class="keyword">return</span> H + H.T - <span class="number">2</span>*G</span><br></pre></td></tr></table></figure><p>Reference:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/21341296">斯坦福CS231N课程笔记（三）-距离矩阵的计算方法</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;在看 k-center 的时候发现自己对其距离矩阵的计算不是很清楚，于是在此记录。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://blog.superui.cc/categories/Machine-Learning/"/>
    
    
    <category term="machine-learning" scheme="https://blog.superui.cc/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>原则读书笔记</title>
    <link href="https://blog.superui.cc/reading-note/principles/"/>
    <id>https://blog.superui.cc/reading-note/principles/</id>
    <published>2021-10-21T05:00:00.000Z</published>
    <updated>2021-10-21T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><p>《原则》  Ray Dalio<span id="more"></span></p><h2 id="极简简介"><a href="#极简简介" class="headerlink" title="极简简介"></a>极简简介</h2><p>桥水基金创始人 Ray Dalio 在本书中向我们介绍了其多年的人生经历，并由此引出他的主要观点——原则的建立和使用。书中极其详细的分条陈述了 Ray 的生活原则和工作原则。在展示原则之外，Ray 希望本书促使读者以最合适的方式发现改进反思自己的原则，这将有助于做出更好的决定，并让别人更好理解你。</p><h2 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h2><h3 id="极简评价"><a href="#极简评价" class="headerlink" title="极简评价"></a>极简评价</h3><p>这本书断断续续看了一个多月吧。是冲着 Ray 的名气买的，读完之后确实受用。受限于目前的阅历和社会分工，其实很多要点暂时还离我比较遥远，以后一定是会重读此书的。</p><ol><li>个人觉得这本书最厉害的一点不是给我们展现 Ray 的厉害的原则，而是在对他的原则进行阐述和解释过程中，教导我们原则的重要性以及如何构建自己的原则，这是最有价值的地方。</li><li>这本书更像是一本人生说明书或者指导手册，以一本工具书的形式，提出了大道理，也提出了很多解决方案。</li><li>我认为处于社会不同位置的人都能从此书中学到不少东西。首先是作为一个“自然人”对自己的管理，要用原则规范提升自己。其次是作为一个“社会人”在工作岗位中作为管理者或者被管理者，如何基于原则高效的沟通和行动。</li><li>本书也在很多阐述的地方不经意的提起一些很常见的思维误区，有利于大家反思自己的思维方式。</li><li>这本书不仅是 Ray 的人生准则，其实也包含很多他相信的“道理”，需要批判看待。</li></ol><h3 id="自己的感想"><a href="#自己的感想" class="headerlink" title="自己的感想"></a>自己的感想</h3><ol><li>原则构建<ol><li>要清楚的知道自己的原则。</li><li>清楚原则还不够，需要“知行合一”。如果存在矛盾，则需要记录，并改进原则。</li></ol></li><li>个人成长<ol><li>使自己“可信”，首先要把事情做成功。</li><li>不固执己见，客观看待自己以及其他人，否则会一次次的栽在自己或其他人的弱点上。</li><li>历史在不停地重现，只是可能不重现在你的身上。性价比高的做法是从他人身上学习，这就需要头脑开放。</li></ol></li><li>对待问题<ol><li>对问题准确的定义十分重要。</li><li>不能容忍问题，否则前功尽弃。</li><li>在团队工作中，Ray 有一个非常好的诊断问题的流程值得学习。包括但不限于问题是哪来的，有多严重，谁该负责，如何改进，甚至包括对问题的诊断应该进行到什么程度。我觉得这一部分其实可以单独写一篇博客来学习一下。</li></ol></li><li>团队管理<ol><li>在团队管理中，很需要对成员开放式思考进行构建。</li><li>分清建议和批评的区别。</li></ol></li></ol><h3 id="有趣的发现"><a href="#有趣的发现" class="headerlink" title="有趣的发现"></a>有趣的发现</h3><ol><li>历史真的是在不断重复。<ul><li>例如1982年墨西哥违约，债务危机，美联储增加货币供给，美国大通胀。但是经济没有崩溃，通胀率下降同时经济增长加速。这是因为资金撤出借债国，回流美国，美元升值，通缩压力。所以美联储可以在不加剧通胀的情况下降息。（我指的是资金回流美国这一点重复，例如2020新冠疫情。）</li></ul></li><li>Ray对王岐山有着极高的评价，两人似乎很熟，有空可以八卦一下。</li></ol><hr><h1 id="Ray-的原则"><a href="#Ray-的原则" class="headerlink" title="Ray 的原则"></a>Ray 的原则</h1><h3 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h3><ol><li>独立思考并决定：你想要什么？事实是什么？面对事实，你如何实现自己的愿望？请保持谦逊和心胸开阔，以便你能动用自己的最佳思维。</li><li>以可信度加权的方式做决定。</li><li>遵照原则做事。</li><li>以系统化的方式来做决策。考察影响你的那些事物的规律，从而理解其背后的因果关系，并学习有效应对这些事务的原则。</li></ol><h3 id="生活原则"><a href="#生活原则" class="headerlink" title="生活原则"></a>生活原则</h3><p>此处仅记录一些相对较大的条目：</p><ul><li><strong>拥抱现实，应对现实：</strong>  做一个超级现实的人； 真相（对现实的准确理解）是任何良好结果的根本依据； 做到头脑极度开放、极度透明； 观察自然，学习现实规律； 进化是生命最大的成就和回报； 理解自然提供的现实教训； 痛苦+反思=进步； 考虑后续与再后续的结果； 接受结果； 从更高的层次俯视机器。</li><li><strong>用五步流程实现你的人生愿望：</strong>  有明确的目标； 找出问题，并且不容忍问题； 诊断问题，找到问题的根源； 规划方案； 坚定的从头至尾执行方案； 谨记：如果你找到了解决方案，弱点是不重要的； 理解你和其他人的“意境地图”与谦逊性。</li><li><strong>做到头脑极度开放：</strong>  理解你的两大障碍； 奉行头脑极度开放； 领会并感激：深思熟虑的意见分歧； 和可信的、愿意表达分歧的人一起审视你的观点； 识别你应当注意的头脑封闭和头脑开放的不同迹象； 理解你如何做到头脑极度开放。</li><li><strong>理解人与人大不相同：</strong>  明白你与其他人的思维方式能带来的力量； 有意义的工作和有意义的人际关系不仅是我们做出的美好选择，而且是我们天生的生理需求； 理解大脑里的主要斗争，以及如何控制这些斗争； 认识自己和他人的特性； 无论你要实现什么目标，让合适的人各司其职以支持你的目标是成功的关键。</li><li><strong>学习如何有效决策：</strong>  要认识到：影响好决策的最大威胁是有害的情绪；决策是一个先了解后决定的两步流程； 综合分析眼前的形势； 综合分析变化中的形势； 高效地综合考虑各个层次； 综合分析现实、理解如何行动的最好工具是逻辑、理性和常识； 根据预期价值计算做决策； 比较更多信息带来的价值和不做决定造成的成本，决定优先顺序； 简化； 使用原则； 对你的决策进行可信度加权； 把你的原则转换成算法，让计算机和你一起决策； 在深刻理解人工智能之前不要过度信赖它。</li></ul><hr><h1 id="按节讨论-摘录"><a href="#按节讨论-摘录" class="headerlink" title="按节讨论/摘录"></a>按节讨论/摘录</h1><p>以下是大篇幅的摘抄，取自文章中的三个大章节。不能保证重要信息全记录。摘抄的原因是看到这些话的时候有一星半点的赞同或感触。此处的摘录比较糙，以后有空重读的话可以精炼消化一下。</p><h3 id="1-我的历程"><a href="#1-我的历程" class="headerlink" title="1. 我的历程"></a>1. 我的历程</h3><ul><li>不管我一生中取得了多大的成功，其主要原因都不是我知道多少事情，而是我知道在无知的情况下自己应该怎么做。</li><li>不幸的是，大多数的人并不能清楚地解释他们的原则。</li><li>尽管使用他人的原则不一定是一件坏事，但不假思索地采用他人的原则有可能将你置于风险之中。</li><li>“正确的失败”：痛苦的失败中获得教训。“错误的失败”：因为失败而被踢出局。</li><li>当政府决策者向你承诺他们不会允许货币贬值发生时，不要相信他们。</li><li>拥有有意义的工作和人际关系要比赚钱好得多。有意义的工作是一项我能全身心投入的使命；有意义的人际关系是指我既深深的关心对方，对方也深深的关心我。</li><li>把赚钱作为你的目标是没有意义的，因为金钱并没有固定的价值，金钱的价值来自他能买到的东西，但是金钱并不能买到一切。</li><li>要一个孩子是我迄今做过的最艰难的决定，因为当时的我显然不知道养孩子将是一种个什么样的经历，而且这个决定是不可撤回的。但事实证明这是我做出的最好的决定。</li><li>每当出现收益率曲线倒挂，对冲通胀的资产价格都会下跌，经济下滑。</li><li>以一国货币计价的债务，可以在该国政府的帮助下成功重组，而且在各国央行同时提供刺激时，通胀和通缩能够互相对冲。</li><li>我学到了一种很好的恐惧犯错的意识，这把我的思维定式从认为“我是对的”变成了问自己“我怎么知道我是对的”。</li><li>使人们相互对立的观点公开化，并对其进行分析，让我对人们的思考方式有了更多的了解。通常我们遵循我们的自然秉性做事时，考虑不到自身的弱点，走向失败，成功的人改变他们的做法，使他们能够继续利用优势，并弥补自身的不足，而不成功的人则不会这样做。</li><li>只有当你能承认甚至接受自身弱点是，你才能做出对自身有益的改变。</li><li>面对你都需要胆识看起来相互矛盾的东西时，耐心地做出选择。</li><li>“靠水晶球谋生的人注定要吃碎在地上的玻璃”：最重要的事不是预知未来，而是知道在每一个时间点上如何针对可获得的信息做出合理的回应。</li><li>确立一个“风险中性”的基准仓位，在进行慎重的冒险时偏离这个仓位。</li><li>我从来不愿仅仅因为投资产品会买的好就去设计他们，尤其是常规投资产品，我想要的只是进行市场交易，建立人际关系，设身处地地为我们的客户服务。</li><li>成熟意味着你可以放弃一些好的选择，从而追求更好的选择。</li><li>所有了不起的投资者和投资策略都是有弱点的，在弱点呈现时就对其失去信心是一种常见的错误，就像在其有效时对其过于迷恋一样。</li><li>拥有吧事情探究明白的能力，要比拥有某件事的具体知识更重要。</li><li>追求商业卓越和追求个人价值的实现，不一定是相互排斥的，而是可以相辅相成的。</li><li>一个管理者能够实现的最大成功就是能够阻止他人在没有你的情况下把事情做好。次好的情况是你自己能把事情做好。最糟糕的事连你自己都做不好。</li><li>我问他在火箭学方面有没有背景，他说没有。“我刚开始读这方面的书。”他说。这就是塑造者典型的思考和行为模式。</li><li>王岐山：“有能力的人居安思危。安然无忧的是愚人。假如冲突能在变得尖锐之前被解决的话，世界上就不会有英雄了。”</li><li>当我就权力制衡这个问题询问他时，他以尤里乌斯·凯撒推翻罗马元老院和共和国为例，说明确保任何人的权利都不能凌驾于制度之上是多么重要。</li><li>发现自己的性格，过与性格相适应的生活，才是最幸福的。</li></ul><h3 id="2-人生原则章节"><a href="#2-人生原则章节" class="headerlink" title="2. 人生原则章节"></a>2. 人生原则章节</h3><ul><li>创造伟大事物的人不是空想者，而是彻底地扎根于现实。</li><li>不要固守你对事物“应该”是什么样的看法，这将使你无法了解真实的情况。</li><li>通过快速试错以适应现实是无价的。</li><li>你的未来取决于你的视角。你在一生中取得什么样的成就，取决于你如何看待事物，以及你关心什么人、什么东西（你的家庭、社区、国家、人类、整个生态系统）。</li><li>没有痛苦就没有收获。</li><li>大多数人在痛苦时不愿反思，而一旦痛苦消失他们的注意力就会转移，所以他们难以通过反思得到教益。</li><li>不管在生活中遇到什么情况，如果你能负起责任，进行良好的决策，而不是抱怨你无法控制的东西，你将更有可能成功并找到幸福。</li><li>对人来说，最难做的事情之一是客观地在自身所处环境（即机器）中看待自身，从而成为机器的设计者和管理者。</li><li>大部分人犯下的最大错误是不客观看待自己以及其他人，这导致他们一次次的栽在自己或其他人的弱点上。</li><li>在你不擅长的领域请教擅长的其他人，这是一个你无论如何都应该培养的出色技能，这将帮你建立安全护栏，避免自己做错事。</li><li>不要混淆你的愿望和事实。</li><li>不要为自身形象而担心，只需要关心能不能实现你的目标。</li><li>不要把不好的结果归咎于任何人，从自己身上找原因。</li><li>5个步骤：目标、问题、诊断、方案、践行。你要成功就必须做好每一步，而且按照顺序一步一步来。这个过程是层层递进的：认真做好每一步，你将获得必须的信息，以便进行到下一步并将其做好。</li><li>你只需要知道什么时候需要这些技能，你能从哪里学到这些技能。</li><li>尽管你几乎可以得到你想要的任何东西，但不可能得到你想要的所有东西。</li><li>不要混淆目标和欲望（不要拿欲望当目标）。</li><li>不要把成功的装饰误认为成功本身。</li><li>在逆境中，你的目标应该是守住自己的成绩，尽量减少损失，或者直面不可挽回的损失。</li><li>承认弱点并不是像弱点投降，而是克服弱点的第一步。</li><li>要精准的找到问题所在。如果问题的原因是某种固有的弱点，你也许需要寻求他人的帮助，或者改变你扮演的角色。</li><li>不要把问题的某个原因误认为问题本身。</li><li>容忍问题和找不到问题一样。只要你没有战胜问题的意志，你就处于毫无希望的境地。你必须养成一种对任何性质的恶习都绝不容忍的习惯，无论其是重是轻</li><li>把你的方案写下来，让所有人都能看到，并对照方案执行。</li><li>建立清晰的衡量评估标准来确保你在严格执行方案。理想的做法是让其他人客观评估并报告你的进度。</li><li>每个人都至少有一个最大的弱点阻碍其成功，找到你的这个弱点并处理它。</li><li>成功有两条路：（1）自己拥有成功所需的要素，（2）从其他人那里得到成功所需的要素。</li><li>要有效行事，你就绝不能允许“想要自己正确”的需求压倒“找出真相”的需求。</li><li>很自然，人们无法理解自己看不到的东西。</li><li>当你住处某个人的心里弱点时，对方的反应通常像你指出他的身体缺陷一样感到不舒服。</li><li>出现意见分歧的各方通常始终坚信自己是对的，而且往往以彼此发怒而告终。</li><li>亚里士多德把悲剧定义为：人的致命缺陷导致的可怕结果。在我看来，自我意识和思维盲点这两大障碍就是人的致命缺陷。</li><li>听听其他人的观点并加以考虑，绝不会削弱你独立思考、自主决策的自由，只会让你在决策时有更宽广的视角。</li><li>要做到头脑开放，你必须高度接受自己错了的可能性，可以鼓励其他人告诉你错在哪里。</li><li>谨记，你是在寻找最好的答案，而不是你自己能得出的最好的答案。最好的答案不一定是你想出来的。</li><li>我定义的“可信”的人有两个特征：曾反复的在相关领域成功找到答案（三次），在被问责的情况下能对自己的观点做出很好的解释。</li><li>当两个人的观点截然相反时，很有可能一个人是错的。搞明白是不是你错了，对你有好处。深思熟虑的意见分歧中，你的目标并不是让对方相信你是对的，而是弄明白谁是对的，并决定应该怎么做。</li><li>你应该考虑和思索各种互相冲突的可能性，也应根据了解到的情况，随时迅速地调整自己的想法，接受可能正确的东西。一种检验你做的好不好的方式是，把和你有分歧的人的观点，向对方复述一遍，瑞过他觉得你服输的对，就说明你做的很好。</li><li>很多人都会和你产生分歧，但你不应该考虑所有人的观点。跟任何人都头脑开放不一定有好处，你应该花时间和你能找到的最可信的人探讨观点。</li><li>头脑封闭的人<ul><li>不喜欢看到自己的观点被挑战。他们通常会因无法说服对方而沮丧，而不是好奇对方为什么看法不同。</li><li>喜欢做陈述而不是提问</li><li>更关心是否被理解，而不是理解其他人</li><li>经常说“我可能错了，但这是我的观点”，暗示自己是开明的</li><li>阻挠他人发言</li><li>难以同时持有两种想法，使自己的观点独大</li><li>缺乏深刻的谦逊意识</li></ul></li><li>头脑开放的人<ul><li>更想了解为什么会出现分歧</li><li>真诚地相信自己可能是错的，提出真诚的问题</li><li>经常觉得有必要从对方的视角看待事物</li><li>知道何时做陈述，何时提问</li><li>喜欢倾听而不是发言，鼓励其他人表达观点</li><li>考虑其他人观点的同时保留自己深入思考的能力</li><li>时刻在心底担忧自己是错的</li></ul></li><li>假如你是一个头脑封闭的人，又在自己有盲点的领域形成了一种观点，结果可能是致命的。</li><li>重视证据，并鼓励其他人也这么做。</li><li>知道什么时候应当停止为自己的观点辩护，信任自己的决策程序。</li><li>如果你不了解人（包括你自己）的特性就对他们抱有期待，你肯定会遇到麻烦。</li><li>当我的潜意识给我想法和提示时，我不是马上按照其行动，而是先用我的理性意识去分析他们。</li><li>你能做的最重要的决定之一是决定问谁。</li><li>不要听到什么信什么，要区分事实和观点。</li><li>所有东西都是放在眼前看更大，所以你应该跳出去以看到全局，有时候可以过一段时间再做决定。</li><li>“当你问一个东西对不对而对方告诉你并不完全对时，那它大致是对的。”</li><li>不要做完美主义者。完美主义者花太多时间关注边缘性的微小因素，影响对重大因素的考虑。</li><li>用“基线以上”和“基线以下”来确定谈话位于哪一层。当一段分析混乱，令人迷惑时，通常是因为谈话者限于基线以下的细节之中，而没有重新把细节与要点联系起来。</li><li>知道什么之后不要去押注，和知道什么注值得押同样重要。</li><li>先把你的“必做之事”做完，再做你的“想做之事”。</li></ul><h2 id="3-工作原则章节"><a href="#3-工作原则章节" class="headerlink" title="3. 工作原则章节"></a>3. 工作原则章节</h2><ul><li>创意择优：1. 开诚布公的亮出你的观点。2. 针对分歧认真讨论。3. 遵循所形成的共识，消除过去的分歧。</li><li>为人要正直，也要求他人保持正直</li><li>若不想当面议论别人，背地里也不要说，要批评别人就当方面指出来。</li><li>大多数人做工作都希望出最少的里而赚尽可能多的钱。</li><li>学校里学习最好的学生可能往往是那些最不善于从错误里学习的人，因为他们已经习惯把做错题当成失败的代名词，而不是把犯错看成学习的机会。</li><li>不要纠结于一时的成败，要放眼于达成目标。不要纠结于“埋怨”还是“赞美”，而要专注于“准确”还是“不准确”。</li><li>没有人能客观的看待自己。</li><li>问题一般源自两个主要原因：简单的误解和根本上存在分歧。求取同步就是以开放而自信的心态修正双方立场的过程。</li><li>知道怎样求取共识和掌控分歧<ul><li>把可能的分歧摆到桌面上</li><li>区别苍白的抱怨和有助于改进工作的诉求</li><li>要记住每个故事都有另一面</li></ul></li><li>保持开放的心态，同时也要坚定果断<ul><li>区别心态开放和封闭的人</li><li>远离心态封闭的人，不管他们知道多少，心态封闭的人都会浪费你的世界。如果你必须与他们打交道，要注意除非他们变得开明，否则无任何裨益。</li><li>提防那些羞于承认自己无所不知的人。他们可能更关注外在形象，而不是达成目标。</li><li>确保工作负责人以开放的心态对待问题和他人的意见。</li><li>意识到求取共识是双向的责任。通常沟通困难在于人们的思维方式不一样。<ul><li>有一些简单的技巧会很有用，比如重复以便你刚听到的别人的观点，确保你理解正确。</li><li>假设你自己或者是没有沟通好，或是没听清，为不实先去责怪对方。要吸收自己沟通不理的教训，避免再犯。</li></ul></li><li>实质重于形式：问题重于沟通方式。</li><li>自己要通情达理，也期待别人通情达理。</li><li>其建议、提问题与批评是不一样的，别混淆<ul><li>提建议并未下结论说有错误，只是想确保考虑了风险，有没有疏忽（并不是真的忽略）</li><li>有人把建设性问题当成职责，反弹强烈，这是不对的。</li></ul></li></ul></li><li>如果由你主持会议，应把握好会话<ul><li>明确主持人和会议的服务对象，如果没有明确的主持人，可能会陷入丧失方向和低效的境地。</li><li>表达清晰，以免造成困惑。</li><li>根据目标和优先次序决定采用什么样的沟通方式。</li><li>谨防“跑题”，列出议程让大家看到进展。</li><li>坚持对话的逻辑性。</li><li>不要因集体决策而丧失个人责任。对个人职责的分派要十分明确。</li><li>你必须让人用两分钟不受打扰地解释自己观点，再插话表达自己意见。</li><li>当心讲起话来不容置疑的“快嘴王”，你的责任是讲清楚事情，有一点没讲清楚都不要继续往下降。作为主持人可以说“抱歉我比较迟钝，希望你慢点说”</li><li>让对话慎始善终，进行总结，结束讨论。同时，人们不必对任何事情都意见一致。</li><li>运用沟通手段，分出优先次序。</li></ul></li><li>3-5人的效率高于20人。边际效益递减。</li><li>珍惜志同道合者，既然有人在你最重要的方面价值观相同，也与你有实践价值观的相同做法，就要确保与这些人为伍。</li><li>如果你发现自己无法调和相互间的主要分歧—尤其是价值观层面的—要考虑是否值得维持这种关系。</li><li>最佳决策应该是创意择优中按观点的可信度高低得出来的。有可信度的观点来自多次成功解决了相关问题的人，能够有逻辑地解释结论背后因果关系的人。</li><li>如果你自己无法成功完成某件事，就不要想着知道别人如何完成。</li><li>关注可信度最高，与你观点不一致的人，尽量理解其推理过程。<ul><li>若某人并无经验，但是所讲道理符合逻辑且可以经受压力测试，一定要试一试。</li><li>关注推理过程而非结论。</li><li>没经验的人也不乏好点子，不会限制在过去的套路。</li></ul></li><li>考虑你要扮演老师、学生、同事中的哪个角色？说教、提问还是辩论？<ul><li>学生理解老师比老师理解学生更重要。</li></ul></li><li>要了解人们提出意见的过程和逻辑<ul><li>要仔细考虑向谁提问，问可信度强，准备好的人。如果自己可信度不强，不要分享自己的观点。</li><li>让每个人都可以肆意评论其他人的观点，此举低效且浪费时间。</li><li>梳理员工工作记录。</li></ul></li><li>每个人都有权利和义务去设法了解重要的事情。</li><li>要关注决策机制是否公允，而非是否如你自己所愿。</li><li>相互达成协议时不能忽略原则。</li><li>不要吧发牢骚、提建议、公开辩论的权力与决策权混淆</li><li>不要对重大分歧不闻不问<ul><li>别被小事烦扰</li><li>不要被分歧束缚：提交上级、或者投票</li></ul></li><li>一旦做出决定，所有人必须服从，即便有不同意见。</li><li>在一家健康的机构中，应该是员工与低层次的自我进行竞争，而不是员工与员工互相竞争。</li><li>你最重要的决策是选好工作的责任人<ul><li>最重要的责任人是在高层负责订立目标、规划成果和组织实施的人</li><li>负最终责任的人应是对行为后果承担责任的人。</li><li>确保每个人都有上级领导，要有人对他问责。</li></ul></li><li>学习成绩不能充分证明这个人是否具备你想要的价值观和能力<ul><li>评估常识、眼界、创造力、决事能力，学习成绩价值有限。</li></ul></li><li>警惕不切实际的理想主义者</li><li>考虑薪酬时，要提供稳定性，也要让人看到机会<ul><li>依人发薪，而不是依工作岗位发薪</li><li>想着把蛋糕做大，而不是给自己把蛋糕切大。</li></ul></li><li>准确评价人，不做好好先生。</li><li>对人的观察不要讳莫如深。开诚布公的考察他们。</li><li>评估人时，你可能犯的两个最大错误是：对自己的评估过于自信，无法取得共识。</li><li>换岗是为了人尽其才，有利于整个团队。</li><li>不断把结果和你的目标进行对照。制定量化评价工具。</li><li>应对每个问题的手段都要服务于两种目的：让你与目标更为接近，能够对机器进行培训和测试。</li><li>如果出现问题，要在两个层面进行讨论：机器层面为什么，案例层面怎么办。</li><li>管理者必须确保自己负责的领域运转有效。他可以通过以下方式：把员工管理好；或者下沉去做本不该自己做但下属做不好的工作；把管理不好的领域提交给上级管理。</li><li>出售管理者的标志是他不必亲自做任何事。管理者应视自己陷入细枝末节为不良信号。</li><li>了解员工及其工作的动力，因为人是你最重要的资源。</li><li>明确职责。记住谁付什么责任，防止角色错位。如果问题出乎你的意料，可能是因为你远离了你的下属和工作流程或者你对下属和留存可能导致的不同后果缺乏足够认识。</li><li>让问责过程透明，而非私下问责。同时欢迎别人问着你，因为没有人能客观看待自己。</li><li>像公司的拥有者那样思考，要求你的同事也这样做。</li><li>不要担心你的员工是不是喜欢你，不要让他们告诉你如何做事，你要操心的是尽可能的做出最佳决策，因为不管你做什么很多人都会说你做得不对。</li><li>不要发号施令让别人服从你，要努力为人所理解，并理解他人，以达成共识。</li><li>当心那些混淆目标和任务的人，因为如果他们分不清楚就不能信任他们并给他们委派职责。</li><li>在无法充分完成时，这时将问题提交给上级解决，把问题提交给上级并不意味着失败而是一种责任。</li><li>在分析问题时要非常具体不要泛泛而谈，不要用我们他们这种不指名道姓的说法，掩盖个人责任。每个人都必须有一位有可信度的热情，高标准的人来监督。</li><li>每个人都必须有一位有可信度的，奉行高标准的人来监督。</li><li>不要仅盯着你自己的工作，还要关注如果你不在场工作会如何展开？</li><li>如果某些职位不是全职的，且需要高度专业化的知识，我宁愿交给顾问或者外部人。</li><li>描绘一幅金字塔形的组织架构，图任何两条有塔顶向下连接塔底的线不应产生交叉。遇到跨部门或附属部门的问题是让金字塔交汇点上的人处理。 </li><li>保持适当的监控让谎言没有可乘之机。</li><li>要不断思考如何产生以小搏大的杠杆效应，我一般在工作中运用50:1的杠杆，意思是说，每当我用一个小时与下属讨论工作，他们都要花大约50个小时的推进相关项目。</li><li>几乎做每件事所花费的时间和资金都比你预期的要多。</li><li>给人员分配任务是最好把各项任务记在检查清单上。完成的任务划掉，这可以做任务的提醒也可以做任务的确认，但是每个人不是只是完成在检查清单上的任务。</li><li>为了促进真正的行为改变，必须内化学习或养成习惯。</li><li>把原则阐述清楚，运用各种工具和行为准则来推进实施，形成信任公平的氛围，使任何结论都可以通过跟踪其背后的逻辑和数据来加以评估。</li><li>为了取得成功，所有机构都必须建立制衡机制。要确保公司里没有任何人比体系更强大，也没有任何人重要到不可替代。</li><li>在所有决策方法中，构建创意择优是最佳的方法。让创意择优发挥作用，人们需要做三件事：坦承自己最诚实的想法；让大家公开讨论理性的表达分歧，以便大家进行高质量的辩论，拓展思路，尽量形成最优的集体决策；用创意择优来处理所有不同意见。</li></ul>]]></content>
    
    
    <summary type="html">&lt;!-- omit in toc --&gt;
&lt;p&gt;《原则》  Ray Dalio</summary>
    
    
    
    <category term="Reading Note" scheme="https://blog.superui.cc/categories/reading-note/"/>
    
    
    <category term="Ray-Dalio" scheme="https://blog.superui.cc/tags/Ray-Dalio/"/>
    
  </entry>
  
  <entry>
    <title>约束满足问题（CSPs）</title>
    <link href="https://blog.superui.cc/artificial-intelligence/ai-csp/"/>
    <id>https://blog.superui.cc/artificial-intelligence/ai-csp/</id>
    <published>2021-10-19T07:50:00.000Z</published>
    <updated>2021-10-19T07:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能中的约束满足问题（Constraint Satisfaction Problems 问题）学习笔记。</p><span id="more"></span><h1 id="约束满足问题"><a href="#约束满足问题" class="headerlink" title="约束满足问题"></a>约束满足问题</h1><p>约束满足问题的目标是在一定的约束下，寻找符合条件的状态。这种问题在生活中比较常见，以大学排课为例，已知教授的授课可以授课的时间，寻求满足所有教授时间的排课课程表。常见的一些约束满足问题有：</p><ul><li>八皇后问题</li><li>图着色问题</li><li>填字游戏</li><li>数独</li></ul><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>CSPs 包含以下三个要素：</p><ul><li>A set of variables（变量）, $X={X_{1},\ldots ,X_{n}}$</li><li>A set of domains （值域） for each variable: $D={D_{1},\ldots ,D_{n}}$</li><li>A set of constraints $C={C_{1},\ldots ,C_{m}}$ （限制条件） that specify allowable combinations of values. Every constraint $C_{j}\in C$ is in turn a pair $\langle t_{j},R_{j}\rangle$ , where $t_{j}\subset X$ is a subset of k variables and $R_{j}$ is a k-ary relation (among k variables) on the corresponding subset of domains $D_{j}$.</li></ul><p>问题的状态由对部分或者全部变量的定值（assignment）来确定：</p><ul><li>如果定值不违反任何的限制条件，我们说他是无矛盾的（consistent）</li><li>如果定值包含了所有的变数，我们说他是完备的（complete）</li><li>如果定值是无矛盾的且完备的，我们说这个定值是一个解（solution），这样的定值就是 CSP 的解。</li></ul><p>一个图着色问题的例子：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-csp/map-color.png" class=""></div><p>一个八皇后问题的例子：</p><div style="width:80%; margin:auto"><img src="/artificial-intelligence/ai-csp/eight-queen.png" class=""></div><p>一般来说 CSPs 使用的都是绝对约束，如果是非绝对的约束（偏好性），这样的问题称为约束优化问题（COP），在此不做讨论。</p><h1 id="求解-CSPs"><a href="#求解-CSPs" class="headerlink" title="求解 CSPs"></a>求解 CSPs</h1><h2 id="CSPs-形式化的优点"><a href="#CSPs-形式化的优点" class="headerlink" title="CSPs 形式化的优点"></a>CSPs 形式化的优点</h2><ol><li>快速消减庞大的搜索空间</li><li>发现某部分不是解迅速丢弃，直观看到哪一部分变量赋值违反约束。</li><li>CSP 具有可交换性（commutative）</li></ol><h2 id="CSPs-中的局部相容性（consistency）"><a href="#CSPs-中的局部相容性（consistency）" class="headerlink" title="CSPs 中的局部相容性（consistency）"></a>CSPs 中的局部相容性（consistency）</h2><p>在 CSPs 中，算法可以<strong>搜索</strong>，也可以做一种称作约束传播的<strong>推理</strong>。推理的目的是用约束减小一个变量的合法取值范围。可以把推理作为搜索前的预处理步骤。核心思想是增强局部相容性，使不相容的结点取值被删除。</p><ul><li>节点相容（Node-consistency）：来自节点本身的一元约束</li><li>弧相容（Arc-consistency）：某变量所有取值满足该变量所有的二元约束。<ul><li>最流行的算法是 AC-3，维护一个弧相容队列。<ul><li>从队列弹出一条弧，使其一个节点弧相容，如果其值域无变化，则处理下一条弧。</li><li>如果其值域发生变化，那么每个指向这个节点的弧必须重新插入队列准备检验。</li></ul></li></ul></li><li>路径相容（Path-consistency）：通过观察变量得到隐式约束并以此来加强二元约束。<ul><li>比如说有三个连接节点，却只有两种颜色。</li><li>所有的 n-ary 约束都可以转换为 binary 约束。</li></ul></li></ul><h2 id="具体解法：回溯搜索"><a href="#具体解法：回溯搜索" class="headerlink" title="具体解法：回溯搜索"></a>具体解法：回溯搜索</h2><p>仍然使用搜索来求解，一般来说使用 Backtracking Search（BTS）回溯搜索。用于深度优先之中，每次为一个变量选择一个赋值，当没有合法的值时就回溯。由于可交换性，我们只用搜索组合而不是排列，所以叶节点个数至多为$d^n$个（不回溯的情况）。</p><p>在回溯搜索中，也需要考虑如下问题来对搜索进行改进：</p><ul><li>下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？</li><li>每步搜索应该进行怎样的推理？是否能预见失败？</li><li>当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？</li></ul><h3 id="1-下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？"><a href="#1-下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？" class="headerlink" title="1. 下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？"></a>1. 下一步给哪个变量赋值？对于所选变量，选用怎样的赋值顺序？</h3><p>选取变量：</p><ul><li>最少剩余值启发式 Minimum Remaining Value (MRV)，选择合法取值最少的变量赋值。这样通过早期有效剪枝有助于最小化节点数。</li><li>对于第一个节点而言，最小剩余值相同，应该选用度启发式，选择与其他未赋值变量约束最多的变量来试图降低未来的分支因子。</li></ul><p>选取赋值：</p><ul><li>最小约束值 Least Constraining Value (LCV)，试图为剩余变量赋值留下最大的空间。这里只需要找到一个解，所以优先考虑最可能的值。</li></ul><h3 id="2-每步搜索应该进行怎样的推理？是否能预见失败？"><a href="#2-每步搜索应该进行怎样的推理？是否能预见失败？" class="headerlink" title="2. 每步搜索应该进行怎样的推理？是否能预见失败？"></a>2. 每步搜索应该进行怎样的推理？是否能预见失败？</h3><p>搜索和推理应当交替进行。推理的目的是减小值域，减小搜索空间。当我们决定给某个变量某个值时，都有机会推理其邻接变量的值域空间。</p><ul><li>最简单的形式是向前检验 Forward Checking（FC）。跟踪维护所有为选取变量的可能取值，当任何一个变量没有合法取值时结束。联合使用 MRV 和前向检验，很多问题的搜索将更有效。但是前向检验只使当前变量弧相容，却不向前看使其他变量弧相容。</li><li>MAC 维护弧相容，递归传播约束。对一个变量赋值后，使用 AC-3，从临接的未赋值变量开始进行约束传播，如果值域为空，则调用失败立即回溯。</li></ul><h3 id="3-当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？"><a href="#3-当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？" class="headerlink" title="3. 当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？"></a>3. 当我们搜索到某赋值违反约束时，搜索本身能避免重复这样的失败吗？</h3><ul><li>简单的时序回溯。退回到上一个变量</li><li>冲突指导的回溯。退回到可能解决当前问题的变量（因为上一个变量可能无力于解决当前冲突）。构建一个冲突集，回溯到冲突集中时间最近的赋值。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能中的约束满足问题（Constraint Satisfaction Problems 问题）学习笔记。&lt;/p&gt;</summary>
    
    
    
    <category term="Artificial Intelligence" scheme="https://blog.superui.cc/categories/Artificial-Intelligence/"/>
    
    
    <category term="AI" scheme="https://blog.superui.cc/tags/AI/"/>
    
    <category term="search" scheme="https://blog.superui.cc/tags/search/"/>
    
  </entry>
  
</feed>
